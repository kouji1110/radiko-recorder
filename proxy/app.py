from flask import Flask, Response, request, jsonify, stream_with_context, send_file, session, redirect, url_for
import requests
from flask_cors import CORS
import logging
import subprocess
import json
import os
from datetime import datetime, timedelta
from apscheduler.schedulers.background import BackgroundScheduler
import atexit
import zipfile
import tempfile
import time
import select
from functools import wraps
import threading

# DBãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
import db
import fetch_programs

app = Flask(__name__)
app.config['JSON_AS_ASCII'] = False  # æ—¥æœ¬èªãªã©ã®éASCIIæ–‡å­—ã‚’ãã®ã¾ã¾å‡ºåŠ›
app.config['SECRET_KEY'] = os.environ.get('SECRET_KEY', 'radiko-recorder-secret-key-change-in-production')
app.config['PERMANENT_SESSION_LIFETIME'] = timedelta(days=30)  # ã‚»ãƒƒã‚·ãƒ§ãƒ³æœ‰åŠ¹æœŸé™30æ—¥
CORS(app, resources={r"/*": {"origins": "*"}}, supports_credentials=True)

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ãƒ‘ã‚¹è¨­å®šï¼ˆDockerç’°å¢ƒç”¨ï¼‰
BASE_DIR = os.environ.get('BASE_DIR', '/app')
SCRIPT_PATH = os.path.join(BASE_DIR, 'script/myradiko')
OUTPUT_DIR = os.path.join(BASE_DIR, 'output/radio')

# APSchedulerã®åˆæœŸåŒ–
scheduler = BackgroundScheduler(daemon=True, timezone='Asia/Tokyo')
scheduler.start()

# ã‚¢ãƒ—ãƒªçµ‚äº†æ™‚ã«ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ã‚’åœæ­¢
atexit.register(lambda: scheduler.shutdown())

logger.info('âœ… APScheduler initialized')

# ========================================
# èªè¨¼è¨­å®š
# ========================================

# ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰è¨­å®šï¼ˆç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯'radiko2025'ï¼‰
AUTH_PASSWORD = os.environ.get('AUTH_PASSWORD', 'radiko2025')

def login_required(f):
    """ãƒ­ã‚°ã‚¤ãƒ³ãŒå¿…è¦ãªã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆç”¨ã®ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿"""
    @wraps(f)
    def decorated_function(*args, **kwargs):
        if not session.get('logged_in'):
            return jsonify({'error': 'Unauthorized', 'message': 'èªè¨¼ãŒå¿…è¦ã§ã™'}), 401
        return f(*args, **kwargs)
    return decorated_function

@app.route('/auth/login', methods=['POST'])
def login():
    """ãƒ­ã‚°ã‚¤ãƒ³ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ"""
    data = request.get_json()
    password = data.get('password', '')

    if password == AUTH_PASSWORD:
        session['logged_in'] = True
        session.permanent = True  # 30æ—¥é–“æœ‰åŠ¹
        logger.info('âœ… Login successful')
        return jsonify({'success': True, 'message': 'ãƒ­ã‚°ã‚¤ãƒ³ã—ã¾ã—ãŸ'})
    else:
        logger.warning('âŒ Login failed: incorrect password')
        return jsonify({'success': False, 'message': 'ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãŒé–“é•ã£ã¦ã„ã¾ã™'}), 401

@app.route('/auth/logout', methods=['POST'])
def logout():
    """ãƒ­ã‚°ã‚¢ã‚¦ãƒˆã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ"""
    session.pop('logged_in', None)
    logger.info('ğŸ‘‹ Logout successful')
    return jsonify({'success': True, 'message': 'ãƒ­ã‚°ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸ'})

@app.route('/auth/check', methods=['GET'])
def check_auth():
    """èªè¨¼çŠ¶æ…‹ç¢ºèªã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ"""
    is_logged_in = session.get('logged_in', False)
    return jsonify({'logged_in': is_logged_in})


# ========================================
# éŒ²éŸ³å®Ÿè¡Œé–¢æ•°
# ========================================

def convert_cron_dow_to_apscheduler(cron_dow):
    """
    cronå½¢å¼ã®æ›œæ—¥ï¼ˆ0=æ—¥æ›œ, 1=æœˆæ›œ, ..., 6=åœŸæ›œï¼‰ã‚’
    APSchedulerå½¢å¼ï¼ˆmon,tue,wed,thu,fri,sat,sunï¼‰ã«å¤‰æ›
    """
    # cronã®æ•°å€¤è¡¨è¨˜ã‚’APSchedulerã®æ–‡å­—åˆ—è¡¨è¨˜ã«å¤‰æ›
    dow_map = {
        '0': 'sun',
        '1': 'mon',
        '2': 'tue',
        '3': 'wed',
        '4': 'thu',
        '5': 'fri',
        '6': 'sat',
        '*': '*'
    }

    # ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã®å ´åˆã‚‚å¯¾å¿œ
    if ',' in cron_dow:
        parts = cron_dow.split(',')
        return ','.join([dow_map.get(p.strip(), p.strip()) for p in parts])

    return dow_map.get(cron_dow, cron_dow)


def execute_recording(command: str, job_id=None, job_type='cron', metadata=None):
    """éŒ²éŸ³ã‚’å®Ÿè¡Œã™ã‚‹é–¢æ•°"""
    try:
        logger.info(f'ğŸ™ï¸ Recording started (type={job_type}, job_id={job_id})')
        logger.info(f'ğŸ“ Command: {command}')
        logger.info(f'ğŸ“‹ Metadata received: {metadata}')
        logger.info(f'ğŸ“‹ Metadata type: {type(metadata)}, bool: {bool(metadata)}')

        # ã‚³ãƒãƒ³ãƒ‰ã‹ã‚‰ãƒ•ã‚©ãƒ«ãƒ€IDãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æŠ½å‡ºï¼ˆç¬¬7å¼•æ•°ï¼‰
        # å½¢å¼: myradiko "title" "rss" "station" "start" "end" "" "folder_id" "" >> ...
        virtual_folder_id = None
        try:
            import re
            # 7ç•ªç›®ã®ã‚¯ã‚©ãƒ¼ãƒˆå†…ã®æ–‡å­—åˆ—ã‚’æ¢ã™
            pattern = r'"([^"]*)"'
            matches = re.findall(pattern, command)
            if len(matches) >= 7:
                folder_id_str = matches[6]  # 7ç•ªç›®ã®å¼•æ•°ï¼ˆ0-indexedï¼‰
                if folder_id_str and folder_id_str != '':
                    try:
                        virtual_folder_id = int(folder_id_str)
                        logger.info(f'ğŸ“ Extracted virtual_folder_id from command: {virtual_folder_id}')
                    except (ValueError, TypeError):
                        logger.warning(f'âš ï¸ Invalid folder ID in command: {folder_id_str}')
        except Exception as e:
            logger.warning(f'âš ï¸ Failed to extract folder from command: {str(e)}')

        # ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œ
        result = subprocess.run(
            command,
            shell=True,
            capture_output=True,
            text=True,
            timeout=7200  # 2æ™‚é–“ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
        )

        if result.returncode == 0:
            logger.info(f'âœ… Recording completed successfully')
            if result.stdout:
                logger.info(f'ğŸ“¤ Output: {result.stdout[:500]}')

            # éŒ²éŸ³æˆåŠŸæ™‚ã€DBã«ç™»éŒ²
            if metadata:
                try:
                    # ç”Ÿæˆã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¢ã™
                    title = metadata.get('title', '')
                    rss = metadata.get('rss', '')
                    start_time = metadata.get('start_time', '')
                    station = metadata.get('station', '')

                    # start_timeãŒ4æ¡ï¼ˆHHMMï¼‰ã®å ´åˆã€ä»Šæ—¥ã®æ—¥ä»˜ã‚’å‰ç½®
                    if len(start_time) == 4:
                        from datetime import datetime
                        today_date = datetime.now().strftime('%Y%m%d')
                        start_time = today_date + start_time
                        logger.info(f'ğŸ“… Expanded start_time from HHMM to YYYYMMDDHHMM: {start_time}')

                    # ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ç”Ÿæˆ
                    filename = f'{title}({start_time[:4]}.{start_time[4:6]}.{start_time[6:8]}).mp3'

                    # myradikoã¯å¸¸ã«OUTPUT_DIR/rss/ã«ä¿å­˜ã™ã‚‹ï¼ˆå®Ÿéš›ã®ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ï¼‰
                    actual_output_dir = os.path.join(OUTPUT_DIR, rss)
                    actual_file_path = os.path.join(actual_output_dir, filename)

                    # file_pathã¯å®Ÿéš›ã®ãƒ‘ã‚¹ï¼ˆä»®æƒ³ãƒ•ã‚©ãƒ«ãƒ€ã‚’å«ã¾ãªã„ï¼‰
                    relative_path = f'{rss}/{filename}'

                    # virtual_folder_idã¯å¤–å´ã®ã‚¹ã‚³ãƒ¼ãƒ—ã‹ã‚‰å–å¾—æ¸ˆã¿

                    # ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ç¢ºèªã¯å®Ÿéš›ã®ãƒ‘ã‚¹ã§è¡Œã†
                    file_path = actual_file_path

                    if os.path.exists(file_path):
                        file_stat = os.stat(file_path)
                        file_metadata = extract_metadata_from_filename(filename, relative_path)

                        # ç•ªçµ„è¡¨ã‹ã‚‰ç•ªçµ„IDã‚’æ¤œç´¢
                        program_id = None
                        if rss and start_time:
                            program_id = db.find_program_by_info(rss, start_time)
                            if program_id:
                                logger.info(f'ğŸ“‹ Found program ID: {program_id}')

                        # DBã«ç™»éŒ²
                        db.register_recorded_file(
                            file_path=relative_path,
                            file_name=filename,
                            program_id=program_id,
                            program_title=file_metadata['program_title'],
                            station_id=file_metadata['station_id'],
                            station_name=station,
                            broadcast_date=file_metadata['broadcast_date'],
                            start_time=start_time,
                            end_time=metadata.get('end_time'),
                            file_size=file_stat.st_size,
                            duration=None,
                            file_modified=datetime.fromtimestamp(file_stat.st_mtime).isoformat(),
                            virtual_folder_id=virtual_folder_id
                        )
                        logger.info(f'ğŸ“ Recorded file registered in DB: {relative_path}')

                        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã¨ã‚¢ãƒ¼ãƒˆãƒ¯ãƒ¼ã‚¯ã‚’åŸ‹ã‚è¾¼ã‚€
                        embed_metadata_after_recording(file_path, title, station)
                except Exception as e:
                    logger.error(f'âŒ Failed to register file in DB: {str(e)}')
                    import traceback
                    logger.error(f'âŒ Traceback: {traceback.format_exc()}')
        else:
            logger.error(f'âŒ Recording failed with return code: {result.returncode}')
            if result.stderr:
                logger.error(f'ğŸ“¤ Error output: {result.stderr[:500]}')

        # atäºˆç´„ã®å ´åˆã¯DBã‹ã‚‰å‰Šé™¤
        if job_id and job_type == 'at':
            db.delete_at_job(job_id)
            logger.info(f'ğŸ—‘ï¸ At job removed from DB: {job_id}')

    except subprocess.TimeoutExpired:
        logger.error(f'âŒ Recording timeout (2 hours exceeded)')
    except Exception as e:
        logger.error(f'âŒ Recording error: {str(e)}')


def restore_jobs_from_db():
    """DBã‹ã‚‰äºˆç´„ã‚’å¾©å…ƒã—ã¦ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ã«ç™»éŒ²"""
    try:
        logger.info('ğŸ”„ Restoring jobs from database...')

        # cronäºˆç´„ã‚’å¾©å…ƒ
        cron_jobs = db.get_all_cron_jobs()
        logger.info(f"ğŸ“‹ Found {len(cron_jobs)} cron jobs in database")

        for job in cron_jobs:
            try:
                # cronå½¢å¼ã®æ›œæ—¥ã‚’APSchedulerå½¢å¼ã«å¤‰æ›
                apscheduler_dow = convert_cron_dow_to_apscheduler(job['day_of_week'])

                # metadataã‚’æ§‹ç¯‰
                metadata = {
                    'title': job.get('title', ''),
                    'rss': job.get('station', ''),
                    'station': job.get('station', ''),
                    'start_time': job.get('start_time', ''),
                    'end_time': job.get('end_time', '')
                }

                scheduler.add_job(
                    func=execute_recording,
                    trigger='cron',
                    minute=job['minute'],
                    hour=job['hour'],
                    day=job['day_of_month'],
                    month=job['month'],
                    day_of_week=apscheduler_dow,
                    args=[job['command'], job['id'], 'cron', metadata],
                    id=f"cron_{job['id']}",
                    replace_existing=True
                )
                logger.info(f"âœ… Cron job restored: {job['title']} (ID: {job['id']}) - Schedule: {job['minute']}:{job['hour']} on {job['day_of_week']} -> {apscheduler_dow}")
            except Exception as e:
                logger.error(f"âŒ Failed to restore cron job {job['id']}: {str(e)}")

        # atäºˆç´„ã‚’å¾©å…ƒ
        at_jobs = db.get_all_at_jobs()
        logger.info(f"ğŸ“‹ Found {len(at_jobs)} at jobs in database")

        for job in at_jobs:
            try:
                # schedule_timeã‚’datetimeã«å¤‰æ›
                run_date = datetime.fromisoformat(job['schedule_time'])

                # éå»ã®äºˆç´„ã¯ã‚¹ã‚­ãƒƒãƒ—
                if run_date < datetime.now():
                    logger.warning(f"âš ï¸ Skipping past at job: {job['title']} (scheduled: {job['schedule_time']})")
                    db.delete_at_job(job['id'])
                    continue

                # metadataã‚’æ§‹ç¯‰
                metadata = {
                    'title': job.get('title', ''),
                    'rss': job.get('station', ''),
                    'station': job.get('station', ''),
                    'start_time': job.get('start_time', ''),
                    'end_time': job.get('end_time', '')
                }

                scheduler.add_job(
                    func=execute_recording,
                    trigger='date',
                    run_date=run_date,
                    args=[job['command'], job['id'], 'at', metadata],
                    id=f"at_{job['id']}",
                    replace_existing=True
                )
                logger.info(f"âœ… At job restored: {job['title']} (ID: {job['id']}, scheduled: {job['schedule_time']})")
            except Exception as e:
                logger.error(f"âŒ Failed to restore at job {job['id']}: {str(e)}")

        logger.info(f'âœ… Job restoration completed: {len(cron_jobs)} cron, {len(at_jobs)} at')

    except Exception as e:
        logger.error(f'âŒ Job restoration error: {str(e)}')


# DBã‹ã‚‰äºˆç´„ã‚’å¾©å…ƒ
restore_jobs_from_db()


# ãƒ•ã‚¡ã‚¤ãƒ«åã‚µãƒ‹ã‚¿ã‚¤ã‚ºé–¢æ•°
def sanitize_filename(title):
    """ç•ªçµ„åã‚’ãƒ•ã‚¡ã‚¤ãƒ«åã¨ã—ã¦å®‰å…¨ãªå½¢å¼ã«å¤‰æ›

    - åŠè§’ã‚¹ãƒšãƒ¼ã‚¹ãƒ»å…¨è§’ã‚¹ãƒšãƒ¼ã‚¹ã‚’ã‚¢ãƒ³ãƒ€ãƒ¼ãƒãƒ¼ã«
    - å…¨è§’æ–‡å­—ã‚’åŠè§’ã«å¤‰æ›
    - å…¨è§’æ•°å­—ãƒ»è‹±å­—ã‚’åŠè§’ã«
    """
    if not title:
        return title

    # ã‚¹ãƒšãƒ¼ã‚¹ã‚’ã‚¢ãƒ³ãƒ€ãƒ¼ãƒãƒ¼ã«
    title = title.replace(' ', '_')
    title = title.replace('ã€€', '_')

    # å…¨è§’è‹±æ•°å­—ã‚’åŠè§’ã«
    full_to_half = str.maketrans(
        'ï¼¡ï¼¢ï¼£ï¼¤ï¼¥ï¼¦ï¼§ï¼¨ï¼©ï¼ªï¼«ï¼¬ï¼­ï¼®ï¼¯ï¼°ï¼±ï¼²ï¼³ï¼´ï¼µï¼¶ï¼·ï¼¸ï¼¹ï¼ºï½ï½‚ï½ƒï½„ï½…ï½†ï½‡ï½ˆï½‰ï½Šï½‹ï½Œï½ï½ï½ï½ï½‘ï½’ï½“ï½”ï½•ï½–ï½—ï½˜ï½™ï½šï¼ï¼‘ï¼’ï¼“ï¼”ï¼•ï¼–ï¼—ï¼˜ï¼™',
        'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789'
    )
    title = title.translate(full_to_half)

    # å…¨è§’æ‹¬å¼§ãƒ»è¨˜å·ã‚’åŠè§’ã«
    replacements = {
        'ï¼ˆ': '(',
        'ï¼‰': ')',
        'ã€Œ': '[',
        'ã€': ']',
        'ï¼š': ':',
        'ï¼': '!',
        'ï¼Ÿ': '?',
        'ï¼»': '[',
        'ï¼½': ']',
        'ã€': '[',
        'ã€‘': ']'
    }

    for old, new in replacements.items():
        title = title.replace(old, new)

    return title

def embed_artwork_to_mp3(file_path, artwork_data, mime_type, title=None, artist=None):
    """MP3ãƒ•ã‚¡ã‚¤ãƒ«ã«ã‚¢ãƒ¼ãƒˆãƒ¯ãƒ¼ã‚¯ã¨ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’åŸ‹ã‚è¾¼ã‚€"""
    try:
        from mutagen.mp3 import MP3
        from mutagen.id3 import ID3, APIC, TIT2, TPE1

        # MP3ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
        audio = MP3(file_path, ID3=ID3)

        # ID3ã‚¿ã‚°ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯è¿½åŠ 
        if audio.tags is None:
            audio.add_tags()

        # ã‚¢ãƒ¼ãƒˆãƒ¯ãƒ¼ã‚¯ã‚’åŸ‹ã‚è¾¼ã¿
        if artwork_data:
            # æ—¢å­˜ã®ã‚¢ãƒ¼ãƒˆãƒ¯ãƒ¼ã‚¯ã‚’å‰Šé™¤
            audio.tags.delall('APIC')

            # MIMEã‚¿ã‚¤ãƒ—ã‚’mutagenã®å½¢å¼ã«å¤‰æ›
            mime_map = {
                'image/jpeg': 'image/jpeg',
                'image/jpg': 'image/jpeg',
                'image/png': 'image/png',
                'image/gif': 'image/gif',
                'image/webp': 'image/webp'
            }
            mutagen_mime = mime_map.get(mime_type, 'image/jpeg')

            # ã‚¢ãƒ¼ãƒˆãƒ¯ãƒ¼ã‚¯ã‚’è¿½åŠ 
            audio.tags.add(
                APIC(
                    encoding=3,  # UTF-8
                    mime=mutagen_mime,
                    type=3,  # Cover (front)
                    desc='Cover',
                    data=artwork_data
                )
            )

        # ã‚¿ã‚¤ãƒˆãƒ«ã‚’åŸ‹ã‚è¾¼ã¿
        if title:
            audio.tags.delall('TIT2')
            audio.tags.add(TIT2(encoding=3, text=title))

        # ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆåã‚’åŸ‹ã‚è¾¼ã¿
        if artist:
            audio.tags.delall('TPE1')
            audio.tags.add(TPE1(encoding=3, text=artist))

        # ä¿å­˜
        audio.save()
        return True

    except Exception as e:
        logger.error(f'Failed to embed artwork to {file_path}: {str(e)}')
        return False


def embed_metadata_after_recording(file_path: str, title: str, station: str):
    """éŒ²éŸ³å®Œäº†å¾Œã«ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã¨ã‚¢ãƒ¼ãƒˆãƒ¯ãƒ¼ã‚¯ã‚’åŸ‹ã‚è¾¼ã‚€"""
    try:
        if not os.path.exists(file_path):
            logger.warning(f'File not found for metadata embedding: {file_path}')
            return False

        # ã‚¢ãƒ¼ãƒˆãƒ¯ãƒ¼ã‚¯ã‚’DBã‹ã‚‰å–å¾—
        artwork_data = db.get_artwork(title)

        if artwork_data:
            # ã‚¢ãƒ¼ãƒˆãƒ¯ãƒ¼ã‚¯ãŒç™»éŒ²ã•ã‚Œã¦ã„ã‚‹å ´åˆã€åŸ‹ã‚è¾¼ã‚€
            logger.info(f'Embedding artwork for: {title}')
            result = embed_artwork_to_mp3(
                file_path,
                artwork_data['image_data'],
                artwork_data['mime_type'],
                title=title,
                artist=station
            )
            if result:
                logger.info(f'âœ… Metadata embedded successfully: {file_path}')
            else:
                logger.warning(f'âš ï¸ Failed to embed metadata: {file_path}')
            return result
        else:
            # ã‚¢ãƒ¼ãƒˆãƒ¯ãƒ¼ã‚¯ãŒãªã„å ´åˆã€ã‚¿ã‚¤ãƒˆãƒ«ã¨ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆã®ã¿åŸ‹ã‚è¾¼ã‚€
            logger.info(f'No artwork found, embedding title/artist only: {title}')
            result = embed_artwork_to_mp3(
                file_path,
                None,  # ã‚¢ãƒ¼ãƒˆãƒ¯ãƒ¼ã‚¯ãªã—
                None,
                title=title,
                artist=station
            )
            if result:
                logger.info(f'âœ… Title/Artist embedded successfully: {file_path}')
            else:
                logger.warning(f'âš ï¸ Failed to embed title/artist: {file_path}')
            return result

    except Exception as e:
        logger.error(f'âŒ Error embedding metadata: {str(e)}')
        return False


# DBåˆæœŸåŒ–
db.init_database()

# ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼è¨­å®šï¼ˆæ·±å¤œ3æ™‚ã«å®Ÿè¡Œï¼‰
scheduler = BackgroundScheduler(daemon=True, timezone='Asia/Tokyo')
scheduler.add_job(
    func=fetch_programs.update_all_areas,
    trigger='cron',
    hour=3,  # æ¯æ—¥3:00AMã«å®Ÿè¡Œ
    minute=0,
    id='update_programs',
    name='Update radiko programs daily at 3:00 AM',
    replace_existing=True
)
scheduler.start()

# ã‚¢ãƒ—ãƒªçµ‚äº†æ™‚ã«ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ã‚’ã‚·ãƒ£ãƒƒãƒˆãƒ€ã‚¦ãƒ³
atexit.register(lambda: scheduler.shutdown())

logger.info('âœ… Scheduler started: updating programs daily at 3:00 AM JST')

@app.route('/health')
def health():
    """ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯"""
    return {'status': 'ok'}, 200

@app.route('/radiko/<path:path>')
def proxy(path):
    """radikoã¸ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’ãƒ—ãƒ­ã‚­ã‚·ã™ã‚‹"""
    url = f'http://radiko.jp/{path}'
    logger.info(f'Proxying request to: {url}')

    try:
        resp = requests.get(
            url,
            timeout=30,
            headers={
                'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36'
            }
        )

        return Response(
            resp.content,
            status=resp.status_code,
            content_type=resp.headers.get('content-type', 'text/xml'),
            headers={
                'Cache-Control': 'no-cache, no-store, must-revalidate',
                'Pragma': 'no-cache',
                'Expires': '0'
            }
        )
    except requests.RequestException as e:
        logger.error(f'Error proxying request: {str(e)}')
        return Response(
            f'Error: {str(e)}',
            status=500,
            content_type='text/plain'
        )


def monitor_and_register_recording(process, title, rss, station, start_time, end_time, virtual_folder_id, safe_title):
    """
    ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§éŒ²éŸ³ãƒ—ãƒ­ã‚»ã‚¹ã®å®Œäº†ã‚’ç›£è¦–ã—ã€DBç™»éŒ²ã‚’è¡Œã†

    ã“ã®é–¢æ•°ã¯åˆ¥ã‚¹ãƒ¬ãƒƒãƒ‰ã§å®Ÿè¡Œã•ã‚Œã‚‹ãŸã‚ã€ãƒ–ãƒ©ã‚¦ã‚¶ãŒåˆ‡æ–­ã•ã‚Œã¦ã‚‚
    ãƒ—ãƒ­ã‚»ã‚¹å®Œäº†ã¨DBç™»éŒ²ã‚’ä¿è¨¼ã™ã‚‹
    """
    try:
        logger.info(f'ğŸ” [Background] Monitoring recording process for: {title}')

        # ãƒ—ãƒ­ã‚»ã‚¹ã®å®Œäº†ã‚’å¾…ã¤
        process.wait()

        logger.info(f'ğŸ“ [Background] Process completed with return code: {process.returncode}')

        # ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ç”Ÿæˆ
        filename = f'{safe_title}({start_time[:4]}.{start_time[4:6]}.{start_time[6:8]}).mp3'

        # myradikoã¯å¸¸ã«OUTPUT_DIR/rss/ã«ä¿å­˜ã™ã‚‹
        actual_output_dir = os.path.join(OUTPUT_DIR, rss)
        actual_file_path = os.path.join(actual_output_dir, filename)
        relative_path = f'{rss}/{filename}'

        # ISOå½¢å¼ã®æ™‚åˆ»ã‚’æº–å‚™
        iso_start_time = f'{start_time[:4]}-{start_time[4:6]}-{start_time[6:8]}T{start_time[8:10]}:{start_time[10:12]}:00' if start_time else None
        iso_end_time = f'{end_time[:4]}-{end_time[4:6]}-{end_time[6:8]}T{end_time[8:10]}:{end_time[10:12]}:00' if end_time else None
        broadcast_date = f'{start_time[:4]}-{start_time[4:6]}-{start_time[6:8]}' if start_time else None

        # ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèª
        if not os.path.exists(actual_file_path):
            logger.warning(f'âš ï¸ [Background] File not found after recording: {actual_file_path}')
            return

        logger.info(f'âœ… [Background] File exists: {actual_file_path}')

        # ãƒ•ã‚¡ã‚¤ãƒ«çµ±è¨ˆæƒ…å ±ã‚’å–å¾—
        file_stat = os.stat(actual_file_path)

        # ç•ªçµ„è¡¨ã‹ã‚‰ç•ªçµ„IDã‚’æ¤œç´¢
        program_id = None
        if rss and iso_start_time:
            program_id = db.find_program_by_info(rss, iso_start_time)
            if program_id:
                logger.info(f'ğŸ“‹ [Background] Found program ID: {program_id}')

        # DBã«ç™»éŒ²
        db.register_recorded_file(
            file_path=relative_path,
            file_name=filename,
            program_id=program_id,
            program_title=title,
            station_id=rss,
            station_name=station,
            broadcast_date=broadcast_date,
            start_time=iso_start_time,
            end_time=iso_end_time,
            file_size=file_stat.st_size,
            duration=None,
            file_modified=datetime.fromtimestamp(file_stat.st_mtime).isoformat(),
            virtual_folder_id=virtual_folder_id
        )
        logger.info(f'âœ… [Background] File registered in DB: {relative_path}')

        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã¨ã‚¢ãƒ¼ãƒˆãƒ¯ãƒ¼ã‚¯ã‚’åŸ‹ã‚è¾¼ã‚€
        embed_metadata_after_recording(actual_file_path, title, station)
        logger.info(f'âœ… [Background] Metadata embedded: {relative_path}')

    except Exception as e:
        logger.error(f'âŒ [Background] Error in monitor_and_register_recording: {str(e)}')
        import traceback
        logger.error(f'âŒ [Background] Traceback: {traceback.format_exc()}')


@app.route('/execute', methods=['POST', 'OPTIONS'])
def execute_recording_http():
    """éŒ²éŸ³ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã¦ãƒ­ã‚°ã‚’ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ï¼ˆHTTPã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆï¼‰"""
    # OPTIONSãƒªã‚¯ã‚¨ã‚¹ãƒˆï¼ˆCORS preflightï¼‰ã¸ã®å¯¾å¿œ
    if request.method == 'OPTIONS':
        response = Response()
        response.headers['Access-Control-Allow-Origin'] = '*'
        response.headers['Access-Control-Allow-Methods'] = 'POST, OPTIONS'
        response.headers['Access-Control-Allow-Headers'] = 'Content-Type'
        return response

    data = request.json
    title = data.get('title', '')
    rss = data.get('rss', '')
    station = data.get('station', '')
    start_time = data.get('start_time', '')
    end_time = data.get('end_time', '')
    folder_id_str = data.get('folder', '')

    # ãƒ•ã‚©ãƒ«ãƒ€IDã‚’æ•´æ•°ã«å¤‰æ›ï¼ˆç©ºæ–‡å­—åˆ—ã¯Noneï¼‰
    virtual_folder_id = None
    if folder_id_str and folder_id_str != '':
        try:
            virtual_folder_id = int(folder_id_str)
        except (ValueError, TypeError):
            logger.warning(f'âš ï¸ Invalid folder ID: {folder_id_str}')

    # ã‚¿ã‚¤ãƒˆãƒ«ã‚’ã‚µãƒ‹ã‚¿ã‚¤ã‚ºï¼ˆã‚¹ãƒšãƒ¼ã‚¹ã‚’ã‚¢ãƒ³ãƒ€ãƒ¼ãƒãƒ¼ã«ã€å…¨è§’è¨˜å·ã‚’åŠè§’ã«ï¼‰
    safe_title = sanitize_filename(title)

    # ãƒ‡ãƒãƒƒã‚°ç”¨ãƒ­ã‚°
    logger.info(f'Original title: {title}')
    logger.info(f'Sanitized title: {safe_title}')
    logger.info(f'ğŸ“ Received virtual_folder_id: {virtual_folder_id}')

    def generate_log():
        """ãƒ­ã‚°ã‚’ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã§è¿”ã™"""
        timestamp = datetime.now().strftime('%Y/%m/%d %H:%M:%S')

        # é–‹å§‹ãƒ­ã‚°
        yield f'data: {json.dumps({"type": "log", "message": f"[{timestamp}] ã‚³ãƒãƒ³ãƒ‰å®Ÿè¡Œé–‹å§‹..."}, ensure_ascii=False)}\n\n'
        yield f'data: {json.dumps({"type": "log", "message": f"[{timestamp}] å…ƒã®ã‚¿ã‚¤ãƒˆãƒ«: {title}"}, ensure_ascii=False)}\n\n'
        yield f'data: {json.dumps({"type": "log", "message": f"[{timestamp}] ã‚µãƒ‹ã‚¿ã‚¤ã‚ºå¾Œ: {safe_title}"}, ensure_ascii=False)}\n\n'

        # myradikoã‚¹ã‚¯ãƒªãƒ—ãƒˆã®ãƒ‘ã‚¹
        script_path = SCRIPT_PATH

        # ã‚³ãƒãƒ³ãƒ‰æ§‹ç¯‰ï¼ˆã‚µãƒ‹ã‚¿ã‚¤ã‚ºã—ãŸã‚¿ã‚¤ãƒˆãƒ«ã‚’ä½¿ç”¨ï¼‰
        cmd = [
            script_path,
            safe_title,
            rss,
            station,
            start_time,
            end_time,
            '',  # SKIP
            '',  # DIRï¼ˆä½¿ç”¨ã—ãªã„ï¼‰
            ''   # MAIL
        ]

        cmd_str = ' '.join([f'"{arg}"' if ' ' in arg else arg for arg in cmd])
        timestamp = datetime.now().strftime('%Y/%m/%d %H:%M:%S')
        yield f'data: {json.dumps({"type": "log", "message": f"[{timestamp}] {cmd_str}"}, ensure_ascii=False)}\n\n'

        try:
            # ãƒ—ãƒ­ã‚»ã‚¹ã‚’èµ·å‹•ï¼ˆãƒãƒƒãƒ•ã‚¡ãªã—ã§å³åº§ã«å‡ºåŠ›ï¼‰
            process = subprocess.Popen(
                cmd,
                stdout=subprocess.PIPE,
                stderr=subprocess.STDOUT,
                encoding='utf-8',
                errors='replace',  # ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼ã‚’ç½®ãæ›ãˆæ–‡å­—ã§å‡¦ç†
                bufsize=0,  # ãƒãƒƒãƒ•ã‚¡ãªã—
                universal_newlines=True
            )

            # ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã‚¹ãƒ¬ãƒƒãƒ‰ã§DBç™»éŒ²ã‚’ç›£è¦–
            # ãƒ–ãƒ©ã‚¦ã‚¶ãŒåˆ‡æ–­ã•ã‚Œã¦ã‚‚ã€ã“ã®ã‚¹ãƒ¬ãƒƒãƒ‰ã¯ç‹¬ç«‹ã—ã¦å®Ÿè¡Œã•ã‚Œã‚‹
            monitor_thread = threading.Thread(
                target=monitor_and_register_recording,
                args=(process, title, rss, station, start_time, end_time, virtual_folder_id, safe_title),
                daemon=False  # ã‚¢ãƒ—ãƒªçµ‚äº†æ™‚ã‚‚å®Œäº†ã‚’å¾…ã¤
            )
            monitor_thread.start()
            logger.info(f'ğŸš€ [Main] Background monitoring thread started for: {title}')

            # å‡ºåŠ›ã‚’é€æ¬¡é€ä¿¡
            last_output_time = time.time()
            error_403_detected = False

            while True:
                # ãƒ—ãƒ­ã‚»ã‚¹ãŒçµ‚äº†ã—ãŸã‹ãƒã‚§ãƒƒã‚¯
                if process.poll() is not None:
                    # æ®‹ã‚Šã®å‡ºåŠ›ã‚’èª­ã¿å–ã‚‹
                    remaining = process.stdout.read()
                    if remaining:
                        for line in remaining.splitlines():
                            line = line.rstrip()
                            if line:
                                timestamp = datetime.now().strftime('%Y/%m/%d %H:%M:%S')
                                # JSONå®‰å…¨ãªæ–‡å­—åˆ—ã‚’ç”Ÿæˆ
                                message = f"[{timestamp}] {line}"
                                yield f'data: {json.dumps({"type": "log", "message": message}, ensure_ascii=False)}\n\n'
                                if '403 Forbidden' in line:
                                    error_403_detected = True
                    break

                # å‡ºåŠ›ã‚’èª­ã¿å–ã‚‹ï¼ˆãƒãƒ³ãƒ–ãƒ­ãƒƒã‚­ãƒ³ã‚°ï¼‰
                line = process.stdout.readline()
                if line:
                    last_output_time = time.time()
                    line = line.rstrip()
                    if line:
                        timestamp = datetime.now().strftime('%Y/%m/%d %H:%M:%S')
                        # JSONå®‰å…¨ãªæ–‡å­—åˆ—ã‚’ç”Ÿæˆ
                        message = f"[{timestamp}] {line}"
                        yield f'data: {json.dumps({"type": "log", "message": message}, ensure_ascii=False)}\n\n'
                        if '403 Forbidden' in line:
                            error_403_detected = True
                else:
                    # å‡ºåŠ›ãŒãªã„å ´åˆã¯å°‘ã—å¾…ã¤
                    time.sleep(0.1)

                    # 30ç§’é–“å‡ºåŠ›ãŒãªã„å ´åˆã€ãƒãƒ¼ãƒˆãƒ“ãƒ¼ãƒˆã‚’é€ä¿¡
                    if time.time() - last_output_time > 30:
                        timestamp = datetime.now().strftime('%Y/%m/%d %H:%M:%S')
                        yield f'data: {json.dumps({"type": "log", "message": f"[{timestamp}] å‡¦ç†ä¸­..."}, ensure_ascii=False)}\n\n'
                        last_output_time = time.time()

            timestamp = datetime.now().strftime('%Y/%m/%d %H:%M:%S')

            # ãƒ•ã‚¡ã‚¤ãƒ«åã‚’å…ˆã«ç”Ÿæˆ
            filename = f'{safe_title}({start_time[:4]}.{start_time[4:6]}.{start_time[6:8]}).mp3'

            # myradikoã¯å¸¸ã«OUTPUT_DIR/rss/ã«ä¿å­˜ã™ã‚‹ï¼ˆå®Ÿéš›ã®ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ï¼‰
            actual_output_dir = os.path.join(OUTPUT_DIR, rss)
            actual_file_path = os.path.join(actual_output_dir, filename)

            # file_pathã¯å®Ÿéš›ã®ãƒ‘ã‚¹ï¼ˆä»®æƒ³ãƒ•ã‚©ãƒ«ãƒ€ã‚’å«ã¾ãªã„ï¼‰
            relative_path = f'{rss}/{filename}'

            # virtual_folder_idã¯å¤–å´ã®ã‚¹ã‚³ãƒ¼ãƒ—ã‹ã‚‰å–å¾—æ¸ˆã¿

            # ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ç¢ºèªã¯å®Ÿéš›ã®ãƒ‘ã‚¹ã§è¡Œã†
            file_path = actual_file_path

            # ISOå½¢å¼ã®æ™‚åˆ»ã‚’äº‹å‰ã«æº–å‚™
            iso_start_time = f'{start_time[:4]}-{start_time[4:6]}-{start_time[6:8]}T{start_time[8:10]}:{start_time[10:12]}:00' if start_time else None
            iso_end_time = f'{end_time[:4]}-{end_time[4:6]}-{end_time[6:8]}T{end_time[8:10]}:{end_time[10:12]}:00' if end_time else None
            broadcast_date = f'{start_time[:4]}-{start_time[4:6]}-{start_time[6:8]}' if start_time else None

            # ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèª
            file_exists = os.path.exists(file_path)

            if process.returncode == 0:
                # éŒ²éŸ³æˆåŠŸ
                if file_exists:
                    # DBç™»éŒ²ã¨ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿åŸ‹ã‚è¾¼ã¿ã¯ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã‚¹ãƒ¬ãƒƒãƒ‰ã§å‡¦ç†ã•ã‚Œã‚‹
                    yield f'data: {json.dumps({"type": "success", "message": f"[{timestamp}] éŒ²éŸ³å®Œäº†ï¼ DBç™»éŒ²å‡¦ç†ä¸­...", "file": relative_path}, ensure_ascii=False)}\n\n'
                    yield f'data: {json.dumps({"type": "log", "message": f"[{timestamp}] ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§DBç™»éŒ²ã¨ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿åŸ‹ã‚è¾¼ã¿ã‚’å®Ÿè¡Œä¸­..."}, ensure_ascii=False)}\n\n'
                else:
                    logger.error(f'âŒ Command succeeded but file not found: {file_path}')
                    yield f'data: {json.dumps({"type": "error", "message": f"[{timestamp}] ã‚¨ãƒ©ãƒ¼: ã‚³ãƒãƒ³ãƒ‰ã¯æˆåŠŸã—ã¾ã—ãŸãŒã€ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"}, ensure_ascii=False)}\n\n'
                    yield f'data: {json.dumps({"type": "error", "message": f"[{timestamp}] æœŸå¾…ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«: {filename}"}, ensure_ascii=False)}\n\n'
            else:
                # ã‚³ãƒãƒ³ãƒ‰ãŒå¤±æ•—ã—ãŸå ´åˆ
                logger.error(f'âŒ Recording command failed with returncode: {process.returncode}')
                yield f'data: {json.dumps({"type": "error", "message": f"[{timestamp}] éŒ²éŸ³å¤±æ•— (çµ‚äº†ã‚³ãƒ¼ãƒ‰: {process.returncode})"}, ensure_ascii=False)}\n\n'

                # 403ã‚¨ãƒ©ãƒ¼ã®å ´åˆã¯è¿½åŠ èª¬æ˜
                if error_403_detected:
                    yield f'data: {json.dumps({"type": "error", "message": f"[{timestamp}] âš ï¸ 403 Forbiddenã‚¨ãƒ©ãƒ¼: radikoã®ã‚¿ã‚¤ãƒ ã‚·ãƒ•ãƒˆæœŸé–“å¤–ï¼ˆ7æ—¥ä»¥ä¸Šå‰ï¼‰ã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™"}, ensure_ascii=False)}\n\n'

                # ãã‚Œã§ã‚‚ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹å ´åˆï¼ˆéƒ¨åˆ†çš„ã«æˆåŠŸï¼‰
                if file_exists:
                    logger.warning(f'âš ï¸ File exists despite error: {file_path}')
                    yield f'data: {json.dumps({"type": "log", "message": f"[{timestamp}] âš ï¸ ã‚¨ãƒ©ãƒ¼ãŒã‚ã‚Šã¾ã—ãŸãŒã€ãƒ•ã‚¡ã‚¤ãƒ«ã¯ä½œæˆã•ã‚Œã¦ã„ã¾ã™"}, ensure_ascii=False)}\n\n'
                    yield f'data: {json.dumps({"type": "log", "message": f"[{timestamp}] ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§DBç™»éŒ²ã‚’è©¦è¡Œä¸­..."}, ensure_ascii=False)}\n\n'

        except Exception as e:
            timestamp = datetime.now().strftime('%Y/%m/%d %H:%M:%S')
            yield f'data: {json.dumps({"type": "error", "message": f"[{timestamp}] ã‚¨ãƒ©ãƒ¼: {str(e)}"}, ensure_ascii=False)}\n\n'

    return Response(
        stream_with_context(generate_log()),
        mimetype='text/event-stream',
        headers={
            'Cache-Control': 'no-cache',
            'X-Accel-Buffering': 'no'
        }
    )

@app.route('/download/<path:filepath>')
def download_file(filepath):
    """éŒ²éŸ³ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"""
    try:
        # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£: ãƒ‘ã‚¹ãƒˆãƒ©ãƒãƒ¼ã‚µãƒ«å¯¾ç­–
        base_dir = OUTPUT_DIR
        safe_path = os.path.normpath(os.path.join(base_dir, filepath))

        if not safe_path.startswith(base_dir):
            return Response('Invalid file path', status=400)

        if not os.path.exists(safe_path):
            return Response('File not found', status=404)

        return send_file(
            safe_path,
            as_attachment=True,
            download_name=os.path.basename(safe_path)
        )
    except Exception as e:
        logger.error(f'Download error: {str(e)}')
        return Response(f'Error: {str(e)}', status=500)

@app.route('/edit-audio', methods=['POST', 'OPTIONS'])
def edit_audio():
    """éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚«ãƒƒãƒˆç·¨é›†"""
    # OPTIONSãƒªã‚¯ã‚¨ã‚¹ãƒˆï¼ˆCORS preflightï¼‰ã¸ã®å¯¾å¿œ
    if request.method == 'OPTIONS':
        response = Response()
        response.headers['Access-Control-Allow-Origin'] = '*'
        response.headers['Access-Control-Allow-Methods'] = 'POST, OPTIONS'
        response.headers['Access-Control-Allow-Headers'] = 'Content-Type'
        return response

    try:
        data = request.json
        file_path = data.get('file_path', '')
        start_time = data.get('start_time', 0)
        end_time = data.get('end_time', 0)
        mode = data.get('mode', 'remove')  # 'remove' or 'extract'

        if not file_path:
            return jsonify({'error': 'File path is required'}), 400

        # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£: ãƒ‘ã‚¹ãƒˆãƒ©ãƒãƒ¼ã‚µãƒ«å¯¾ç­–
        base_dir = OUTPUT_DIR
        safe_path = os.path.normpath(os.path.join(base_dir, file_path))

        if not safe_path.startswith(base_dir):
            return jsonify({'error': 'Invalid file path'}), 400

        if not os.path.exists(safe_path):
            return jsonify({'error': 'File not found'}), 404

        # ãƒ•ã‚¡ã‚¤ãƒ«åã¨æ‹¡å¼µå­ã‚’åˆ†é›¢
        file_dir = os.path.dirname(safe_path)
        file_name = os.path.basename(safe_path)
        name_without_ext, ext = os.path.splitext(file_name)

        # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ç”Ÿæˆ
        if mode == 'remove':
            output_filename = f'{name_without_ext}_cut{ext}'
        else:  # extract
            output_filename = f'{name_without_ext}_extract{ext}'

        output_path = os.path.join(file_dir, output_filename)

        # ffmpegã‚³ãƒãƒ³ãƒ‰ã‚’æ§‹ç¯‰
        if mode == 'remove':
            # ç¯„å›²ã‚’å‰Šé™¤: é–‹å§‹å‰ã®éƒ¨åˆ†ã¨çµ‚äº†å¾Œã®éƒ¨åˆ†ã‚’çµåˆ
            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
            temp1 = os.path.join(file_dir, f'temp1_{name_without_ext}{ext}')
            temp2 = os.path.join(file_dir, f'temp2_{name_without_ext}{ext}')
            concat_file = os.path.join(file_dir, f'concat_{name_without_ext}.txt')

            try:
                # é–‹å§‹å‰ã®éƒ¨åˆ†ã‚’æŠ½å‡º
                cmd1 = [
                    'ffmpeg', '-y', '-i', safe_path,
                    '-t', str(start_time),
                    '-c', 'copy',
                    temp1
                ]

                # çµ‚äº†å¾Œã®éƒ¨åˆ†ã‚’æŠ½å‡º
                cmd2 = [
                    'ffmpeg', '-y', '-i', safe_path,
                    '-ss', str(end_time),
                    '-c', 'copy',
                    temp2
                ]

                # å®Ÿè¡Œ
                subprocess.run(cmd1, check=True, capture_output=True)
                subprocess.run(cmd2, check=True, capture_output=True)

                # concatãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
                with open(concat_file, 'w') as f:
                    f.write(f"file '{temp1}'\n")
                    f.write(f"file '{temp2}'\n")

                # çµåˆ
                cmd3 = [
                    'ffmpeg', '-y', '-f', 'concat', '-safe', '0',
                    '-i', concat_file,
                    '-c', 'copy',
                    output_path
                ]
                subprocess.run(cmd3, check=True, capture_output=True)

                # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
                os.remove(temp1)
                os.remove(temp2)
                os.remove(concat_file)

            except Exception as e:
                # ã‚¨ãƒ©ãƒ¼æ™‚ã¯ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
                for temp_file in [temp1, temp2, concat_file]:
                    if os.path.exists(temp_file):
                        os.remove(temp_file)
                raise e

        else:  # extract
            # ç¯„å›²ã‚’æŠ½å‡º
            cmd = [
                'ffmpeg', '-y', '-i', safe_path,
                '-ss', str(start_time),
                '-to', str(end_time),
                '-c', 'copy',
                output_path
            ]
            subprocess.run(cmd, check=True, capture_output=True)

        # ç›¸å¯¾ãƒ‘ã‚¹ã‚’è¿”ã™
        relative_path = os.path.relpath(output_path, base_dir)

        logger.info(f'Audio edit completed: {output_filename}')

        return jsonify({
            'success': True,
            'output_file': output_filename,
            'output_path': relative_path
        })

    except subprocess.CalledProcessError as e:
        logger.error(f'FFmpeg error: {e.stderr.decode() if e.stderr else str(e)}')
        return jsonify({'error': 'Audio editing failed'}), 500
    except Exception as e:
        logger.error(f'Edit audio error: {str(e)}')
        return jsonify({'error': str(e)}), 500

@app.route('/rename-file', methods=['POST', 'OPTIONS'])
def rename_file():
    """ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒªãƒãƒ¼ãƒ """
    # OPTIONSãƒªã‚¯ã‚¨ã‚¹ãƒˆï¼ˆCORS preflightï¼‰ã¸ã®å¯¾å¿œ
    if request.method == 'OPTIONS':
        response = Response()
        response.headers['Access-Control-Allow-Origin'] = '*'
        response.headers['Access-Control-Allow-Methods'] = 'POST, OPTIONS'
        response.headers['Access-Control-Allow-Headers'] = 'Content-Type'
        return response

    try:
        data = request.json
        file_path = data.get('file_path', '')
        new_name = data.get('new_name', '')

        if not file_path or not new_name:
            return jsonify({'error': 'File path and new name are required'}), 400

        # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£: ãƒ‘ã‚¹ãƒˆãƒ©ãƒãƒ¼ã‚µãƒ«å¯¾ç­–
        base_dir = OUTPUT_DIR
        safe_path = os.path.normpath(os.path.join(base_dir, file_path))

        if not safe_path.startswith(base_dir):
            return jsonify({'error': 'Invalid file path'}), 400

        if not os.path.exists(safe_path):
            return jsonify({'error': 'File not found'}), 404

        # æ–°ã—ã„ãƒ•ã‚¡ã‚¤ãƒ«åã®ãƒ‘ã‚¹ã‚’æ§‹ç¯‰
        file_dir = os.path.dirname(safe_path)
        new_path = os.path.join(file_dir, new_name)

        # æ—¢ã«åŒã˜åå‰ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
        if os.path.exists(new_path):
            return jsonify({'error': 'A file with that name already exists'}), 400

        # ãƒªãƒãƒ¼ãƒ å®Ÿè¡Œ
        os.rename(safe_path, new_path)

        # ç›¸å¯¾ãƒ‘ã‚¹ã‚’è¿”ã™
        relative_path = os.path.relpath(new_path, base_dir)

        logger.info(f'File renamed: {file_path} -> {new_name}')

        return jsonify({
            'success': True,
            'new_name': new_name,
            'new_path': relative_path
        })

    except Exception as e:
        logger.error(f'Rename file error: {str(e)}')
        return jsonify({'error': str(e)}), 500

@app.route('/files', methods=['GET'])
def list_files():
    """éŒ²éŸ³æ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã‚’å–å¾—ï¼ˆãƒ«ãƒ¼ãƒˆãƒ•ã‚©ãƒ«ãƒ€ã®ã¿ã€virtual_folder_id=NULLï¼‰"""
    try:
        # DBã‹ã‚‰ãƒ«ãƒ¼ãƒˆãƒ•ã‚©ãƒ«ãƒ€ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—ï¼ˆvirtual_folder_id=NULLï¼‰
        files = db.get_files_in_folder(folder_id=None, limit=1000, offset=0)
        return jsonify({'files': files})
    except Exception as e:
        logger.error(f'List files error: {str(e)}')
        return jsonify({'error': str(e)}), 500

@app.route('/check-file', methods=['POST'])
def check_file_exists():
    """ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ãƒã‚§ãƒƒã‚¯"""
    try:
        data = request.json
        title = data.get('title', '')
        rss = data.get('rss', '')
        start_time = data.get('start_time', '')

        # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’æ§‹ç¯‰
        output_dir = os.path.join(OUTPUT_DIR, rss)
        filename = f'{title}({start_time[:4]}.{start_time[4:6]}.{start_time[6:8]}).mp3'
        file_path = os.path.join(output_dir, filename)

        exists = os.path.exists(file_path)
        relative_path = f'{rss}/{filename}' if exists else None

        return jsonify({
            'exists': exists,
            'path': relative_path,
            'filename': filename
        })
    except Exception as e:
        logger.error(f'Check file error: {str(e)}')
        return jsonify({'error': str(e)}), 500

@app.route('/cron/list', methods=['GET'])
def list_cron():
    """DBã‹ã‚‰cronäºˆç´„ã‚’å–å¾—"""
    try:
        jobs = db.get_all_cron_jobs()

        # ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ç”¨ã«ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
        cron_jobs = []
        for job in jobs:
            cron_jobs.append({
                'id': job['id'],
                'raw': f"{job['minute']} {job['hour']} {job['day_of_month']} {job['month']} {job['day_of_week']} {job['command']}",
                'minute': job['minute'],
                'hour': job['hour'],
                'dayOfWeek': job['day_of_week'],
                'command': job['command'],
                'title': job['title'],
                'station': job['station'],
                'startTime': job['start_time'],
                'endTime': job['end_time'],
                'virtual_folder_id': job.get('virtual_folder_id')
            })

        return jsonify({'cron_jobs': cron_jobs})

    except Exception as e:
        logger.error(f'List cron error: {str(e)}')
        return jsonify({'error': str(e)}), 500

def parse_cron_command(cron_line):
    """cronã‚³ãƒãƒ³ãƒ‰ã‚’ãƒ‘ãƒ¼ã‚¹ã—ã¦ç•ªçµ„æƒ…å ±ã‚’æŠ½å‡º"""
    import re

    parts = cron_line.split(None, 5)  # æœ€åˆã®5ã¤ã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ï¼ˆcronå¼ï¼‰ã¨ã‚³ãƒãƒ³ãƒ‰éƒ¨åˆ†ã‚’åˆ†é›¢

    if len(parts) < 6:
        return {
            'raw': cron_line,
            'minute': '',
            'hour': '',
            'dayOfWeek': '',
            'command': cron_line,
            'title': '',
            'station': '',
            'startTime': '',
            'endTime': ''
        }

    minute = parts[0]
    hour = parts[1]
    day_of_month = parts[2]
    month = parts[3]
    day_of_week = parts[4]
    command_part = parts[5]

    # myradikoã‚³ãƒãƒ³ãƒ‰ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°
    # æ–°å½¢å¼: /path/to/myradiko "ç•ªçµ„å" "RSS" "æ”¾é€å±€" "`date...`HHMM" "`date...`HHMM" "" "" ""
    # å¼•æ•°1=ã‚¿ã‚¤ãƒˆãƒ«, å¼•æ•°2=RSS, å¼•æ•°3=æ”¾é€å±€, å¼•æ•°4=é–‹å§‹æ™‚åˆ», å¼•æ•°5=çµ‚äº†æ™‚åˆ»
    pattern = r'([^\s]+)\s+"([^"]*)"\s+"([^"]*)"\s+"([^"]*)"\s+"[^"]*(\d{4})".*?"[^"]*(\d{4})"'
    match = re.search(pattern, command_part)

    title = ''
    station = ''
    start_time = ''
    end_time = ''

    if match:
        title = match.group(2)        # å¼•æ•°1: ã‚¿ã‚¤ãƒˆãƒ«
        # å¼•æ•°2ã¯RSSãªã®ã§ã€å¼•æ•°3ã®æ”¾é€å±€IDã‚’ä½¿ç”¨
        station = match.group(4)      # å¼•æ•°3: æ”¾é€å±€ID
        start_time = match.group(5)   # HHMMå½¢å¼
        end_time = match.group(6)     # HHMMå½¢å¼

    return {
        'raw': cron_line,
        'minute': minute,
        'hour': hour,
        'dayOfWeek': day_of_week,
        'command': command_part,
        'title': title,
        'station': station,
        'startTime': start_time,
        'endTime': end_time
    }

@app.route('/cron/add', methods=['POST'])
def add_cron():
    """DBã«æ–°ã—ã„cronäºˆç´„ã‚’è¿½åŠ ã—ã¦ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ã«ç™»éŒ²"""
    try:
        data = request.json
        cron_command = data.get('command', '')

        if not cron_command:
            return jsonify({'error': 'Command is required'}), 400

        # cronã‚³ãƒãƒ³ãƒ‰ã‚’ãƒ‘ãƒ¼ã‚¹
        parsed = parse_cron_command(cron_command)

        # ã‚³ãƒãƒ³ãƒ‰ã‹ã‚‰ãƒ•ã‚©ãƒ«ãƒ€IDã‚’æŠ½å‡ºï¼ˆç¬¬7å¼•æ•°ï¼‰
        virtual_folder_id = None
        try:
            import re
            pattern = r'"([^"]*)"'
            matches = re.findall(pattern, parsed['command'])
            if len(matches) >= 7:
                folder_id_str = matches[6]  # 7ç•ªç›®ã®å¼•æ•°ï¼ˆ0-indexedï¼‰
                if folder_id_str and folder_id_str != '':
                    try:
                        virtual_folder_id = int(folder_id_str)
                        logger.info(f'ğŸ“ Extracted folder_id from cron command: {virtual_folder_id}')
                    except (ValueError, TypeError):
                        logger.warning(f'âš ï¸ Invalid folder ID in cron command: {folder_id_str}')
        except Exception as e:
            logger.warning(f'âš ï¸ Failed to extract folder from cron command: {str(e)}')

        # DBã«ä¿å­˜
        job_id = db.save_cron_job(
            minute=parsed['minute'],
            hour=parsed['hour'],
            day_of_month='*',
            month='*',
            day_of_week=parsed['dayOfWeek'],
            command=parsed['command'],
            title=parsed['title'],
            station=parsed['station'],
            start_time=parsed['startTime'],
            end_time=parsed['endTime'],
            virtual_folder_id=virtual_folder_id
        )

        if not job_id:
            return jsonify({'error': 'Failed to save cron job'}), 500

        # ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ã«ç™»éŒ²
        try:
            # cronå½¢å¼ã®æ›œæ—¥ã‚’APSchedulerå½¢å¼ã«å¤‰æ›
            apscheduler_dow = convert_cron_dow_to_apscheduler(parsed['dayOfWeek'])

            logger.info(f"ğŸ“ Adding cron job to scheduler - ID: {job_id}")
            logger.info(f"ğŸ“ Schedule: minute={parsed['minute']}, hour={parsed['hour']}, dow={parsed['dayOfWeek']} -> {apscheduler_dow}")
            logger.info(f"ğŸ“ Command: {parsed['command'][:100]}")

            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’æ§‹ç¯‰
            metadata = {
                'title': parsed['title'],
                'rss': parsed['station'],
                'station': parsed['station'],
                'start_time': parsed['startTime'],
                'end_time': parsed['endTime']
            }

            scheduler.add_job(
                func=execute_recording,
                trigger='cron',
                minute=parsed['minute'],
                hour=parsed['hour'],
                day='*',
                month='*',
                day_of_week=apscheduler_dow,
                args=[parsed['command'], job_id, 'cron', metadata],
                id=f"cron_{job_id}",
                replace_existing=True
            )
            logger.info(f"âœ… Cron job added to scheduler successfully: cron_{job_id}")

            # ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ã®çŠ¶æ…‹ã‚’ãƒ­ã‚°
            all_jobs = scheduler.get_jobs()
            logger.info(f"ğŸ“Š Total scheduled jobs: {len(all_jobs)}")

        except Exception as e:
            logger.error(f"âŒ Failed to add job to scheduler: {str(e)}")
            logger.error(f"âŒ Job details - minute:{parsed['minute']}, hour:{parsed['hour']}, dow:{parsed['dayOfWeek']}, cmd:{parsed['command'][:50]}")
            # DBã‹ã‚‰ã‚‚å‰Šé™¤
            db.delete_cron_job(job_id)
            return jsonify({'error': f'Failed to schedule job: {str(e)}'}), 500

        return jsonify({'success': True, 'message': 'Cron job added successfully', 'job_id': job_id})

    except Exception as e:
        logger.error(f'Add cron error: {str(e)}')
        return jsonify({'error': str(e)}), 500

@app.route('/cron/remove', methods=['POST'])
def remove_cron():
    """DBã‹ã‚‰cronäºˆç´„ã‚’å‰Šé™¤ã—ã¦ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ã‹ã‚‰ã‚‚å‰Šé™¤"""
    try:
        data = request.json
        job_id = data.get('id')

        if not job_id:
            return jsonify({'error': 'Job ID is required'}), 400

        # DBã‹ã‚‰è©²å½“ã™ã‚‹ã‚¸ãƒ§ãƒ–ã‚’æ¤œç´¢
        jobs = db.get_all_cron_jobs()
        job_to_delete = None

        for job in jobs:
            if job['id'] == job_id:
                job_to_delete = job
                break

        if not job_to_delete:
            return jsonify({'error': 'Cron job not found'}), 404

        # ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ã‹ã‚‰å‰Šé™¤
        try:
            scheduler.remove_job(f"cron_{job_id}")
            logger.info(f"âœ… Cron job removed from scheduler: {job_id}")
        except Exception as e:
            logger.warning(f"âš ï¸ Job not found in scheduler (may be already removed): {str(e)}")

        # DBã‹ã‚‰å‰Šé™¤
        if db.delete_cron_job(job_id):
            return jsonify({'success': True, 'message': 'Cron job removed successfully'})
        else:
            return jsonify({'error': 'Failed to delete cron job from database'}), 500

    except Exception as e:
        logger.error(f'Remove cron error: {str(e)}')
        return jsonify({'error': str(e)}), 500

@app.route('/cron/logs', methods=['GET'])
def get_cron_logs():
    """cronã®ãƒ­ã‚°ã‚’å–å¾—ï¼ˆå®Ÿè¡Œã‚µãƒãƒªãƒ¼ã®ã¿ï¼‰"""
    try:
        summary_logs = []

        # myradikoå®Ÿè¡Œãƒ­ã‚°ã‚’ç¢ºèªã—ã¦ã‚µãƒãƒªãƒ¼ã‚’ä½œæˆ
        myradiko_log = '/tmp/myradiko_output.log'
        if os.path.exists(myradiko_log):
            try:
                with open(myradiko_log, 'r') as f:
                    content = f.read()

                # ãƒ­ã‚°ã‚’ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã”ã¨ã«åˆ†å‰²ï¼ˆlocaleã‚¨ãƒ©ãƒ¼ä»¥é™ãŒã²ã¨ã¤ã®å®Ÿè¡Œï¼‰
                sections = content.split('warning: setlocale:')

                # æœ€æ–°10ä»¶ã®å®Ÿè¡Œãƒ­ã‚°ã‚’è§£æ
                recent_sections = sections[-11:-1] if len(sections) > 11 else sections[1:]

                for section in reversed(recent_sections):
                    # æˆåŠŸ/å¤±æ•—ã‚’åˆ¤å®š
                    if 'size=' in section and 'time=' in section:
                        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã¨æ™‚é–“ãŒè¨˜éŒ²ã•ã‚Œã¦ã„ã‚Œã°æˆåŠŸ
                        # ãƒ•ã‚¡ã‚¤ãƒ«åã‚’æŠ½å‡º
                        lines = section.split('\n')
                        filename = 'ä¸æ˜'
                        for line in lines:
                            if '.mp3' in line or '.m4a' in line:
                                # Outputè¡Œã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«åã‚’æŠ½å‡º
                                if 'Output #0' in line or 'to ' in line:
                                    parts = line.split("'")
                                    if len(parts) >= 2:
                                        filename = parts[1].replace('.m4a', '.mp3')
                                        break

                        # ã‚µã‚¤ã‚ºã‚’æŠ½å‡º
                        size_match = section.split('size=')[-1].split()[0] if 'size=' in section else 'ä¸æ˜'

                        summary_logs.append(f'âœ… æˆåŠŸ: {filename} ({size_match})')
                    elif 'Error' in section or 'failed' in section.lower():
                        # ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’æŠ½å‡º
                        error_lines = [l for l in section.split('\n') if 'Error' in l or 'failed' in l.lower()]
                        error_msg = error_lines[0] if error_lines else 'ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ'
                        summary_logs.append(f'âŒ å¤±æ•—: {error_msg[:80]}')

            except Exception as e:
                logger.error(f'Error reading myradiko log: {str(e)}')

        # cronã‚¸ãƒ§ãƒ–ä¸€è¦§ã‚‚è¡¨ç¤º
        try:
            result = subprocess.run(['crontab', '-l'],
                                  capture_output=True,
                                  text=True)
            if result.returncode == 0 and result.stdout.strip():
                summary_logs.insert(0, '=== ç™»éŒ²ã•ã‚Œã¦ã„ã‚‹cronã‚¸ãƒ§ãƒ– ===')
                summary_logs.insert(1, result.stdout.strip())
                summary_logs.insert(2, '')
                summary_logs.insert(3, '=== æœ€è¿‘ã®å®Ÿè¡Œçµæœ ===')
        except Exception as e:
            pass

        if not summary_logs:
            summary_logs = ['ãƒ­ã‚°ãŒã‚ã‚Šã¾ã›ã‚“ã€‚cronãŒå®Ÿè¡Œã•ã‚Œã‚‹ã¨ã“ã“ã«å®Ÿè¡ŒçµæœãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚']

        return jsonify({'logs': summary_logs})

    except Exception as e:
        logger.error(f'Get cron logs error: {str(e)}')
        return jsonify({'error': str(e)}), 500

@app.route('/file/delete', methods=['POST'])
def delete_file():
    """éŒ²éŸ³ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤"""
    try:
        data = request.json
        filepath = data.get('path', '')

        if not filepath:
            return jsonify({'error': 'File path is required'}), 400

        # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£: ãƒ‘ã‚¹ãƒˆãƒ©ãƒãƒ¼ã‚µãƒ«å¯¾ç­–
        base_dir = OUTPUT_DIR
        safe_path = os.path.normpath(os.path.join(base_dir, filepath))

        if not safe_path.startswith(base_dir):
            return jsonify({'error': 'Invalid file path'}), 400

        # ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹å ´åˆã¯ç‰©ç†å‰Šé™¤
        file_existed = os.path.exists(safe_path)
        if file_existed:
            os.remove(safe_path)
            logger.info(f'File deleted: {safe_path}')
        else:
            logger.warning(f'File not found (will delete DB record only): {safe_path}')

        # DBã‹ã‚‰ã‚‚å‰Šé™¤ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªãã¦ã‚‚DBãƒ¬ã‚³ãƒ¼ãƒ‰ã¯å‰Šé™¤ï¼‰
        db.delete_recorded_file(filepath)
        logger.info(f'File deleted from DB: {filepath}')

        message = 'File deleted successfully' if file_existed else 'DB record deleted (file not found)'
        return jsonify({'success': True, 'message': message, 'file_existed': file_existed})

    except Exception as e:
        logger.error(f'Delete file error: {str(e)}')
        return jsonify({'error': str(e)}), 500

@app.route('/files/delete-multiple', methods=['POST'])
def delete_multiple_files():
    """è¤‡æ•°ã®éŒ²éŸ³ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸€æ‹¬å‰Šé™¤"""
    try:
        data = request.json
        filepaths = data.get('paths', [])

        if not filepaths or not isinstance(filepaths, list):
            return jsonify({'error': 'File paths array is required'}), 400

        base_dir = OUTPUT_DIR
        deleted = []
        errors = []

        for filepath in filepaths:
            try:
                # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£: ãƒ‘ã‚¹ãƒˆãƒ©ãƒãƒ¼ã‚µãƒ«å¯¾ç­–
                safe_path = os.path.normpath(os.path.join(base_dir, filepath))

                if not safe_path.startswith(base_dir):
                    errors.append({'path': filepath, 'error': 'Invalid file path'})
                    continue

                # ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹å ´åˆã¯ç‰©ç†å‰Šé™¤
                file_existed = os.path.exists(safe_path)
                if file_existed:
                    os.remove(safe_path)
                    logger.info(f'File deleted: {safe_path}')
                else:
                    logger.warning(f'File not found (will delete DB record only): {safe_path}')

                # DBã‹ã‚‰ã‚‚å‰Šé™¤ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªãã¦ã‚‚DBãƒ¬ã‚³ãƒ¼ãƒ‰ã¯å‰Šé™¤ï¼‰
                db.delete_recorded_file(filepath)
                logger.info(f'File deleted from DB: {filepath}')

                deleted.append(filepath)

            except Exception as e:
                errors.append({'path': filepath, 'error': str(e)})
                logger.error(f'Failed to delete {filepath}: {str(e)}')

        return jsonify({
            'success': True,
            'deleted': deleted,
            'errors': errors,
            'message': f'{len(deleted)} files deleted successfully'
        })

    except Exception as e:
        logger.error(f'Delete multiple files error: {str(e)}')
        return jsonify({'error': str(e)}), 500

@app.route('/files/download-zip', methods=['POST'])
def download_zip():
    """è¤‡æ•°ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ZIPå½¢å¼ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"""
    try:
        data = request.json
        filepaths = data.get('paths', [])

        if not filepaths or not isinstance(filepaths, list):
            return jsonify({'error': 'File paths array is required'}), 400

        base_dir = OUTPUT_DIR

        # ä¸€æ™‚ZIPãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
        temp_zip = tempfile.NamedTemporaryFile(delete=False, suffix='.zip')
        temp_zip_path = temp_zip.name
        temp_zip.close()

        try:
            with zipfile.ZipFile(temp_zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
                added_files = 0
                for filepath in filepaths:
                    try:
                        # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£: ãƒ‘ã‚¹ãƒˆãƒ©ãƒãƒ¼ã‚µãƒ«å¯¾ç­–
                        safe_path = os.path.normpath(os.path.join(base_dir, filepath))

                        if not safe_path.startswith(base_dir):
                            logger.warning(f'Invalid file path: {filepath}')
                            continue

                        if not os.path.exists(safe_path):
                            logger.warning(f'File not found: {filepath}')
                            continue

                        # ZIPã«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¿½åŠ ï¼ˆå…ƒã®ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ä¿æŒï¼‰
                        arcname = os.path.basename(safe_path)
                        zipf.write(safe_path, arcname=arcname)
                        added_files += 1
                        logger.info(f'Added to ZIP: {arcname}')

                    except Exception as e:
                        logger.error(f'Failed to add {filepath} to ZIP: {str(e)}')

            if added_files == 0:
                os.unlink(temp_zip_path)
                return jsonify({'error': 'No valid files found'}), 404

            # ZIPãƒ•ã‚¡ã‚¤ãƒ«ã‚’é€ä¿¡
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            zip_filename = f'radiko_recordings_{timestamp}.zip'

            response = send_file(
                temp_zip_path,
                mimetype='application/zip',
                as_attachment=True,
                download_name=zip_filename
            )

            # é€ä¿¡å¾Œã«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ã™ã‚‹
            @response.call_on_close
            def cleanup():
                try:
                    if os.path.exists(temp_zip_path):
                        os.unlink(temp_zip_path)
                        logger.info(f'Temp ZIP file deleted: {temp_zip_path}')
                except Exception as e:
                    logger.error(f'Failed to delete temp ZIP: {str(e)}')

            return response

        except Exception as e:
            # ã‚¨ãƒ©ãƒ¼æ™‚ã‚‚ZIPãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
            if os.path.exists(temp_zip_path):
                os.unlink(temp_zip_path)
            raise e

    except Exception as e:
        logger.error(f'Download ZIP error: {str(e)}')
        return jsonify({'error': str(e)}), 500

@app.route('/stream/<path:filepath>')
def stream_file(filepath):
    """éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°é…ä¿¡"""
    try:
        # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£: ãƒ‘ã‚¹ãƒˆãƒ©ãƒãƒ¼ã‚µãƒ«å¯¾ç­–
        base_dir = OUTPUT_DIR
        safe_path = os.path.normpath(os.path.join(base_dir, filepath))

        if not safe_path.startswith(base_dir):
            return jsonify({'error': 'Invalid file path'}), 400

        if not os.path.exists(safe_path):
            return jsonify({'error': 'File not found'}), 404

        # ãƒ•ã‚¡ã‚¤ãƒ«ã®æ‹¡å¼µå­ã‚’ç¢ºèª
        ext = os.path.splitext(safe_path)[1].lower()

        # MIMEã‚¿ã‚¤ãƒ—ã‚’è¨­å®š
        mime_types = {
            '.mp3': 'audio/mpeg',
            '.m4a': 'audio/mp4',
            '.aac': 'audio/aac',
            '.wav': 'audio/wav'
        }

        mime_type = mime_types.get(ext, 'application/octet-stream')

        # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°é…ä¿¡ï¼ˆRange Requestå¯¾å¿œï¼‰
        return send_file(
            safe_path,
            mimetype=mime_type,
            as_attachment=False,
            conditional=True  # Range Requestå¯¾å¿œ
        )

    except Exception as e:
        logger.error(f'Stream file error: {str(e)}')
        return jsonify({'error': str(e)}), 500

@app.route('/schedule-at', methods=['POST'])
def schedule_at():
    """DBã«atäºˆç´„ã‚’ä¿å­˜ã—ã¦ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ã«ç™»éŒ²"""
    try:
        data = request.json
        script_path = data.get('script_path', SCRIPT_PATH)
        title = data.get('title', '')        # ç•ªçµ„å
        start_time = data.get('start_time')  # YYYYMMDDHHmmå½¢å¼
        end_time = data.get('end_time')      # YYYYMMDDHHmmå½¢å¼
        station_id = data.get('station_id')
        at_time = data.get('at_time')        # HH:MM YYYY-MM-DDå½¢å¼
        folder = data.get('folder', '')      # ä¿å­˜å…ˆãƒ•ã‚©ãƒ«ãƒ€

        if not all([start_time, end_time, station_id, at_time]):
            return jsonify({'error': 'Missing required parameters'}), 400

        # ã‚¿ã‚¤ãƒˆãƒ«ã‚’ã‚µãƒ‹ã‚¿ã‚¤ã‚ºï¼ˆã‚¹ãƒšãƒ¼ã‚¹ã‚’ã‚¢ãƒ³ãƒ€ãƒ¼ãƒãƒ¼ã«ã€å…¨è§’è¨˜å·ã‚’åŠè§’ã«ï¼‰
        safe_title = sanitize_filename(title)

        # cronã¨åŒã˜å½¢å¼ã®ã‚³ãƒãƒ³ãƒ‰ã‚’ç”Ÿæˆï¼ˆã‚µãƒ‹ã‚¿ã‚¤ã‚ºã—ãŸã‚¿ã‚¤ãƒˆãƒ«ã‚’ä½¿ç”¨ï¼‰
        command = f'{script_path} "{safe_title}" "{station_id}" "{station_id}" "{start_time}" "{end_time}" "" "{folder}" "" >> /tmp/myradiko_output.log 2>&1'

        # at_timeã‚’datetimeã«å¤‰æ› (HH:MM YYYY-MM-DD -> datetime)
        schedule_time_str = f"{at_time.split()[1]} {at_time.split()[0]}"  # YYYY-MM-DD HH:MM
        schedule_time = datetime.strptime(schedule_time_str, '%Y-%m-%d %H:%M')

        # éå»ã®æ™‚åˆ»ãƒã‚§ãƒƒã‚¯
        now = datetime.now()
        if schedule_time < now:
            return jsonify({'error': 'Cannot schedule in the past'}), 400

        # DBã«ä¿å­˜ï¼ˆjob_idã¯è‡ªå‹•ç”Ÿæˆï¼‰
        job_id = db.save_at_job(
            job_id=None,  # Auto-generate
            schedule_time=schedule_time.strftime('%Y-%m-%d %H:%M:%S'),
            command=command,
            title=title,
            station=station_id,
            start_time=start_time,
            end_time=end_time
        )

        if not job_id:
            return jsonify({'error': 'Failed to save at job to database'}), 500

        # metadataã‚’æ§‹ç¯‰
        metadata = {
            'title': title,
            'rss': station_id,
            'station': station_id,
            'start_time': start_time,
            'end_time': end_time
        }

        # ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ã«ç™»éŒ²
        scheduler.add_job(
            func=execute_recording,
            trigger='date',
            run_date=schedule_time,
            args=[command, job_id, 'at', metadata],
            id=f"at_{job_id}",
            replace_existing=True
        )

        logger.info(f'âœ… At job scheduled: {job_id} at {schedule_time}')

        return jsonify({
            'success': True,
            'message': 'atäºˆç´„ã‚’ç™»éŒ²ã—ã¾ã—ãŸ',
            'job_id': job_id,
            'schedule_time': schedule_time.strftime('%Y-%m-%d %H:%M:%S')
        })

    except Exception as e:
        logger.error(f'Schedule at error: {str(e)}')
        return jsonify({'error': str(e)}), 500

@app.route('/at/list', methods=['GET'])
def list_at_jobs():
    """DBã‹ã‚‰atäºˆç´„ä¸€è¦§ã‚’å–å¾—"""
    try:
        jobs_data = db.get_all_at_jobs()

        jobs = []
        for job in jobs_data:
            # schedule_timeã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ (YYYY-MM-DD HH:MM:SS -> ã‚ˆã‚Šèª­ã¿ã‚„ã™ã„å½¢å¼)
            try:
                schedule_dt = datetime.strptime(job['schedule_time'], '%Y-%m-%d %H:%M:%S')
                formatted_datetime = schedule_dt.strftime('%Y/%m/%d %a %H:%M')
            except:
                formatted_datetime = job['schedule_time']

            jobs.append({
                'id': str(job['id']),
                'datetime': formatted_datetime,
                'title': job.get('title', ''),
                'station': job.get('station', ''),
                'schedule_time': job['schedule_time']
            })

        return jsonify({'jobs': jobs})

    except Exception as e:
        logger.error(f'List at jobs error: {str(e)}')
        return jsonify({'error': str(e)}), 500

@app.route('/at/cancel/<job_id>', methods=['DELETE'])
def cancel_at_job(job_id):
    """DBã‹ã‚‰atäºˆç´„ã‚’å‰Šé™¤ã—ã¦ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ã‹ã‚‰ã‚‚å‰Šé™¤"""
    try:
        # ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ã‹ã‚‰å‰Šé™¤
        try:
            scheduler.remove_job(f"at_{job_id}")
            logger.info(f"âœ… At job removed from scheduler: {job_id}")
        except Exception as e:
            logger.warning(f"âš ï¸ Job not found in scheduler (may be already executed or removed): {str(e)}")

        # DBã‹ã‚‰å‰Šé™¤
        if db.delete_at_job(int(job_id)):
            return jsonify({
                'success': True,
                'message': f'atäºˆç´„ #{job_id} ã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã—ã¾ã—ãŸ'
            })
        else:
            return jsonify({'error': 'Failed to delete at job from database'}), 500

    except Exception as e:
        logger.error(f'Cancel at job error: {str(e)}')
        return jsonify({'error': str(e)}), 500

@app.route('/at/detail/<job_id>', methods=['GET'])
def get_at_job_detail(job_id):
    """DBã‹ã‚‰atäºˆç´„ã®è©³ç´°ã‚’å–å¾—"""
    try:
        jobs = db.get_all_at_jobs()

        job_detail = None
        for job in jobs:
            if str(job['id']) == str(job_id):
                job_detail = job
                break

        if not job_detail:
            return jsonify({'error': 'Job not found'}), 404

        return jsonify({
            'command': job_detail['command'],
            'title': job_detail.get('title', ''),
            'station': job_detail.get('station', ''),
            'start_time': job_detail.get('start_time', ''),
            'end_time': job_detail.get('end_time', ''),
            'schedule_time': job_detail['schedule_time']
        })

    except Exception as e:
        logger.error(f'Get at job detail error: {str(e)}')
        return jsonify({'error': str(e)}), 500

# ========================================
# ç•ªçµ„è¡¨DBé–¢é€£API
# ========================================

@app.route('/programs/search', methods=['GET'])
def search_programs_api():
    """ç•ªçµ„ã‚’æ¤œç´¢"""
    try:
        keyword = request.args.get('keyword', '')
        area_id = request.args.get('area_id')
        date_from = request.args.get('date_from')
        date_to = request.args.get('date_to')

        logger.info(f'ğŸ” Search API called with keyword="{keyword}", area_id={area_id}, date_from={date_from}, date_to={date_to}')

        if not keyword:
            return jsonify({'error': 'keyword parameter is required'}), 400

        results = db.search_programs(keyword, area_id, date_from, date_to)
        logger.info(f'ğŸ” Search API returning {len(results)} results')

        return jsonify({
            'success': True,
            'count': len(results),
            'programs': results
        })

    except Exception as e:
        logger.error(f'Search API error: {str(e)}')
        return jsonify({'error': str(e)}), 500


@app.route('/programs/area/<area_id>/date/<date>', methods=['GET'])
def get_area_programs_api(area_id, date):
    """ç‰¹å®šã‚¨ãƒªã‚¢ãƒ»æ—¥ä»˜ã®ç•ªçµ„ã‚’å–å¾—ï¼ˆDBã«ãªã‘ã‚Œã°radiko APIã‹ã‚‰å–å¾—ï¼‰"""
    try:
        # å¼·åˆ¶æ›´æ–°ãƒ•ãƒ©ã‚°
        force_refresh = request.args.get('force', 'false').lower() == 'true'

        programs = db.get_programs_by_area_date(area_id, date)

        # å¼·åˆ¶æ›´æ–° ã¾ãŸã¯ DBã«ãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆã€radiko APIã‹ã‚‰å–å¾—ã—ã¦DBã«ä¿å­˜
        if force_refresh or len(programs) == 0:
            if force_refresh:
                logger.info(f'ğŸ”„ Force refresh for {area_id}/{date}, fetching from radiko API...')
            else:
                logger.info(f'ğŸ“¥ No data in DB for {area_id}/{date}, fetching from radiko API...')

            # radiko APIã‹ã‚‰å–å¾—
            fetched_programs = fetch_programs.fetch_area_programs(area_id, date)

            if fetched_programs:
                # DBã«ä¿å­˜ï¼ˆæ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã¯å‰Šé™¤ã•ã‚Œã‚‹ï¼‰
                db.save_programs(fetched_programs, area_id, date)
                logger.info(f'âœ… Fetched and saved {len(fetched_programs)} programs for {area_id}/{date}')

                # ä¿å­˜ã—ãŸãƒ‡ãƒ¼ã‚¿ã‚’å†å–å¾—ã—ã¦ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
                programs = db.get_programs_by_area_date(area_id, date)
            else:
                logger.warning(f'âš ï¸ No programs found from radiko API for {area_id}/{date}')

        return jsonify({
            'success': True,
            'area_id': area_id,
            'date': date,
            'count': len(programs),
            'programs': programs
        })

    except Exception as e:
        logger.error(f'Get area programs API error: {str(e)}')
        return jsonify({'error': str(e)}), 500


@app.route('/programs/update/status', methods=['GET'])
def get_update_status_api():
    """ç•ªçµ„è¡¨ã®æ›´æ–°ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’å–å¾—"""
    try:
        status = db.get_update_status()
        return jsonify(status)

    except Exception as e:
        logger.error(f'Get update status API error: {str(e)}')
        return jsonify({'error': str(e)}), 500


@app.route('/programs/update/trigger', methods=['POST'])
def trigger_update_api():
    """ç•ªçµ„è¡¨ã®å³æ™‚æ›´æ–°ã‚’ãƒˆãƒªã‚¬ãƒ¼"""
    try:
        logger.info('Manual update triggered via API')

        # ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§å®Ÿè¡Œï¼ˆãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’ãƒ–ãƒ­ãƒƒã‚¯ã—ãªã„ï¼‰
        scheduler.add_job(
            func=fetch_programs.update_all_areas,
            trigger='date',  # å³åº§ã«å®Ÿè¡Œ
            id='manual_update',
            name='Manual update',
            replace_existing=True
        )

        return jsonify({
            'success': True,
            'message': 'Update started in background'
        })

    except Exception as e:
        logger.error(f'Trigger update API error: {str(e)}')
        return jsonify({'error': str(e)}), 500


# ==================== ç®¡ç†ãƒ¡ãƒ‹ãƒ¥ãƒ¼API ====================

@app.route('/admin/update-programs-stream', methods=['GET'])
def admin_update_programs_stream():
    """ç®¡ç†ç”»é¢ã‹ã‚‰ã®ç•ªçµ„è¡¨ä¸€æ‹¬æ›´æ–°ï¼ˆSSEã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ï¼‰"""
    def generate():
        try:
            days = int(request.args.get('days', 3))
            logger.info(f'Admin: manual program update for {days} days (streaming)')

            # é€²æ—æƒ…å ±ã‚’ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°é€ä¿¡
            yield f"data: {json.dumps({'type': 'start', 'message': f'{days}æ—¥åˆ†ã®ç•ªçµ„è¡¨æ›´æ–°ã‚’é–‹å§‹ã—ã¾ã™...'})}\n\n"

            # fetch_programs.pyã®ALL_AREA_IDSã‚’å–å¾—
            from fetch_programs import ALL_AREA_IDS
            from datetime import datetime, timedelta
            import time

            # æ—¥ä»˜ãƒªã‚¹ãƒˆã‚’ç”Ÿæˆï¼ˆä»Šæ—¥ã‹ã‚‰æŒ‡å®šæ—¥æ•°åˆ†ï¼‰
            today = datetime.now()
            if today.hour < 5:
                today = today - timedelta(days=1)

            dates = []
            for i in range(days):
                date = today + timedelta(days=i)
                date_str = date.strftime('%Y%m%d')
                dates.append(date_str)

            total_tasks = len(ALL_AREA_IDS) * len(dates)
            completed = 0
            total_programs = 0
            success_count = 0
            error_count = 0
            warning_count = 0

            yield f"data: {json.dumps({'type': 'info', 'message': f'å…¨{len(ALL_AREA_IDS)}ã‚¨ãƒªã‚¢ Ã— {len(dates)}æ—¥ = {total_tasks}ä»¶ã®å‡¦ç†'})}\n\n"

            # å„ã‚¨ãƒªã‚¢ã‚’å‡¦ç†
            for idx, area_id in enumerate(ALL_AREA_IDS, 1):
                yield f"data: {json.dumps({'type': 'progress', 'area': area_id, 'current': idx, 'total': len(ALL_AREA_IDS)})}\n\n"

                for date in dates:
                    try:
                        programs = fetch_programs.fetch_area_programs(area_id, date)

                        if programs:
                            db.save_programs(programs, area_id, date)
                            total_programs += len(programs)
                            success_count += 1
                            yield f"data: {json.dumps({'type': 'success', 'area': area_id, 'date': date, 'programs': len(programs)})}\n\n"
                        else:
                            warning_count += 1
                            yield f"data: {json.dumps({'type': 'warning', 'area': area_id, 'date': date, 'message': 'No programs found'})}\n\n"

                        completed += 1
                        progress_percent = int((completed / total_tasks) * 100)
                        yield f"data: {json.dumps({'type': 'percent', 'percent': progress_percent, 'completed': completed, 'total': total_tasks, 'success': success_count, 'error': error_count, 'warning': warning_count})}\n\n"

                        time.sleep(0.2)  # ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­–

                    except Exception as e:
                        error_count += 1
                        error_msg = str(e)
                        # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚¨ãƒ©ãƒ¼ã‚’ã‚ã‹ã‚Šã‚„ã™ã
                        if 'timed out' in error_msg or 'timeout' in error_msg.lower():
                            error_msg = 'ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ (radikoã‚µãƒ¼ãƒãƒ¼å¿œç­”ãªã—)'
                        yield f"data: {json.dumps({'type': 'error', 'area': area_id, 'date': date, 'message': error_msg})}\n\n"
                        completed += 1
                        progress_percent = int((completed / total_tasks) * 100)
                        yield f"data: {json.dumps({'type': 'percent', 'percent': progress_percent, 'completed': completed, 'total': total_tasks, 'success': success_count, 'error': error_count, 'warning': warning_count})}\n\n"

            # å¤ã„ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤
            yield f"data: {json.dumps({'type': 'info', 'message': 'å¤ã„ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤ä¸­...'})}\n\n"
            db.cleanup_old_data(days_to_keep=15)

            # å®Œäº†
            yield f"data: {json.dumps({'type': 'complete', 'total_programs': total_programs, 'success': success_count, 'error': error_count, 'warning': warning_count, 'message': 'æ›´æ–°ãŒå®Œäº†ã—ã¾ã—ãŸ'})}\n\n"

        except Exception as e:
            logger.error(f'Admin update programs stream error: {str(e)}')
            yield f"data: {json.dumps({'type': 'error', 'message': str(e)})}\n\n"

    return Response(stream_with_context(generate()), mimetype='text/event-stream')


@app.route('/admin/logs/<log_type>')
def admin_view_logs(log_type):
    """ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¡¨ç¤º"""
    try:
        log_content = ''

        if log_type == 'myradiko':
            # myradikoå®Ÿè¡Œãƒ­ã‚°
            log_path = '/tmp/myradiko_output.log'
            if os.path.exists(log_path):
                with open(log_path, 'r', encoding='utf-8', errors='ignore') as f:
                    lines = f.readlines()
                    # æœ€æ–°500è¡Œã®ã¿
                    log_content = ''.join(lines[-500:])
            else:
                log_content = 'ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“'

        elif log_type == 'docker':
            # Flaskã‚¢ãƒ—ãƒªã®ãƒ­ã‚°ï¼ˆã“ã®ã‚³ãƒ³ãƒ†ãƒŠå†…ã§ã¯å–å¾—ä¸å¯ï¼‰
            log_content = 'Dockerãƒ­ã‚°ã¯ãƒ›ã‚¹ãƒˆå´ã§ `docker-compose logs proxy` ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã¦ç¢ºèªã—ã¦ãã ã•ã„ã€‚\n\n'
            log_content += 'ã‚³ãƒ³ãƒ†ãƒŠå†…ã‹ã‚‰ãƒ›ã‚¹ãƒˆã®Dockerã‚³ãƒãƒ³ãƒ‰ã¯å®Ÿè¡Œã§ãã¾ã›ã‚“ã€‚'

        elif log_type == 'nginx':
            # Nginxãƒ­ã‚°ï¼ˆã“ã®ã‚³ãƒ³ãƒ†ãƒŠå†…ã§ã¯å–å¾—ä¸å¯ï¼‰
            log_content = 'Nginxãƒ­ã‚°ã¯ãƒ›ã‚¹ãƒˆå´ã§ `docker-compose logs web` ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã¦ç¢ºèªã—ã¦ãã ã•ã„ã€‚\n\n'
            log_content += 'ã¾ãŸã¯ã€docker exec ã‚³ãƒãƒ³ãƒ‰ã§webã‚³ãƒ³ãƒ†ãƒŠã«å…¥ã‚Šã€/var/log/nginx/ä»¥ä¸‹ã®ãƒ­ã‚°ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚'

        else:
            return jsonify({'error': 'Invalid log type'}), 400

        return jsonify({
            'success': True,
            'log': log_content
        })

    except Exception as e:
        logger.error(f'Admin view logs error: {str(e)}')
        return jsonify({'error': str(e)}), 500


@app.route('/admin/execute-manual', methods=['POST'])
def admin_execute_manual():
    """æ‰‹å‹•ã§myradikoã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œ"""
    try:
        data = request.json
        script_path = data.get('script_path', SCRIPT_PATH)
        title = data.get('title', '')
        station_id = data.get('station_id')
        start_time = data.get('start_time')
        end_time = data.get('end_time')

        if not all([station_id, start_time, end_time]):
            return jsonify({'error': 'Missing required parameters'}), 400

        # ã‚¿ã‚¤ãƒˆãƒ«ã‚’ã‚µãƒ‹ã‚¿ã‚¤ã‚ºï¼ˆã‚¹ãƒšãƒ¼ã‚¹ã‚’ã‚¢ãƒ³ãƒ€ãƒ¼ãƒãƒ¼ã«ã€å…¨è§’è¨˜å·ã‚’åŠè§’ã«ï¼‰
        safe_title = sanitize_filename(title)

        # ã‚³ãƒãƒ³ãƒ‰ã‚’æ§‹ç¯‰ï¼ˆã‚µãƒ‹ã‚¿ã‚¤ã‚ºã—ãŸã‚¿ã‚¤ãƒˆãƒ«ã‚’ä½¿ç”¨ï¼‰
        command = f'{script_path} "{safe_title}" "{station_id}" "{station_id}" "{start_time}" "{end_time}" "" "" "" >> /tmp/myradiko_output.log 2>&1'

        logger.info(f'Admin: executing manual command: {command}')

        # ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œï¼ˆåŒæœŸå®Ÿè¡Œï¼‰
        result = subprocess.run(
            command,
            shell=True,
            capture_output=True,
            encoding='utf-8',
            errors='replace',  # ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼ã‚’ç½®ãæ›ãˆæ–‡å­—ã§å‡¦ç†
            timeout=600  # 10åˆ†ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
        )

        output = result.stdout + result.stderr

        if result.returncode != 0:
            logger.error(f'Command failed: {output}')
            return jsonify({
                'success': False,
                'error': 'ã‚³ãƒãƒ³ãƒ‰å®Ÿè¡Œã«å¤±æ•—ã—ã¾ã—ãŸ',
                'output': output
            }), 500

        logger.info(f'Command executed successfully: {output}')

        return jsonify({
            'success': True,
            'message': 'ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã¾ã—ãŸ',
            'output': output
        })

    except subprocess.TimeoutExpired:
        return jsonify({'error': 'ã‚³ãƒãƒ³ãƒ‰ãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸï¼ˆ10åˆ†ä»¥ä¸Šï¼‰'}), 500
    except Exception as e:
        logger.error(f'Admin execute manual error: {str(e)}')
        return jsonify({'error': str(e)}), 500


@app.route('/admin/cleanup', methods=['POST'])
def admin_cleanup():
    """å¤ã„DBãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤"""
    try:
        deleted = db.cleanup_old_data(days_to_keep=15)

        return jsonify({
            'success': True,
            'message': 'å¤ã„ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤ã—ã¾ã—ãŸ',
            'deleted': deleted
        })

    except Exception as e:
        logger.error(f'Admin cleanup error: {str(e)}')
        return jsonify({'error': str(e)}), 500


@app.route('/admin/disk-space')
def admin_disk_space():
    """ãƒ‡ã‚£ã‚¹ã‚¯å®¹é‡ã‚’ç¢ºèª"""
    try:
        # dfã‚³ãƒãƒ³ãƒ‰ã§ãƒ‡ã‚£ã‚¹ã‚¯å®¹é‡ã‚’å–å¾—
        result = subprocess.run(
            ['df', '-h', BASE_DIR],
            capture_output=True,
            text=True,
            timeout=5
        )

        return jsonify({
            'success': True,
            'info': result.stdout
        })

    except Exception as e:
        logger.error(f'Admin disk space error: {str(e)}')
        return jsonify({'error': str(e)}), 500


@app.route('/admin/db-status')
def admin_db_status():
    """DBçµ±è¨ˆæƒ…å ±ã‚’å–å¾—"""
    try:
        import sqlite3

        conn = sqlite3.connect(db.DB_PATH)
        cursor = conn.cursor()

        # ç·ç•ªçµ„æ•°
        cursor.execute('SELECT COUNT(*) FROM programs')
        total_programs = cursor.fetchone()[0]

        # æ›´æ–°å±¥æ­´æ•°
        cursor.execute('SELECT COUNT(*) FROM update_log')
        total_updates = cursor.fetchone()[0]

        # DBãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º
        db_size = os.path.getsize(db.DB_PATH)
        db_size_mb = round(db_size / 1024 / 1024, 2)

        conn.close()

        return jsonify({
            'success': True,
            'total_programs': total_programs,
            'total_updates': total_updates,
            'db_size': f'{db_size_mb} MB'
        })

    except Exception as e:
        logger.error(f'Admin DB status error: {str(e)}')
        return jsonify({'error': str(e)}), 500

@app.route('/admin/cleanup-orphaned-records', methods=['POST'])
def cleanup_orphaned_records():
    """ç‰©ç†ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„DBãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’å‰Šé™¤"""
    try:
        import sqlite3

        conn = sqlite3.connect(db.DB_PATH)
        cursor = conn.cursor()

        # å…¨ã¦ã®éŒ²éŸ³ãƒ•ã‚¡ã‚¤ãƒ«ãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’å–å¾—
        cursor.execute('SELECT id, file_path FROM recorded_files')
        all_records = cursor.fetchall()

        orphaned = []
        cleaned = []

        for record_id, file_path in all_records:
            if not file_path:
                continue

            full_path = os.path.join(OUTPUT_DIR, file_path)

            # ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„å ´åˆ
            if not os.path.exists(full_path):
                orphaned.append({
                    'id': record_id,
                    'path': file_path
                })

                # DBã‹ã‚‰å‰Šé™¤
                cursor.execute('DELETE FROM recorded_files WHERE id = ?', (record_id,))
                cleaned.append(file_path)
                logger.info(f'Orphaned record cleaned: {file_path}')

        conn.commit()
        conn.close()

        return jsonify({
            'success': True,
            'orphaned_count': len(orphaned),
            'cleaned': cleaned,
            'message': f'{len(cleaned)} orphaned records cleaned'
        })

    except Exception as e:
        logger.error(f'Cleanup orphaned records error: {str(e)}')
        return jsonify({'error': str(e)}), 500


# ========================================
# ã‚¢ãƒ¼ãƒˆãƒ¯ãƒ¼ã‚¯ç®¡ç†API
# ========================================

@app.route('/artwork/upload', methods=['POST'])
def upload_artwork():
    """ã‚¢ãƒ¼ãƒˆãƒ¯ãƒ¼ã‚¯ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰"""
    try:
        if 'file' not in request.files:
            return jsonify({'error': 'No file provided'}), 400

        if 'title' not in request.form:
            return jsonify({'error': 'No title provided'}), 400

        file = request.files['file']
        title = request.form['title']
        artist = request.form.get('artist', '')  # ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆåï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰

        if file.filename == '':
            return jsonify({'error': 'No file selected'}), 400

        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚¿ã‚¤ãƒ—ãƒã‚§ãƒƒã‚¯
        allowed_types = ['image/jpeg', 'image/jpg', 'image/png', 'image/gif', 'image/webp']
        mime_type = file.content_type

        if mime_type not in allowed_types:
            return jsonify({'error': f'Invalid file type: {mime_type}'}), 400

        # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
        image_data = file.read()

        # DBã«ä¿å­˜
        success = db.save_artwork(title, image_data, mime_type)

        if not success:
            return jsonify({'error': 'Failed to save artwork'}), 500

        # è©²å½“ã™ã‚‹ç•ªçµ„ã‚¿ã‚¤ãƒˆãƒ«ã®MP3ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢ã—ã¦ã‚¢ãƒ¼ãƒˆãƒ¯ãƒ¼ã‚¯ã‚’åŸ‹ã‚è¾¼ã‚€
        embedded_count = 0
        failed_count = 0

        # ç•ªçµ„ã‚¿ã‚¤ãƒˆãƒ«ã‹ã‚‰æŠ½å‡ºã—ãŸåå‰ã§ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢
        program_title_pattern = title.replace('_', ' ')  # ã‚¢ãƒ³ãƒ€ãƒ¼ãƒãƒ¼ã‚’ã‚¹ãƒšãƒ¼ã‚¹ã«æˆ»ã™

        for root, dirs, files in os.walk(OUTPUT_DIR):
            for filename in files:
                if filename.endswith('.mp3'):
                    # ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰ç•ªçµ„åã‚’æŠ½å‡º
                    name_without_ext = filename.replace('.mp3', '')
                    # æ—¥ä»˜éƒ¨åˆ†ã‚’å‰Šé™¤
                    import re
                    file_program_name = re.sub(r'\(\d{4}\.\d{2}\.\d{2}\)$', '', name_without_ext).strip()

                    # ç•ªçµ„ã‚¿ã‚¤ãƒˆãƒ«ã¨ãƒãƒƒãƒã™ã‚‹ã‹ç¢ºèª
                    if file_program_name == title or file_program_name == program_title_pattern:
                        file_path = os.path.join(root, filename)
                        logger.info(f'Embedding artwork to: {file_path}')

                        if embed_artwork_to_mp3(file_path, image_data, mime_type, title=title, artist=artist if artist else None):
                            embedded_count += 1
                        else:
                            failed_count += 1

        logger.info(f'Artwork embedded: {embedded_count} files, failed: {failed_count} files')

        return jsonify({
            'success': True,
            'message': f'Artwork uploaded for: {title}',
            'embedded': embedded_count,
            'failed': failed_count
        })

    except Exception as e:
        logger.error(f'Upload artwork error: {str(e)}')
        return jsonify({'error': str(e)}), 500


@app.route('/artwork/<path:title>', methods=['GET'])
def get_artwork(title):
    """ã‚¿ã‚¤ãƒˆãƒ«ã«å¯¾å¿œã™ã‚‹ã‚¢ãƒ¼ãƒˆãƒ¯ãƒ¼ã‚¯ã‚’å–å¾—"""
    try:
        artwork = db.get_artwork(title)

        if artwork:
            from io import BytesIO
            return send_file(
                BytesIO(artwork['image_data']),
                mimetype=artwork['mime_type'],
                as_attachment=False
            )
        else:
            # ã‚¢ãƒ¼ãƒˆãƒ¯ãƒ¼ã‚¯ãŒç™»éŒ²ã•ã‚Œã¦ã„ãªã„å ´åˆã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ(__DEFAULT__)ã‚’è¿”ã™
            default_artwork = db.get_artwork('__DEFAULT__')
            if default_artwork:
                from io import BytesIO
                return send_file(
                    BytesIO(default_artwork['image_data']),
                    mimetype=default_artwork['mime_type'],
                    as_attachment=False
                )
            else:
                # __DEFAULT__ã‚‚å­˜åœ¨ã—ãªã„å ´åˆï¼ˆèµ·å‹•ç›´å¾Œãªã©ï¼‰ã¯ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰è¿”ã™
                return send_file('img/jacket.png', mimetype='image/png')

    except Exception as e:
        logger.error(f'Get artwork error: {str(e)}')
        return jsonify({'error': str(e)}), 500


@app.route('/artwork/list', methods=['GET'])
def list_artworks():
    """ç™»éŒ²ã•ã‚Œã¦ã„ã‚‹ã‚¢ãƒ¼ãƒˆãƒ¯ãƒ¼ã‚¯ä¸€è¦§ã‚’å–å¾—"""
    try:
        artworks = db.list_artworks()
        return jsonify({'success': True, 'artworks': artworks})

    except Exception as e:
        logger.error(f'List artworks error: {str(e)}')
        return jsonify({'error': str(e)}), 500


@app.route('/artwork/delete', methods=['POST'])
def delete_artwork():
    """ã‚¢ãƒ¼ãƒˆãƒ¯ãƒ¼ã‚¯ã‚’å‰Šé™¤"""
    try:
        data = request.json
        title = data.get('title')

        if not title:
            return jsonify({'error': 'No title provided'}), 400

        success = db.delete_artwork(title)

        if success:
            return jsonify({'success': True, 'message': f'Artwork deleted for: {title}'})
        else:
            return jsonify({'error': 'Artwork not found'}), 404

    except Exception as e:
        logger.error(f'Delete artwork error: {str(e)}')
        return jsonify({'error': str(e)}), 500


@app.route('/admin/batch-update-metadata', methods=['POST'])
def batch_update_metadata():
    """ã™ã¹ã¦ã®éŒ²éŸ³ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ä¸€æ‹¬æ›´æ–°"""
    try:
        # DBã‹ã‚‰å…¨ã¦ã®éŒ²éŸ³ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—
        import sqlite3
        conn = sqlite3.connect(db.DB_PATH)
        cursor = conn.cursor()

        cursor.execute('''
            SELECT file_path, program_title, station_name
            FROM recorded_files
            WHERE file_path IS NOT NULL
        ''')

        files = cursor.fetchall()
        conn.close()

        processed = 0
        success_count = 0
        failed_count = 0
        skipped_count = 0
        results = []

        for file_path, program_title, station_name in files:
            processed += 1
            full_path = os.path.join(OUTPUT_DIR, file_path)

            # ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
            if not os.path.exists(full_path):
                skipped_count += 1
                results.append({
                    'file': file_path,
                    'success': False,
                    'message': 'File not found'
                })
                continue

            # MP3ãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿å‡¦ç†
            if not full_path.endswith('.mp3'):
                skipped_count += 1
                results.append({
                    'file': file_path,
                    'success': False,
                    'message': 'Not an MP3 file'
                })
                continue

            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’åŸ‹ã‚è¾¼ã‚€
            result = embed_metadata_after_recording(
                full_path,
                program_title or '',
                station_name or ''
            )

            if result:
                success_count += 1
                results.append({
                    'file': file_path,
                    'success': True,
                    'message': 'Metadata updated'
                })
            else:
                failed_count += 1
                results.append({
                    'file': file_path,
                    'success': False,
                    'message': 'Failed to update metadata'
                })

        logger.info(f'Batch metadata update: processed={processed}, success={success_count}, failed={failed_count}, skipped={skipped_count}')

        return jsonify({
            'success': True,
            'processed': processed,
            'success_count': success_count,
            'failed_count': failed_count,
            'skipped_count': skipped_count,
            'results': results
        })

    except Exception as e:
        logger.error(f'Batch update metadata error: {str(e)}')
        return jsonify({'error': str(e)}), 500


def extract_metadata_from_filename(filename, filepath):
    """ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º

    æƒ³å®šãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ: ç•ªçµ„å(YYYY.MM.DD).mp3 ã¾ãŸã¯ ç•ªçµ„å_å±€_èª¬æ˜(YYYY.MM.DD).mp3
    filepathä¾‹: JOAK-FM/ç•ªçµ„å(2025.10.29).mp3
    """
    import re
    from datetime import datetime as dt

    # å±€IDã‚’ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‹ã‚‰æŠ½å‡º
    station_id = None
    if '/' in filepath:
        station_id = filepath.split('/')[0]

    # æ‹¡å¼µå­ã‚’é™¤å»
    name_without_ext = filename.replace('.mp3', '').replace('.m4a', '').replace('.aac', '')

    # æ”¾é€æ—¥ã‚’æŠ½å‡º: (YYYY.MM.DD) ã¾ãŸã¯ (YYYY-MM-DD) ã¾ãŸã¯ _YYYY-MM-DD
    date_pattern = r'[\(\_](\d{4})[\.\-](\d{2})[\.\-](\d{2})[\)\_]?'
    date_match = re.search(date_pattern, name_without_ext)

    broadcast_date = None
    if date_match:
        year, month, day = date_match.groups()
        broadcast_date = f'{year}-{month}-{day}'
        # æ—¥ä»˜éƒ¨åˆ†ã‚’é™¤å»ã—ã¦ç•ªçµ„ã‚¿ã‚¤ãƒˆãƒ«ã‚’æŠ½å‡º
        program_title = re.sub(date_pattern, '', name_without_ext).strip('_- ')
    else:
        program_title = name_without_ext

    return {
        'program_title': program_title,
        'station_id': station_id,
        'broadcast_date': broadcast_date
    }


@app.route('/files/scan', methods=['POST'])
def scan_and_register_files():
    """æ—¢å­˜ã®éŒ²éŸ³ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¹ã‚­ãƒ£ãƒ³ã—ã¦DBã«ç™»éŒ²"""
    from datetime import datetime

    try:
        base_dir = OUTPUT_DIR
        registered = 0
        updated = 0
        errors = []

        if not os.path.exists(base_dir):
            return jsonify({'error': 'Output directory not found'}), 404

        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ ã‚’ã‚¹ã‚­ãƒ£ãƒ³
        for root, dirs, filenames in os.walk(base_dir):
            for filename in filenames:
                if filename.endswith(('.mp3', '.m4a', '.aac')):
                    try:
                        full_path = os.path.join(root, filename)
                        relative_path = os.path.relpath(full_path, base_dir)
                        file_stat = os.stat(full_path)

                        # ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
                        metadata = extract_metadata_from_filename(filename, relative_path)

                        # DBã«ç™»éŒ²
                        file_id = db.register_recorded_file(
                            file_path=relative_path,
                            file_name=filename,
                            program_title=metadata['program_title'],
                            station_id=metadata['station_id'],
                            station_name=None,  # å¾Œã§è¿½åŠ å¯èƒ½
                            broadcast_date=metadata['broadcast_date'],
                            start_time=None,
                            end_time=None,
                            file_size=file_stat.st_size,
                            duration=None,  # å¾Œã§è¿½åŠ å¯èƒ½
                            file_modified=datetime.fromtimestamp(file_stat.st_mtime).isoformat()
                        )

                        if file_id:
                            # æ—¢å­˜ãƒ¬ã‚³ãƒ¼ãƒ‰ã®æ›´æ–°ã‹æ–°è¦ç™»éŒ²ã‹ã‚’åˆ¤å®š
                            existing = db.get_recorded_file_by_path(relative_path)
                            if existing and existing['id'] != file_id:
                                updated += 1
                            else:
                                registered += 1

                    except Exception as e:
                        errors.append({'file': filename, 'error': str(e)})
                        logger.error(f'Failed to register file {filename}: {str(e)}')

        return jsonify({
            'success': True,
            'registered': registered,
            'updated': updated,
            'total': registered + updated,
            'errors': errors
        })

    except Exception as e:
        logger.error(f'Scan files error: {str(e)}')
        return jsonify({'error': str(e)}), 500


# ========================================
# ä»®æƒ³ãƒ•ã‚©ãƒ«ãƒ€ç®¡ç†API
# ========================================

@app.route('/folders', methods=['GET'])
def list_folders():
    """ä»®æƒ³ãƒ•ã‚©ãƒ«ãƒ€ä¸€è¦§ã‚’å–å¾—"""
    try:
        folders = db.get_all_virtual_folders()
        return jsonify({'success': True, 'folders': folders})
    except Exception as e:
        logger.error(f'List folders error: {str(e)}')
        return jsonify({'error': str(e)}), 500


@app.route('/folders', methods=['POST'])
def create_folder():
    """ä»®æƒ³ãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½œæˆ"""
    try:
        data = request.json
        name = data.get('name')
        if not name:
            return jsonify({'error': 'ãƒ•ã‚©ãƒ«ãƒ€åãŒå¿…è¦ã§ã™'}), 400

        parent_id = data.get('parent_id')
        color = data.get('color')
        icon = data.get('icon')

        folder_id = db.create_virtual_folder(name, parent_id, color, icon)
        return jsonify({'success': True, 'folder_id': folder_id})
    except Exception as e:
        logger.error(f'Create folder error: {str(e)}')
        return jsonify({'error': str(e)}), 500


@app.route('/folders/<int:folder_id>', methods=['PUT'])
def update_folder(folder_id):
    """ä»®æƒ³ãƒ•ã‚©ãƒ«ãƒ€ã‚’æ›´æ–°"""
    try:
        data = request.json
        success = db.update_virtual_folder(
            folder_id,
            name=data.get('name'),
            color=data.get('color'),
            icon=data.get('icon'),
            parent_id=data.get('parent_id')
        )
        return jsonify({'success': success})
    except Exception as e:
        logger.error(f'Update folder error: {str(e)}')
        return jsonify({'error': str(e)}), 500


@app.route('/folders/<int:folder_id>', methods=['DELETE'])
def delete_folder(folder_id):
    """ä»®æƒ³ãƒ•ã‚©ãƒ«ãƒ€ã‚’å‰Šé™¤"""
    try:
        success = db.delete_virtual_folder(folder_id)
        return jsonify({'success': success})
    except Exception as e:
        logger.error(f'Delete folder error: {str(e)}')
        return jsonify({'error': str(e)}), 500


@app.route('/files/move', methods=['POST'])
def move_file():
    """ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä»®æƒ³ãƒ•ã‚©ãƒ«ãƒ€ã«ç§»å‹•"""
    try:
        data = request.json
        file_path = data.get('file_path')
        folder_id = data.get('folder_id')

        if not file_path:
            return jsonify({'error': 'ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ãŒå¿…è¦ã§ã™'}), 400

        success = db.move_file_to_folder(file_path, folder_id)
        return jsonify({'success': success})
    except Exception as e:
        logger.error(f'Move file error: {str(e)}')
        return jsonify({'error': str(e)}), 500


@app.route('/folders/<int:folder_id>/files', methods=['GET'])
def get_folder_files(folder_id):
    """ä»®æƒ³ãƒ•ã‚©ãƒ«ãƒ€å†…ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—"""
    try:
        page = request.args.get('page', 1, type=int)
        limit = request.args.get('limit', 1000, type=int)
        offset = (page - 1) * limit

        files = db.get_files_in_folder(folder_id, limit, offset)
        return jsonify({'success': True, 'files': files})
    except Exception as e:
        logger.error(f'Get folder files error: {str(e)}')
        return jsonify({'error': str(e)}), 500


if __name__ == '__main__':
    # é–‹ç™ºç’°å¢ƒç”¨ï¼ˆæœ¬ç•ªã§ã¯gunicornã‚’ä½¿ç”¨ï¼‰
    app.run(host='0.0.0.0', port=8080, debug=False, threaded=True)
