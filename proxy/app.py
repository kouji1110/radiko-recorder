from flask import Flask, Response, request, jsonify, stream_with_context, send_file
import requests
from flask_cors import CORS
import logging
import subprocess
import json
import os
from datetime import datetime
from apscheduler.schedulers.background import BackgroundScheduler
import atexit
import zipfile
import tempfile

# DBãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
import db
import fetch_programs

app = Flask(__name__)
app.config['JSON_AS_ASCII'] = False  # æ—¥æœ¬èªãªã©ã®éASCIIæ–‡å­—ã‚’ãã®ã¾ã¾å‡ºåŠ›
CORS(app, resources={r"/*": {"origins": "*"}})

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ãƒ‘ã‚¹è¨­å®šï¼ˆDockerç’°å¢ƒç”¨ï¼‰
BASE_DIR = os.environ.get('BASE_DIR', '/app')
SCRIPT_PATH = os.path.join(BASE_DIR, 'script/myradiko')
OUTPUT_DIR = os.path.join(BASE_DIR, 'output/radio')

# ãƒ•ã‚¡ã‚¤ãƒ«åã‚µãƒ‹ã‚¿ã‚¤ã‚ºé–¢æ•°
def sanitize_filename(title):
    """ç•ªçµ„åã‚’ãƒ•ã‚¡ã‚¤ãƒ«åã¨ã—ã¦å®‰å…¨ãªå½¢å¼ã«å¤‰æ›

    - åŠè§’ã‚¹ãƒšãƒ¼ã‚¹ãƒ»å…¨è§’ã‚¹ãƒšãƒ¼ã‚¹ã‚’ã‚¢ãƒ³ãƒ€ãƒ¼ãƒãƒ¼ã«
    - å…¨è§’æ–‡å­—ã‚’åŠè§’ã«å¤‰æ›
    - å…¨è§’æ•°å­—ãƒ»è‹±å­—ã‚’åŠè§’ã«
    """
    if not title:
        return title

    # ã‚¹ãƒšãƒ¼ã‚¹ã‚’ã‚¢ãƒ³ãƒ€ãƒ¼ãƒãƒ¼ã«
    title = title.replace(' ', '_')
    title = title.replace('ã€€', '_')

    # å…¨è§’è‹±æ•°å­—ã‚’åŠè§’ã«
    full_to_half = str.maketrans(
        'ï¼¡ï¼¢ï¼£ï¼¤ï¼¥ï¼¦ï¼§ï¼¨ï¼©ï¼ªï¼«ï¼¬ï¼­ï¼®ï¼¯ï¼°ï¼±ï¼²ï¼³ï¼´ï¼µï¼¶ï¼·ï¼¸ï¼¹ï¼ºï½ï½‚ï½ƒï½„ï½…ï½†ï½‡ï½ˆï½‰ï½Šï½‹ï½Œï½ï½ï½ï½ï½‘ï½’ï½“ï½”ï½•ï½–ï½—ï½˜ï½™ï½šï¼ï¼‘ï¼’ï¼“ï¼”ï¼•ï¼–ï¼—ï¼˜ï¼™',
        'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789'
    )
    title = title.translate(full_to_half)

    # å…¨è§’æ‹¬å¼§ãƒ»è¨˜å·ã‚’åŠè§’ã«
    replacements = {
        'ï¼ˆ': '(',
        'ï¼‰': ')',
        'ã€Œ': '[',
        'ã€': ']',
        'ï¼š': ':',
        'ï¼': '!',
        'ï¼Ÿ': '?',
        'ï¼»': '[',
        'ï¼½': ']',
        'ã€': '[',
        'ã€‘': ']'
    }

    for old, new in replacements.items():
        title = title.replace(old, new)

    return title

# DBåˆæœŸåŒ–
db.init_database()

# ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼è¨­å®šï¼ˆæ·±å¤œ3æ™‚ã«å®Ÿè¡Œï¼‰
scheduler = BackgroundScheduler(daemon=True, timezone='Asia/Tokyo')
scheduler.add_job(
    func=fetch_programs.update_all_areas,
    trigger='cron',
    hour=3,  # æ¯æ—¥3:00AMã«å®Ÿè¡Œ
    minute=0,
    id='update_programs',
    name='Update radiko programs daily at 3:00 AM',
    replace_existing=True
)
scheduler.start()

# ã‚¢ãƒ—ãƒªçµ‚äº†æ™‚ã«ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ã‚’ã‚·ãƒ£ãƒƒãƒˆãƒ€ã‚¦ãƒ³
atexit.register(lambda: scheduler.shutdown())

logger.info('âœ… Scheduler started: updating programs daily at 3:00 AM JST')

@app.route('/health')
def health():
    """ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯"""
    return {'status': 'ok'}, 200

@app.route('/radiko/<path:path>')
def proxy(path):
    """radikoã¸ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’ãƒ—ãƒ­ã‚­ã‚·ã™ã‚‹"""
    url = f'http://radiko.jp/{path}'
    logger.info(f'Proxying request to: {url}')

    try:
        resp = requests.get(
            url,
            timeout=30,
            headers={
                'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36'
            }
        )

        return Response(
            resp.content,
            status=resp.status_code,
            content_type=resp.headers.get('content-type', 'text/xml'),
            headers={
                'Cache-Control': 'no-cache, no-store, must-revalidate',
                'Pragma': 'no-cache',
                'Expires': '0'
            }
        )
    except requests.RequestException as e:
        logger.error(f'Error proxying request: {str(e)}')
        return Response(
            f'Error: {str(e)}',
            status=500,
            content_type='text/plain'
        )

@app.route('/execute', methods=['POST', 'OPTIONS'])
def execute_recording():
    """éŒ²éŸ³ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã¦ãƒ­ã‚°ã‚’ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°"""
    # OPTIONSãƒªã‚¯ã‚¨ã‚¹ãƒˆï¼ˆCORS preflightï¼‰ã¸ã®å¯¾å¿œ
    if request.method == 'OPTIONS':
        response = Response()
        response.headers['Access-Control-Allow-Origin'] = '*'
        response.headers['Access-Control-Allow-Methods'] = 'POST, OPTIONS'
        response.headers['Access-Control-Allow-Headers'] = 'Content-Type'
        return response

    data = request.json
    title = data.get('title', '')
    rss = data.get('rss', '')
    station = data.get('station', '')
    start_time = data.get('start_time', '')
    end_time = data.get('end_time', '')

    # ã‚¿ã‚¤ãƒˆãƒ«ã‚’ã‚µãƒ‹ã‚¿ã‚¤ã‚ºï¼ˆã‚¹ãƒšãƒ¼ã‚¹ã‚’ã‚¢ãƒ³ãƒ€ãƒ¼ãƒãƒ¼ã«ã€å…¨è§’è¨˜å·ã‚’åŠè§’ã«ï¼‰
    safe_title = sanitize_filename(title)

    # ãƒ‡ãƒãƒƒã‚°ç”¨ãƒ­ã‚°
    logger.info(f'Original title: {title}')
    logger.info(f'Sanitized title: {safe_title}')

    def generate_log():
        """ãƒ­ã‚°ã‚’ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã§è¿”ã™"""
        timestamp = datetime.now().strftime('%Y/%m/%d %H:%M:%S')

        # é–‹å§‹ãƒ­ã‚°
        yield f'data: {json.dumps({"type": "log", "message": f"[{timestamp}] ã‚³ãƒãƒ³ãƒ‰å®Ÿè¡Œé–‹å§‹..."})}\n\n'
        yield f'data: {json.dumps({"type": "log", "message": f"[{timestamp}] å…ƒã®ã‚¿ã‚¤ãƒˆãƒ«: {title}"})}\n\n'
        yield f'data: {json.dumps({"type": "log", "message": f"[{timestamp}] ã‚µãƒ‹ã‚¿ã‚¤ã‚ºå¾Œ: {safe_title}"})}\n\n'

        # myradikoã‚¹ã‚¯ãƒªãƒ—ãƒˆã®ãƒ‘ã‚¹
        script_path = SCRIPT_PATH

        # ã‚³ãƒãƒ³ãƒ‰æ§‹ç¯‰ï¼ˆã‚µãƒ‹ã‚¿ã‚¤ã‚ºã—ãŸã‚¿ã‚¤ãƒˆãƒ«ã‚’ä½¿ç”¨ï¼‰
        cmd = [
            script_path,
            safe_title,
            rss,
            station,
            start_time,
            end_time,
            '',  # SKIP
            '',  # DIR
            ''   # MAIL
        ]

        cmd_str = ' '.join([f'"{arg}"' if ' ' in arg else arg for arg in cmd])
        timestamp = datetime.now().strftime('%Y/%m/%d %H:%M:%S')
        yield f'data: {json.dumps({"type": "log", "message": f"[{timestamp}] {cmd_str}"})}\n\n'

        try:
            # ãƒ—ãƒ­ã‚»ã‚¹ã‚’èµ·å‹•
            process = subprocess.Popen(
                cmd,
                stdout=subprocess.PIPE,
                stderr=subprocess.STDOUT,
                encoding='utf-8',
                errors='replace',  # ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼ã‚’ç½®ãæ›ãˆæ–‡å­—ã§å‡¦ç†
                bufsize=1
            )

            # å‡ºåŠ›ã‚’é€æ¬¡é€ä¿¡
            for line in process.stdout:
                line = line.rstrip()
                if line:
                    timestamp = datetime.now().strftime('%Y/%m/%d %H:%M:%S')
                    yield f'data: {json.dumps({"type": "log", "message": f"[{timestamp}] {line}"})}\n\n'

            # ãƒ—ãƒ­ã‚»ã‚¹ã®çµ‚äº†ã‚’å¾…ã¤
            process.wait()

            timestamp = datetime.now().strftime('%Y/%m/%d %H:%M:%S')
            if process.returncode == 0:
                # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’æ§‹ç¯‰ï¼ˆã‚µãƒ‹ã‚¿ã‚¤ã‚ºã—ãŸã‚¿ã‚¤ãƒˆãƒ«ã‚’ä½¿ç”¨ï¼‰
                output_dir = os.path.join(OUTPUT_DIR, rss)
                filename = f'{safe_title}({start_time[:4]}.{start_time[4:6]}.{start_time[6:8]}).mp3'
                file_path = os.path.join(output_dir, filename)

                # ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèª
                if os.path.exists(file_path):
                    # ç›¸å¯¾ãƒ‘ã‚¹ã‚’ç”Ÿæˆï¼ˆãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰URLç”¨ï¼‰
                    relative_path = f'{rss}/{filename}'
                    yield f'data: {json.dumps({"type": "success", "message": f"[{timestamp}] å®Ÿè¡Œå®Œäº†ï¼", "file": relative_path})}\n\n'
                else:
                    yield f'data: {json.dumps({"type": "success", "message": f"[{timestamp}] å®Ÿè¡Œå®Œäº†ï¼ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ï¼‰"})}\n\n'
            else:
                yield f'data: {json.dumps({"type": "error", "message": f"[{timestamp}] ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ (çµ‚äº†ã‚³ãƒ¼ãƒ‰: {process.returncode})"})}\n\n'

        except Exception as e:
            timestamp = datetime.now().strftime('%Y/%m/%d %H:%M:%S')
            yield f'data: {json.dumps({"type": "error", "message": f"[{timestamp}] ã‚¨ãƒ©ãƒ¼: {str(e)}"})}\n\n'

    return Response(
        stream_with_context(generate_log()),
        mimetype='text/event-stream',
        headers={
            'Cache-Control': 'no-cache',
            'X-Accel-Buffering': 'no'
        }
    )

@app.route('/download/<path:filepath>')
def download_file(filepath):
    """éŒ²éŸ³ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"""
    try:
        # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£: ãƒ‘ã‚¹ãƒˆãƒ©ãƒãƒ¼ã‚µãƒ«å¯¾ç­–
        base_dir = OUTPUT_DIR
        safe_path = os.path.normpath(os.path.join(base_dir, filepath))

        if not safe_path.startswith(base_dir):
            return Response('Invalid file path', status=400)

        if not os.path.exists(safe_path):
            return Response('File not found', status=404)

        return send_file(
            safe_path,
            as_attachment=True,
            download_name=os.path.basename(safe_path)
        )
    except Exception as e:
        logger.error(f'Download error: {str(e)}')
        return Response(f'Error: {str(e)}', status=500)

@app.route('/files', methods=['GET'])
def list_files():
    """éŒ²éŸ³æ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã‚’å–å¾—"""
    try:
        base_dir = OUTPUT_DIR
        files = []

        if not os.path.exists(base_dir):
            return jsonify({'files': []})

        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å†å¸°çš„ã«æ¢ç´¢
        for root, dirs, filenames in os.walk(base_dir):
            for filename in filenames:
                if filename.endswith('.mp3'):
                    full_path = os.path.join(root, filename)
                    relative_path = os.path.relpath(full_path, base_dir)
                    file_stat = os.stat(full_path)

                    files.append({
                        'path': relative_path,
                        'name': filename,
                        'size': file_stat.st_size,
                        'modified': file_stat.st_mtime
                    })

        # æ›´æ–°æ—¥æ™‚ã§ã‚½ãƒ¼ãƒˆï¼ˆæ–°ã—ã„é †ï¼‰
        files.sort(key=lambda x: x['modified'], reverse=True)

        return jsonify({'files': files})
    except Exception as e:
        logger.error(f'List files error: {str(e)}')
        return jsonify({'error': str(e)}), 500

@app.route('/check-file', methods=['POST'])
def check_file_exists():
    """ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ãƒã‚§ãƒƒã‚¯"""
    try:
        data = request.json
        title = data.get('title', '')
        rss = data.get('rss', '')
        start_time = data.get('start_time', '')

        # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’æ§‹ç¯‰
        output_dir = os.path.join(OUTPUT_DIR, rss)
        filename = f'{title}({start_time[:4]}.{start_time[4:6]}.{start_time[6:8]}).mp3'
        file_path = os.path.join(output_dir, filename)

        exists = os.path.exists(file_path)
        relative_path = f'{rss}/{filename}' if exists else None

        return jsonify({
            'exists': exists,
            'path': relative_path,
            'filename': filename
        })
    except Exception as e:
        logger.error(f'Check file error: {str(e)}')
        return jsonify({'error': str(e)}), 500

@app.route('/cron/list', methods=['GET'])
def list_cron():
    """ç¾åœ¨ã®crontabã‚’å–å¾—ã—ã¦ãƒ‘ãƒ¼ã‚¹"""
    try:
        result = subprocess.run(['crontab', '-l'],
                              capture_output=True,
                              text=True)

        if result.returncode == 0:
            lines = result.stdout.strip().split('\n')
            cron_jobs = []

            for line in lines:
                if line and not line.startswith('#'):
                    parsed = parse_cron_command(line)
                    cron_jobs.append(parsed)

            return jsonify({'cron_jobs': cron_jobs})
        else:
            return jsonify({'cron_jobs': []})

    except Exception as e:
        logger.error(f'List cron error: {str(e)}')
        return jsonify({'error': str(e)}), 500

def parse_cron_command(cron_line):
    """cronã‚³ãƒãƒ³ãƒ‰ã‚’ãƒ‘ãƒ¼ã‚¹ã—ã¦ç•ªçµ„æƒ…å ±ã‚’æŠ½å‡º"""
    import re

    parts = cron_line.split(None, 5)  # æœ€åˆã®5ã¤ã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ï¼ˆcronå¼ï¼‰ã¨ã‚³ãƒãƒ³ãƒ‰éƒ¨åˆ†ã‚’åˆ†é›¢

    if len(parts) < 6:
        return {
            'raw': cron_line,
            'minute': '',
            'hour': '',
            'dayOfWeek': '',
            'command': cron_line,
            'title': '',
            'station': '',
            'startTime': '',
            'endTime': ''
        }

    minute = parts[0]
    hour = parts[1]
    day_of_month = parts[2]
    month = parts[3]
    day_of_week = parts[4]
    command_part = parts[5]

    # myradikoã‚³ãƒãƒ³ãƒ‰ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°
    # æ–°å½¢å¼: /path/to/myradiko "ç•ªçµ„å" "RSS" "æ”¾é€å±€" "`date...`HHMM" "`date...`HHMM" "" "" ""
    # å¼•æ•°1=ã‚¿ã‚¤ãƒˆãƒ«, å¼•æ•°2=RSS, å¼•æ•°3=æ”¾é€å±€, å¼•æ•°4=é–‹å§‹æ™‚åˆ», å¼•æ•°5=çµ‚äº†æ™‚åˆ»
    pattern = r'([^\s]+)\s+"([^"]*)"\s+"([^"]*)"\s+"([^"]*)"\s+"[^"]*(\d{4})".*?"[^"]*(\d{4})"'
    match = re.search(pattern, command_part)

    title = ''
    station = ''
    start_time = ''
    end_time = ''

    if match:
        title = match.group(2)        # å¼•æ•°1: ã‚¿ã‚¤ãƒˆãƒ«
        # å¼•æ•°2ã¯RSSãªã®ã§ã€å¼•æ•°3ã®æ”¾é€å±€IDã‚’ä½¿ç”¨
        station = match.group(4)      # å¼•æ•°3: æ”¾é€å±€ID
        start_time = match.group(5)   # HHMMå½¢å¼
        end_time = match.group(6)     # HHMMå½¢å¼

    return {
        'raw': cron_line,
        'minute': minute,
        'hour': hour,
        'dayOfWeek': day_of_week,
        'command': command_part,
        'title': title,
        'station': station,
        'startTime': start_time,
        'endTime': end_time
    }

@app.route('/cron/add', methods=['POST'])
def add_cron():
    """crontabã«æ–°ã—ã„ã‚¸ãƒ§ãƒ–ã‚’è¿½åŠ """
    try:
        data = request.json
        cron_command = data.get('command', '')

        if not cron_command:
            return jsonify({'error': 'Command is required'}), 400

        # ç¾åœ¨ã®crontabã‚’å–å¾—
        result = subprocess.run(['crontab', '-l'],
                              capture_output=True,
                              text=True)

        current_crontab = result.stdout if result.returncode == 0 else ''

        # é‡è¤‡ãƒã‚§ãƒƒã‚¯
        if cron_command in current_crontab:
            return jsonify({'error': 'This cron job already exists'}), 400

        # æ–°ã—ã„cronã‚¸ãƒ§ãƒ–ã‚’è¿½åŠ 
        new_crontab = current_crontab.rstrip('\n') + '\n' + cron_command + '\n'

        # crontabã‚’æ›´æ–°
        process = subprocess.Popen(['crontab', '-'],
                                 stdin=subprocess.PIPE,
                                 stdout=subprocess.PIPE,
                                 stderr=subprocess.PIPE,
                                 text=True)

        stdout, stderr = process.communicate(input=new_crontab)

        if process.returncode == 0:
            return jsonify({'success': True, 'message': 'Cron job added successfully'})
        else:
            return jsonify({'error': stderr}), 500

    except Exception as e:
        logger.error(f'Add cron error: {str(e)}')
        return jsonify({'error': str(e)}), 500

@app.route('/cron/remove', methods=['POST'])
def remove_cron():
    """crontabã‹ã‚‰ã‚¸ãƒ§ãƒ–ã‚’å‰Šé™¤"""
    try:
        data = request.json
        cron_command = data.get('command', '')

        if not cron_command:
            return jsonify({'error': 'Command is required'}), 400

        # ç¾åœ¨ã®crontabã‚’å–å¾—
        result = subprocess.run(['crontab', '-l'],
                              capture_output=True,
                              text=True)

        if result.returncode != 0:
            return jsonify({'error': 'No crontab found'}), 404

        current_crontab = result.stdout
        lines = current_crontab.split('\n')

        # æŒ‡å®šã•ã‚ŒãŸã‚³ãƒãƒ³ãƒ‰ã‚’é™¤å¤–
        new_lines = [line for line in lines if line.strip() != cron_command.strip()]
        new_crontab = '\n'.join(new_lines)

        # crontabã‚’æ›´æ–°
        process = subprocess.Popen(['crontab', '-'],
                                 stdin=subprocess.PIPE,
                                 stdout=subprocess.PIPE,
                                 stderr=subprocess.PIPE,
                                 text=True)

        stdout, stderr = process.communicate(input=new_crontab)

        if process.returncode == 0:
            return jsonify({'success': True, 'message': 'Cron job removed successfully'})
        else:
            return jsonify({'error': stderr}), 500

    except Exception as e:
        logger.error(f'Remove cron error: {str(e)}')
        return jsonify({'error': str(e)}), 500

@app.route('/cron/logs', methods=['GET'])
def get_cron_logs():
    """cronã®ãƒ­ã‚°ã‚’å–å¾—ï¼ˆå®Ÿè¡Œã‚µãƒãƒªãƒ¼ã®ã¿ï¼‰"""
    try:
        summary_logs = []

        # myradikoå®Ÿè¡Œãƒ­ã‚°ã‚’ç¢ºèªã—ã¦ã‚µãƒãƒªãƒ¼ã‚’ä½œæˆ
        myradiko_log = '/tmp/myradiko_output.log'
        if os.path.exists(myradiko_log):
            try:
                with open(myradiko_log, 'r') as f:
                    content = f.read()

                # ãƒ­ã‚°ã‚’ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã”ã¨ã«åˆ†å‰²ï¼ˆlocaleã‚¨ãƒ©ãƒ¼ä»¥é™ãŒã²ã¨ã¤ã®å®Ÿè¡Œï¼‰
                sections = content.split('warning: setlocale:')

                # æœ€æ–°10ä»¶ã®å®Ÿè¡Œãƒ­ã‚°ã‚’è§£æ
                recent_sections = sections[-11:-1] if len(sections) > 11 else sections[1:]

                for section in reversed(recent_sections):
                    # æˆåŠŸ/å¤±æ•—ã‚’åˆ¤å®š
                    if 'size=' in section and 'time=' in section:
                        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã¨æ™‚é–“ãŒè¨˜éŒ²ã•ã‚Œã¦ã„ã‚Œã°æˆåŠŸ
                        # ãƒ•ã‚¡ã‚¤ãƒ«åã‚’æŠ½å‡º
                        lines = section.split('\n')
                        filename = 'ä¸æ˜'
                        for line in lines:
                            if '.mp3' in line or '.m4a' in line:
                                # Outputè¡Œã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«åã‚’æŠ½å‡º
                                if 'Output #0' in line or 'to ' in line:
                                    parts = line.split("'")
                                    if len(parts) >= 2:
                                        filename = parts[1].replace('.m4a', '.mp3')
                                        break

                        # ã‚µã‚¤ã‚ºã‚’æŠ½å‡º
                        size_match = section.split('size=')[-1].split()[0] if 'size=' in section else 'ä¸æ˜'

                        summary_logs.append(f'âœ… æˆåŠŸ: {filename} ({size_match})')
                    elif 'Error' in section or 'failed' in section.lower():
                        # ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’æŠ½å‡º
                        error_lines = [l for l in section.split('\n') if 'Error' in l or 'failed' in l.lower()]
                        error_msg = error_lines[0] if error_lines else 'ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ'
                        summary_logs.append(f'âŒ å¤±æ•—: {error_msg[:80]}')

            except Exception as e:
                logger.error(f'Error reading myradiko log: {str(e)}')

        # cronã‚¸ãƒ§ãƒ–ä¸€è¦§ã‚‚è¡¨ç¤º
        try:
            result = subprocess.run(['crontab', '-l'],
                                  capture_output=True,
                                  text=True)
            if result.returncode == 0 and result.stdout.strip():
                summary_logs.insert(0, '=== ç™»éŒ²ã•ã‚Œã¦ã„ã‚‹cronã‚¸ãƒ§ãƒ– ===')
                summary_logs.insert(1, result.stdout.strip())
                summary_logs.insert(2, '')
                summary_logs.insert(3, '=== æœ€è¿‘ã®å®Ÿè¡Œçµæœ ===')
        except Exception as e:
            pass

        if not summary_logs:
            summary_logs = ['ãƒ­ã‚°ãŒã‚ã‚Šã¾ã›ã‚“ã€‚cronãŒå®Ÿè¡Œã•ã‚Œã‚‹ã¨ã“ã“ã«å®Ÿè¡ŒçµæœãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚']

        return jsonify({'logs': summary_logs})

    except Exception as e:
        logger.error(f'Get cron logs error: {str(e)}')
        return jsonify({'error': str(e)}), 500

@app.route('/file/delete', methods=['POST'])
def delete_file():
    """éŒ²éŸ³ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤"""
    try:
        data = request.json
        filepath = data.get('path', '')

        if not filepath:
            return jsonify({'error': 'File path is required'}), 400

        # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£: ãƒ‘ã‚¹ãƒˆãƒ©ãƒãƒ¼ã‚µãƒ«å¯¾ç­–
        base_dir = OUTPUT_DIR
        safe_path = os.path.normpath(os.path.join(base_dir, filepath))

        if not safe_path.startswith(base_dir):
            return jsonify({'error': 'Invalid file path'}), 400

        if not os.path.exists(safe_path):
            return jsonify({'error': 'File not found'}), 404

        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
        os.remove(safe_path)
        logger.info(f'File deleted: {safe_path}')

        return jsonify({'success': True, 'message': 'File deleted successfully'})

    except Exception as e:
        logger.error(f'Delete file error: {str(e)}')
        return jsonify({'error': str(e)}), 500

@app.route('/files/delete-multiple', methods=['POST'])
def delete_multiple_files():
    """è¤‡æ•°ã®éŒ²éŸ³ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸€æ‹¬å‰Šé™¤"""
    try:
        data = request.json
        filepaths = data.get('paths', [])

        if not filepaths or not isinstance(filepaths, list):
            return jsonify({'error': 'File paths array is required'}), 400

        base_dir = OUTPUT_DIR
        deleted = []
        errors = []

        for filepath in filepaths:
            try:
                # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£: ãƒ‘ã‚¹ãƒˆãƒ©ãƒãƒ¼ã‚µãƒ«å¯¾ç­–
                safe_path = os.path.normpath(os.path.join(base_dir, filepath))

                if not safe_path.startswith(base_dir):
                    errors.append({'path': filepath, 'error': 'Invalid file path'})
                    continue

                if not os.path.exists(safe_path):
                    errors.append({'path': filepath, 'error': 'File not found'})
                    continue

                # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
                os.remove(safe_path)
                deleted.append(filepath)
                logger.info(f'File deleted: {safe_path}')

            except Exception as e:
                errors.append({'path': filepath, 'error': str(e)})
                logger.error(f'Failed to delete {filepath}: {str(e)}')

        return jsonify({
            'success': True,
            'deleted': deleted,
            'errors': errors,
            'message': f'{len(deleted)} files deleted successfully'
        })

    except Exception as e:
        logger.error(f'Delete multiple files error: {str(e)}')
        return jsonify({'error': str(e)}), 500

@app.route('/files/download-zip', methods=['POST'])
def download_zip():
    """è¤‡æ•°ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ZIPå½¢å¼ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"""
    try:
        data = request.json
        filepaths = data.get('paths', [])

        if not filepaths or not isinstance(filepaths, list):
            return jsonify({'error': 'File paths array is required'}), 400

        base_dir = OUTPUT_DIR

        # ä¸€æ™‚ZIPãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
        temp_zip = tempfile.NamedTemporaryFile(delete=False, suffix='.zip')
        temp_zip_path = temp_zip.name
        temp_zip.close()

        try:
            with zipfile.ZipFile(temp_zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
                added_files = 0
                for filepath in filepaths:
                    try:
                        # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£: ãƒ‘ã‚¹ãƒˆãƒ©ãƒãƒ¼ã‚µãƒ«å¯¾ç­–
                        safe_path = os.path.normpath(os.path.join(base_dir, filepath))

                        if not safe_path.startswith(base_dir):
                            logger.warning(f'Invalid file path: {filepath}')
                            continue

                        if not os.path.exists(safe_path):
                            logger.warning(f'File not found: {filepath}')
                            continue

                        # ZIPã«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¿½åŠ ï¼ˆå…ƒã®ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ä¿æŒï¼‰
                        arcname = os.path.basename(safe_path)
                        zipf.write(safe_path, arcname=arcname)
                        added_files += 1
                        logger.info(f'Added to ZIP: {arcname}')

                    except Exception as e:
                        logger.error(f'Failed to add {filepath} to ZIP: {str(e)}')

            if added_files == 0:
                os.unlink(temp_zip_path)
                return jsonify({'error': 'No valid files found'}), 404

            # ZIPãƒ•ã‚¡ã‚¤ãƒ«ã‚’é€ä¿¡
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            zip_filename = f'radiko_recordings_{timestamp}.zip'

            response = send_file(
                temp_zip_path,
                mimetype='application/zip',
                as_attachment=True,
                download_name=zip_filename
            )

            # é€ä¿¡å¾Œã«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ã™ã‚‹
            @response.call_on_close
            def cleanup():
                try:
                    if os.path.exists(temp_zip_path):
                        os.unlink(temp_zip_path)
                        logger.info(f'Temp ZIP file deleted: {temp_zip_path}')
                except Exception as e:
                    logger.error(f'Failed to delete temp ZIP: {str(e)}')

            return response

        except Exception as e:
            # ã‚¨ãƒ©ãƒ¼æ™‚ã‚‚ZIPãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
            if os.path.exists(temp_zip_path):
                os.unlink(temp_zip_path)
            raise e

    except Exception as e:
        logger.error(f'Download ZIP error: {str(e)}')
        return jsonify({'error': str(e)}), 500

@app.route('/stream/<path:filepath>')
def stream_file(filepath):
    """éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°é…ä¿¡"""
    try:
        # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£: ãƒ‘ã‚¹ãƒˆãƒ©ãƒãƒ¼ã‚µãƒ«å¯¾ç­–
        base_dir = OUTPUT_DIR
        safe_path = os.path.normpath(os.path.join(base_dir, filepath))

        if not safe_path.startswith(base_dir):
            return jsonify({'error': 'Invalid file path'}), 400

        if not os.path.exists(safe_path):
            return jsonify({'error': 'File not found'}), 404

        # ãƒ•ã‚¡ã‚¤ãƒ«ã®æ‹¡å¼µå­ã‚’ç¢ºèª
        ext = os.path.splitext(safe_path)[1].lower()

        # MIMEã‚¿ã‚¤ãƒ—ã‚’è¨­å®š
        mime_types = {
            '.mp3': 'audio/mpeg',
            '.m4a': 'audio/mp4',
            '.aac': 'audio/aac',
            '.wav': 'audio/wav'
        }

        mime_type = mime_types.get(ext, 'application/octet-stream')

        # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°é…ä¿¡ï¼ˆRange Requestå¯¾å¿œï¼‰
        return send_file(
            safe_path,
            mimetype=mime_type,
            as_attachment=False,
            conditional=True  # Range Requestå¯¾å¿œ
        )

    except Exception as e:
        logger.error(f'Stream file error: {str(e)}')
        return jsonify({'error': str(e)}), 500

@app.route('/schedule-at', methods=['POST'])
def schedule_at():
    """atäºˆç´„ã‚’ç™»éŒ²"""
    try:
        data = request.json
        script_path = data.get('script_path', SCRIPT_PATH)
        title = data.get('title', '')        # ç•ªçµ„å
        start_time = data.get('start_time')  # YYYYMMDDHHmmå½¢å¼
        end_time = data.get('end_time')      # YYYYMMDDHHmmå½¢å¼
        station_id = data.get('station_id')
        at_time = data.get('at_time')        # HH:MM YYYY-MM-DDå½¢å¼

        if not all([start_time, end_time, station_id, at_time]):
            return jsonify({'error': 'Missing required parameters'}), 400

        # ã‚¿ã‚¤ãƒˆãƒ«ã‚’ã‚µãƒ‹ã‚¿ã‚¤ã‚ºï¼ˆã‚¹ãƒšãƒ¼ã‚¹ã‚’ã‚¢ãƒ³ãƒ€ãƒ¼ãƒãƒ¼ã«ã€å…¨è§’è¨˜å·ã‚’åŠè§’ã«ï¼‰
        safe_title = sanitize_filename(title)

        # cronã¨åŒã˜å½¢å¼ã®ã‚³ãƒãƒ³ãƒ‰ã‚’ç”Ÿæˆï¼ˆã‚µãƒ‹ã‚¿ã‚¤ã‚ºã—ãŸã‚¿ã‚¤ãƒˆãƒ«ã‚’ä½¿ç”¨ï¼‰
        command = f'{script_path} "{safe_title}" "{station_id}" "{station_id}" "{start_time}" "{end_time}" "" "" "" >> /tmp/myradiko_output.log 2>&1'
        at_command = f"echo '{command}' | at {at_time}"

        logger.info(f'Scheduling at job: {at_command}')

        result = subprocess.run(
            at_command,
            shell=True,
            capture_output=True,
            text=True
        )

        if result.returncode != 0:
            logger.error(f'at command failed: {result.stderr}')
            return jsonify({'error': result.stderr}), 500

        logger.info(f'at job scheduled successfully: {result.stdout}')

        return jsonify({
            'success': True,
            'message': 'atäºˆç´„ã‚’ç™»éŒ²ã—ã¾ã—ãŸ',
            'output': result.stdout
        })

    except Exception as e:
        logger.error(f'Schedule at error: {str(e)}')
        return jsonify({'error': str(e)}), 500

@app.route('/at/list', methods=['GET'])
def list_at_jobs():
    """atäºˆç´„ä¸€è¦§ã‚’å–å¾—"""
    try:
        result = subprocess.run(
            ['atq'],
            capture_output=True,
            text=True
        )

        if result.returncode != 0:
            logger.error(f'atq command failed: {result.stderr}')
            return jsonify({'jobs': []})

        jobs = []
        for line in result.stdout.strip().split('\n'):
            if line:
                # atqã®å‡ºåŠ›å½¢å¼: job_id date time queue user
                # ä¾‹: 1	Thu Oct 24 00:00:00 2025 a root
                parts = line.split()
                if len(parts) >= 6:
                    job_id = parts[0]
                    weekday = parts[1]
                    month = parts[2]
                    day = parts[3]
                    time = parts[4]
                    year = parts[5]

                    jobs.append({
                        'id': job_id,
                        'datetime': f'{year}/{month}/{day} {weekday} {time}',
                        'raw': line
                    })

        return jsonify({'jobs': jobs})

    except Exception as e:
        logger.error(f'List at jobs error: {str(e)}')
        return jsonify({'error': str(e)}), 500

@app.route('/at/cancel/<job_id>', methods=['DELETE'])
def cancel_at_job(job_id):
    """atäºˆç´„ã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«"""
    try:
        result = subprocess.run(
            ['atrm', job_id],
            capture_output=True,
            text=True
        )

        if result.returncode != 0:
            logger.error(f'atrm command failed: {result.stderr}')
            return jsonify({'error': result.stderr}), 500

        logger.info(f'at job {job_id} cancelled successfully')

        return jsonify({
            'success': True,
            'message': f'atäºˆç´„ #{job_id} ã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã—ã¾ã—ãŸ'
        })

    except Exception as e:
        logger.error(f'Cancel at job error: {str(e)}')
        return jsonify({'error': str(e)}), 500

@app.route('/at/detail/<job_id>', methods=['GET'])
def get_at_job_detail(job_id):
    """atäºˆç´„ã®è©³ç´°ã‚’å–å¾—"""
    try:
        result = subprocess.run(
            ['at', '-c', job_id],
            capture_output=True,
            text=True
        )

        if result.returncode != 0:
            logger.error(f'at -c command failed: {result.stderr}')
            return jsonify({'error': result.stderr}), 500

        # ã‚³ãƒãƒ³ãƒ‰éƒ¨åˆ†ã‚’æŠ½å‡ºï¼ˆæœ€å¾Œã®è¡ŒãŒã‚³ãƒãƒ³ãƒ‰ï¼‰
        lines = result.stdout.strip().split('\n')
        command = ''
        for line in reversed(lines):
            if line and not line.startswith('#') and 'myradiko' in line:
                command = line
                break

        return jsonify({
            'command': command,
            'full_output': result.stdout
        })

    except Exception as e:
        logger.error(f'Get at job detail error: {str(e)}')
        return jsonify({'error': str(e)}), 500

# ========================================
# ç•ªçµ„è¡¨DBé–¢é€£API
# ========================================

@app.route('/api/programs/search', methods=['GET'])
def search_programs_api():
    """ç•ªçµ„ã‚’æ¤œç´¢"""
    try:
        keyword = request.args.get('keyword', '')
        area_id = request.args.get('area_id')
        date_from = request.args.get('date_from')
        date_to = request.args.get('date_to')

        logger.info(f'ğŸ” Search API called with keyword="{keyword}", area_id={area_id}, date_from={date_from}, date_to={date_to}')

        if not keyword:
            return jsonify({'error': 'keyword parameter is required'}), 400

        results = db.search_programs(keyword, area_id, date_from, date_to)
        logger.info(f'ğŸ” Search API returning {len(results)} results')

        return jsonify({
            'success': True,
            'count': len(results),
            'programs': results
        })

    except Exception as e:
        logger.error(f'Search API error: {str(e)}')
        return jsonify({'error': str(e)}), 500


@app.route('/api/programs/area/<area_id>/date/<date>', methods=['GET'])
def get_area_programs_api(area_id, date):
    """ç‰¹å®šã‚¨ãƒªã‚¢ãƒ»æ—¥ä»˜ã®ç•ªçµ„ã‚’å–å¾—ï¼ˆDBã«ãªã‘ã‚Œã°radiko APIã‹ã‚‰å–å¾—ï¼‰"""
    try:
        # å¼·åˆ¶æ›´æ–°ãƒ•ãƒ©ã‚°
        force_refresh = request.args.get('force', 'false').lower() == 'true'

        programs = db.get_programs_by_area_date(area_id, date)

        # å¼·åˆ¶æ›´æ–° ã¾ãŸã¯ DBã«ãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆã€radiko APIã‹ã‚‰å–å¾—ã—ã¦DBã«ä¿å­˜
        if force_refresh or len(programs) == 0:
            if force_refresh:
                logger.info(f'ğŸ”„ Force refresh for {area_id}/{date}, fetching from radiko API...')
            else:
                logger.info(f'ğŸ“¥ No data in DB for {area_id}/{date}, fetching from radiko API...')

            # radiko APIã‹ã‚‰å–å¾—
            fetched_programs = fetch_programs.fetch_area_programs(area_id, date)

            if fetched_programs:
                # DBã«ä¿å­˜ï¼ˆæ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã¯å‰Šé™¤ã•ã‚Œã‚‹ï¼‰
                db.save_programs(fetched_programs, area_id, date)
                logger.info(f'âœ… Fetched and saved {len(fetched_programs)} programs for {area_id}/{date}')

                # ä¿å­˜ã—ãŸãƒ‡ãƒ¼ã‚¿ã‚’å†å–å¾—ã—ã¦ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
                programs = db.get_programs_by_area_date(area_id, date)
            else:
                logger.warning(f'âš ï¸ No programs found from radiko API for {area_id}/{date}')

        return jsonify({
            'success': True,
            'area_id': area_id,
            'date': date,
            'count': len(programs),
            'programs': programs
        })

    except Exception as e:
        logger.error(f'Get area programs API error: {str(e)}')
        return jsonify({'error': str(e)}), 500


@app.route('/api/programs/update/status', methods=['GET'])
def get_update_status_api():
    """ç•ªçµ„è¡¨ã®æ›´æ–°ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’å–å¾—"""
    try:
        status = db.get_update_status()
        return jsonify(status)

    except Exception as e:
        logger.error(f'Get update status API error: {str(e)}')
        return jsonify({'error': str(e)}), 500


@app.route('/api/programs/update/trigger', methods=['POST'])
def trigger_update_api():
    """ç•ªçµ„è¡¨ã®å³æ™‚æ›´æ–°ã‚’ãƒˆãƒªã‚¬ãƒ¼"""
    try:
        logger.info('Manual update triggered via API')

        # ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§å®Ÿè¡Œï¼ˆãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’ãƒ–ãƒ­ãƒƒã‚¯ã—ãªã„ï¼‰
        scheduler.add_job(
            func=fetch_programs.update_all_areas,
            trigger='date',  # å³åº§ã«å®Ÿè¡Œ
            id='manual_update',
            name='Manual update',
            replace_existing=True
        )

        return jsonify({
            'success': True,
            'message': 'Update started in background'
        })

    except Exception as e:
        logger.error(f'Trigger update API error: {str(e)}')
        return jsonify({'error': str(e)}), 500


# ==================== ç®¡ç†ãƒ¡ãƒ‹ãƒ¥ãƒ¼API ====================

@app.route('/admin/update-programs-stream', methods=['GET'])
def admin_update_programs_stream():
    """ç®¡ç†ç”»é¢ã‹ã‚‰ã®ç•ªçµ„è¡¨ä¸€æ‹¬æ›´æ–°ï¼ˆSSEã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ï¼‰"""
    def generate():
        try:
            days = int(request.args.get('days', 3))
            logger.info(f'Admin: manual program update for {days} days (streaming)')

            # é€²æ—æƒ…å ±ã‚’ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°é€ä¿¡
            yield f"data: {json.dumps({'type': 'start', 'message': f'{days}æ—¥åˆ†ã®ç•ªçµ„è¡¨æ›´æ–°ã‚’é–‹å§‹ã—ã¾ã™...'})}\n\n"

            # fetch_programs.pyã®ALL_AREA_IDSã‚’å–å¾—
            from fetch_programs import ALL_AREA_IDS
            from datetime import datetime, timedelta
            import time

            # æ—¥ä»˜ãƒªã‚¹ãƒˆã‚’ç”Ÿæˆï¼ˆä»Šæ—¥ã‹ã‚‰æŒ‡å®šæ—¥æ•°åˆ†ï¼‰
            today = datetime.now()
            if today.hour < 5:
                today = today - timedelta(days=1)

            dates = []
            for i in range(days):
                date = today + timedelta(days=i)
                date_str = date.strftime('%Y%m%d')
                dates.append(date_str)

            total_tasks = len(ALL_AREA_IDS) * len(dates)
            completed = 0
            total_programs = 0
            success_count = 0
            error_count = 0
            warning_count = 0

            yield f"data: {json.dumps({'type': 'info', 'message': f'å…¨{len(ALL_AREA_IDS)}ã‚¨ãƒªã‚¢ Ã— {len(dates)}æ—¥ = {total_tasks}ä»¶ã®å‡¦ç†'})}\n\n"

            # å„ã‚¨ãƒªã‚¢ã‚’å‡¦ç†
            for idx, area_id in enumerate(ALL_AREA_IDS, 1):
                yield f"data: {json.dumps({'type': 'progress', 'area': area_id, 'current': idx, 'total': len(ALL_AREA_IDS)})}\n\n"

                for date in dates:
                    try:
                        programs = fetch_programs.fetch_area_programs(area_id, date)

                        if programs:
                            db.save_programs(programs, area_id, date)
                            total_programs += len(programs)
                            success_count += 1
                            yield f"data: {json.dumps({'type': 'success', 'area': area_id, 'date': date, 'programs': len(programs)})}\n\n"
                        else:
                            warning_count += 1
                            yield f"data: {json.dumps({'type': 'warning', 'area': area_id, 'date': date, 'message': 'No programs found'})}\n\n"

                        completed += 1
                        progress_percent = int((completed / total_tasks) * 100)
                        yield f"data: {json.dumps({'type': 'percent', 'percent': progress_percent, 'completed': completed, 'total': total_tasks, 'success': success_count, 'error': error_count, 'warning': warning_count})}\n\n"

                        time.sleep(0.2)  # ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­–

                    except Exception as e:
                        error_count += 1
                        error_msg = str(e)
                        # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚¨ãƒ©ãƒ¼ã‚’ã‚ã‹ã‚Šã‚„ã™ã
                        if 'timed out' in error_msg or 'timeout' in error_msg.lower():
                            error_msg = 'ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ (radikoã‚µãƒ¼ãƒãƒ¼å¿œç­”ãªã—)'
                        yield f"data: {json.dumps({'type': 'error', 'area': area_id, 'date': date, 'message': error_msg})}\n\n"
                        completed += 1
                        progress_percent = int((completed / total_tasks) * 100)
                        yield f"data: {json.dumps({'type': 'percent', 'percent': progress_percent, 'completed': completed, 'total': total_tasks, 'success': success_count, 'error': error_count, 'warning': warning_count})}\n\n"

            # å¤ã„ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤
            yield f"data: {json.dumps({'type': 'info', 'message': 'å¤ã„ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤ä¸­...'})}\n\n"
            db.cleanup_old_data(days_to_keep=15)

            # å®Œäº†
            yield f"data: {json.dumps({'type': 'complete', 'total_programs': total_programs, 'success': success_count, 'error': error_count, 'warning': warning_count, 'message': 'æ›´æ–°ãŒå®Œäº†ã—ã¾ã—ãŸ'})}\n\n"

        except Exception as e:
            logger.error(f'Admin update programs stream error: {str(e)}')
            yield f"data: {json.dumps({'type': 'error', 'message': str(e)})}\n\n"

    return Response(stream_with_context(generate()), mimetype='text/event-stream')


@app.route('/admin/logs/<log_type>')
def admin_view_logs(log_type):
    """ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¡¨ç¤º"""
    try:
        log_content = ''

        if log_type == 'myradiko':
            # myradikoå®Ÿè¡Œãƒ­ã‚°
            log_path = '/tmp/myradiko_output.log'
            if os.path.exists(log_path):
                with open(log_path, 'r', encoding='utf-8', errors='ignore') as f:
                    lines = f.readlines()
                    # æœ€æ–°500è¡Œã®ã¿
                    log_content = ''.join(lines[-500:])
            else:
                log_content = 'ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“'

        elif log_type == 'docker':
            # Flaskã‚¢ãƒ—ãƒªã®ãƒ­ã‚°ï¼ˆã“ã®ã‚³ãƒ³ãƒ†ãƒŠå†…ã§ã¯å–å¾—ä¸å¯ï¼‰
            log_content = 'Dockerãƒ­ã‚°ã¯ãƒ›ã‚¹ãƒˆå´ã§ `docker-compose logs proxy` ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã¦ç¢ºèªã—ã¦ãã ã•ã„ã€‚\n\n'
            log_content += 'ã‚³ãƒ³ãƒ†ãƒŠå†…ã‹ã‚‰ãƒ›ã‚¹ãƒˆã®Dockerã‚³ãƒãƒ³ãƒ‰ã¯å®Ÿè¡Œã§ãã¾ã›ã‚“ã€‚'

        elif log_type == 'nginx':
            # Nginxãƒ­ã‚°ï¼ˆã“ã®ã‚³ãƒ³ãƒ†ãƒŠå†…ã§ã¯å–å¾—ä¸å¯ï¼‰
            log_content = 'Nginxãƒ­ã‚°ã¯ãƒ›ã‚¹ãƒˆå´ã§ `docker-compose logs web` ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã¦ç¢ºèªã—ã¦ãã ã•ã„ã€‚\n\n'
            log_content += 'ã¾ãŸã¯ã€docker exec ã‚³ãƒãƒ³ãƒ‰ã§webã‚³ãƒ³ãƒ†ãƒŠã«å…¥ã‚Šã€/var/log/nginx/ä»¥ä¸‹ã®ãƒ­ã‚°ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚'

        else:
            return jsonify({'error': 'Invalid log type'}), 400

        return jsonify({
            'success': True,
            'log': log_content
        })

    except Exception as e:
        logger.error(f'Admin view logs error: {str(e)}')
        return jsonify({'error': str(e)}), 500


@app.route('/admin/execute-manual', methods=['POST'])
def admin_execute_manual():
    """æ‰‹å‹•ã§myradikoã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œ"""
    try:
        data = request.json
        script_path = data.get('script_path', SCRIPT_PATH)
        title = data.get('title', '')
        station_id = data.get('station_id')
        start_time = data.get('start_time')
        end_time = data.get('end_time')

        if not all([station_id, start_time, end_time]):
            return jsonify({'error': 'Missing required parameters'}), 400

        # ã‚¿ã‚¤ãƒˆãƒ«ã‚’ã‚µãƒ‹ã‚¿ã‚¤ã‚ºï¼ˆã‚¹ãƒšãƒ¼ã‚¹ã‚’ã‚¢ãƒ³ãƒ€ãƒ¼ãƒãƒ¼ã«ã€å…¨è§’è¨˜å·ã‚’åŠè§’ã«ï¼‰
        safe_title = sanitize_filename(title)

        # ã‚³ãƒãƒ³ãƒ‰ã‚’æ§‹ç¯‰ï¼ˆã‚µãƒ‹ã‚¿ã‚¤ã‚ºã—ãŸã‚¿ã‚¤ãƒˆãƒ«ã‚’ä½¿ç”¨ï¼‰
        command = f'{script_path} "{safe_title}" "{station_id}" "{station_id}" "{start_time}" "{end_time}" "" "" "" >> /tmp/myradiko_output.log 2>&1'

        logger.info(f'Admin: executing manual command: {command}')

        # ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œï¼ˆåŒæœŸå®Ÿè¡Œï¼‰
        result = subprocess.run(
            command,
            shell=True,
            capture_output=True,
            encoding='utf-8',
            errors='replace',  # ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼ã‚’ç½®ãæ›ãˆæ–‡å­—ã§å‡¦ç†
            timeout=600  # 10åˆ†ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
        )

        output = result.stdout + result.stderr

        if result.returncode != 0:
            logger.error(f'Command failed: {output}')
            return jsonify({
                'success': False,
                'error': 'ã‚³ãƒãƒ³ãƒ‰å®Ÿè¡Œã«å¤±æ•—ã—ã¾ã—ãŸ',
                'output': output
            }), 500

        logger.info(f'Command executed successfully: {output}')

        return jsonify({
            'success': True,
            'message': 'ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã¾ã—ãŸ',
            'output': output
        })

    except subprocess.TimeoutExpired:
        return jsonify({'error': 'ã‚³ãƒãƒ³ãƒ‰ãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸï¼ˆ10åˆ†ä»¥ä¸Šï¼‰'}), 500
    except Exception as e:
        logger.error(f'Admin execute manual error: {str(e)}')
        return jsonify({'error': str(e)}), 500


@app.route('/admin/cleanup', methods=['POST'])
def admin_cleanup():
    """å¤ã„DBãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤"""
    try:
        deleted = db.cleanup_old_data(days_to_keep=15)

        return jsonify({
            'success': True,
            'message': 'å¤ã„ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤ã—ã¾ã—ãŸ',
            'deleted': deleted
        })

    except Exception as e:
        logger.error(f'Admin cleanup error: {str(e)}')
        return jsonify({'error': str(e)}), 500


@app.route('/admin/disk-space')
def admin_disk_space():
    """ãƒ‡ã‚£ã‚¹ã‚¯å®¹é‡ã‚’ç¢ºèª"""
    try:
        # dfã‚³ãƒãƒ³ãƒ‰ã§ãƒ‡ã‚£ã‚¹ã‚¯å®¹é‡ã‚’å–å¾—
        result = subprocess.run(
            ['df', '-h', BASE_DIR],
            capture_output=True,
            text=True,
            timeout=5
        )

        return jsonify({
            'success': True,
            'info': result.stdout
        })

    except Exception as e:
        logger.error(f'Admin disk space error: {str(e)}')
        return jsonify({'error': str(e)}), 500


@app.route('/admin/db-status')
def admin_db_status():
    """DBçµ±è¨ˆæƒ…å ±ã‚’å–å¾—"""
    try:
        import sqlite3

        conn = sqlite3.connect(db.DB_PATH)
        cursor = conn.cursor()

        # ç·ç•ªçµ„æ•°
        cursor.execute('SELECT COUNT(*) FROM programs')
        total_programs = cursor.fetchone()[0]

        # æ›´æ–°å±¥æ­´æ•°
        cursor.execute('SELECT COUNT(*) FROM update_log')
        total_updates = cursor.fetchone()[0]

        # DBãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º
        db_size = os.path.getsize(db.DB_PATH)
        db_size_mb = round(db_size / 1024 / 1024, 2)

        conn.close()

        return jsonify({
            'success': True,
            'total_programs': total_programs,
            'total_updates': total_updates,
            'db_size': f'{db_size_mb} MB'
        })

    except Exception as e:
        logger.error(f'Admin DB status error: {str(e)}')
        return jsonify({'error': str(e)}), 500


if __name__ == '__main__':
    app.run(host='0.0.0.0', port=8080, debug=False)
