from flask import Flask, Response, request, jsonify, stream_with_context, send_file
import requests
from flask_cors import CORS
import logging
import subprocess
import json
import os
from datetime import datetime
from apscheduler.schedulers.background import BackgroundScheduler
import atexit
import zipfile
import tempfile
import time
import select

# DBãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
import db
import fetch_programs

app = Flask(__name__)
app.config['JSON_AS_ASCII'] = False  # æ—¥æœ¬èªãªã©ã®éASCIIæ–‡å­—ã‚’ãã®ã¾ã¾å‡ºåŠ›
CORS(app, resources={r"/*": {"origins": "*"}})

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ãƒ‘ã‚¹è¨­å®šï¼ˆDockerç’°å¢ƒç”¨ï¼‰
BASE_DIR = os.environ.get('BASE_DIR', '/app')
SCRIPT_PATH = os.path.join(BASE_DIR, 'script/myradiko')
OUTPUT_DIR = os.path.join(BASE_DIR, 'output/radio')

# APSchedulerã®åˆæœŸåŒ–
scheduler = BackgroundScheduler(daemon=True, timezone='Asia/Tokyo')
scheduler.start()

# ã‚¢ãƒ—ãƒªçµ‚äº†æ™‚ã«ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ã‚’åœæ­¢
atexit.register(lambda: scheduler.shutdown())

logger.info('âœ… APScheduler initialized')


# ========================================
# éŒ²éŸ³å®Ÿè¡Œé–¢æ•°
# ========================================

def convert_cron_dow_to_apscheduler(cron_dow):
    """
    cronå½¢å¼ã®æ›œæ—¥ï¼ˆ0=æ—¥æ›œ, 1=æœˆæ›œ, ..., 6=åœŸæ›œï¼‰ã‚’
    APSchedulerå½¢å¼ï¼ˆmon,tue,wed,thu,fri,sat,sunï¼‰ã«å¤‰æ›
    """
    # cronã®æ•°å€¤è¡¨è¨˜ã‚’APSchedulerã®æ–‡å­—åˆ—è¡¨è¨˜ã«å¤‰æ›
    dow_map = {
        '0': 'sun',
        '1': 'mon',
        '2': 'tue',
        '3': 'wed',
        '4': 'thu',
        '5': 'fri',
        '6': 'sat',
        '*': '*'
    }

    # ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã®å ´åˆã‚‚å¯¾å¿œ
    if ',' in cron_dow:
        parts = cron_dow.split(',')
        return ','.join([dow_map.get(p.strip(), p.strip()) for p in parts])

    return dow_map.get(cron_dow, cron_dow)


def execute_recording(command: str, job_id=None, job_type='cron'):
    """éŒ²éŸ³ã‚’å®Ÿè¡Œã™ã‚‹é–¢æ•°"""
    try:
        logger.info(f'ğŸ™ï¸ Recording started (type={job_type}, job_id={job_id})')
        logger.info(f'ğŸ“ Command: {command}')

        # ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œ
        result = subprocess.run(
            command,
            shell=True,
            capture_output=True,
            text=True,
            timeout=7200  # 2æ™‚é–“ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
        )

        if result.returncode == 0:
            logger.info(f'âœ… Recording completed successfully')
            if result.stdout:
                logger.info(f'ğŸ“¤ Output: {result.stdout[:500]}')
        else:
            logger.error(f'âŒ Recording failed with return code: {result.returncode}')
            if result.stderr:
                logger.error(f'ğŸ“¤ Error output: {result.stderr[:500]}')

        # atäºˆç´„ã®å ´åˆã¯DBã‹ã‚‰å‰Šé™¤
        if job_id and job_type == 'at':
            db.delete_at_job(job_id)
            logger.info(f'ğŸ—‘ï¸ At job removed from DB: {job_id}')

    except subprocess.TimeoutExpired:
        logger.error(f'âŒ Recording timeout (2 hours exceeded)')
    except Exception as e:
        logger.error(f'âŒ Recording error: {str(e)}')


def restore_jobs_from_db():
    """DBã‹ã‚‰äºˆç´„ã‚’å¾©å…ƒã—ã¦ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ã«ç™»éŒ²"""
    try:
        logger.info('ğŸ”„ Restoring jobs from database...')

        # cronäºˆç´„ã‚’å¾©å…ƒ
        cron_jobs = db.get_all_cron_jobs()
        logger.info(f"ğŸ“‹ Found {len(cron_jobs)} cron jobs in database")

        for job in cron_jobs:
            try:
                # cronå½¢å¼ã®æ›œæ—¥ã‚’APSchedulerå½¢å¼ã«å¤‰æ›
                apscheduler_dow = convert_cron_dow_to_apscheduler(job['day_of_week'])

                scheduler.add_job(
                    func=execute_recording,
                    trigger='cron',
                    minute=job['minute'],
                    hour=job['hour'],
                    day=job['day_of_month'],
                    month=job['month'],
                    day_of_week=apscheduler_dow,
                    args=[job['command'], job['id'], 'cron'],
                    id=f"cron_{job['id']}",
                    replace_existing=True
                )
                logger.info(f"âœ… Cron job restored: {job['title']} (ID: {job['id']}) - Schedule: {job['minute']}:{job['hour']} on {job['day_of_week']} -> {apscheduler_dow}")
            except Exception as e:
                logger.error(f"âŒ Failed to restore cron job {job['id']}: {str(e)}")

        # atäºˆç´„ã‚’å¾©å…ƒ
        at_jobs = db.get_all_at_jobs()
        logger.info(f"ğŸ“‹ Found {len(at_jobs)} at jobs in database")

        for job in at_jobs:
            try:
                # schedule_timeã‚’datetimeã«å¤‰æ›
                run_date = datetime.fromisoformat(job['schedule_time'])

                # éå»ã®äºˆç´„ã¯ã‚¹ã‚­ãƒƒãƒ—
                if run_date < datetime.now():
                    logger.warning(f"âš ï¸ Skipping past at job: {job['title']} (scheduled: {job['schedule_time']})")
                    db.delete_at_job(job['id'])
                    continue

                scheduler.add_job(
                    func=execute_recording,
                    trigger='date',
                    run_date=run_date,
                    args=[job['command'], job['id'], 'at'],
                    id=f"at_{job['id']}",
                    replace_existing=True
                )
                logger.info(f"âœ… At job restored: {job['title']} (ID: {job['id']}, scheduled: {job['schedule_time']})")
            except Exception as e:
                logger.error(f"âŒ Failed to restore at job {job['id']}: {str(e)}")

        logger.info(f'âœ… Job restoration completed: {len(cron_jobs)} cron, {len(at_jobs)} at')

    except Exception as e:
        logger.error(f'âŒ Job restoration error: {str(e)}')


# DBã‹ã‚‰äºˆç´„ã‚’å¾©å…ƒ
restore_jobs_from_db()


# ãƒ•ã‚¡ã‚¤ãƒ«åã‚µãƒ‹ã‚¿ã‚¤ã‚ºé–¢æ•°
def sanitize_filename(title):
    """ç•ªçµ„åã‚’ãƒ•ã‚¡ã‚¤ãƒ«åã¨ã—ã¦å®‰å…¨ãªå½¢å¼ã«å¤‰æ›

    - åŠè§’ã‚¹ãƒšãƒ¼ã‚¹ãƒ»å…¨è§’ã‚¹ãƒšãƒ¼ã‚¹ã‚’ã‚¢ãƒ³ãƒ€ãƒ¼ãƒãƒ¼ã«
    - å…¨è§’æ–‡å­—ã‚’åŠè§’ã«å¤‰æ›
    - å…¨è§’æ•°å­—ãƒ»è‹±å­—ã‚’åŠè§’ã«
    """
    if not title:
        return title

    # ã‚¹ãƒšãƒ¼ã‚¹ã‚’ã‚¢ãƒ³ãƒ€ãƒ¼ãƒãƒ¼ã«
    title = title.replace(' ', '_')
    title = title.replace('ã€€', '_')

    # å…¨è§’è‹±æ•°å­—ã‚’åŠè§’ã«
    full_to_half = str.maketrans(
        'ï¼¡ï¼¢ï¼£ï¼¤ï¼¥ï¼¦ï¼§ï¼¨ï¼©ï¼ªï¼«ï¼¬ï¼­ï¼®ï¼¯ï¼°ï¼±ï¼²ï¼³ï¼´ï¼µï¼¶ï¼·ï¼¸ï¼¹ï¼ºï½ï½‚ï½ƒï½„ï½…ï½†ï½‡ï½ˆï½‰ï½Šï½‹ï½Œï½ï½ï½ï½ï½‘ï½’ï½“ï½”ï½•ï½–ï½—ï½˜ï½™ï½šï¼ï¼‘ï¼’ï¼“ï¼”ï¼•ï¼–ï¼—ï¼˜ï¼™',
        'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789'
    )
    title = title.translate(full_to_half)

    # å…¨è§’æ‹¬å¼§ãƒ»è¨˜å·ã‚’åŠè§’ã«
    replacements = {
        'ï¼ˆ': '(',
        'ï¼‰': ')',
        'ã€Œ': '[',
        'ã€': ']',
        'ï¼š': ':',
        'ï¼': '!',
        'ï¼Ÿ': '?',
        'ï¼»': '[',
        'ï¼½': ']',
        'ã€': '[',
        'ã€‘': ']'
    }

    for old, new in replacements.items():
        title = title.replace(old, new)

    return title

# DBåˆæœŸåŒ–
db.init_database()

# ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼è¨­å®šï¼ˆæ·±å¤œ3æ™‚ã«å®Ÿè¡Œï¼‰
scheduler = BackgroundScheduler(daemon=True, timezone='Asia/Tokyo')
scheduler.add_job(
    func=fetch_programs.update_all_areas,
    trigger='cron',
    hour=3,  # æ¯æ—¥3:00AMã«å®Ÿè¡Œ
    minute=0,
    id='update_programs',
    name='Update radiko programs daily at 3:00 AM',
    replace_existing=True
)
scheduler.start()

# ã‚¢ãƒ—ãƒªçµ‚äº†æ™‚ã«ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ã‚’ã‚·ãƒ£ãƒƒãƒˆãƒ€ã‚¦ãƒ³
atexit.register(lambda: scheduler.shutdown())

logger.info('âœ… Scheduler started: updating programs daily at 3:00 AM JST')

@app.route('/health')
def health():
    """ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯"""
    return {'status': 'ok'}, 200

@app.route('/radiko/<path:path>')
def proxy(path):
    """radikoã¸ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’ãƒ—ãƒ­ã‚­ã‚·ã™ã‚‹"""
    url = f'http://radiko.jp/{path}'
    logger.info(f'Proxying request to: {url}')

    try:
        resp = requests.get(
            url,
            timeout=30,
            headers={
                'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36'
            }
        )

        return Response(
            resp.content,
            status=resp.status_code,
            content_type=resp.headers.get('content-type', 'text/xml'),
            headers={
                'Cache-Control': 'no-cache, no-store, must-revalidate',
                'Pragma': 'no-cache',
                'Expires': '0'
            }
        )
    except requests.RequestException as e:
        logger.error(f'Error proxying request: {str(e)}')
        return Response(
            f'Error: {str(e)}',
            status=500,
            content_type='text/plain'
        )

@app.route('/execute', methods=['POST', 'OPTIONS'])
def execute_recording_http():
    """éŒ²éŸ³ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã¦ãƒ­ã‚°ã‚’ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ï¼ˆHTTPã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆï¼‰"""
    # OPTIONSãƒªã‚¯ã‚¨ã‚¹ãƒˆï¼ˆCORS preflightï¼‰ã¸ã®å¯¾å¿œ
    if request.method == 'OPTIONS':
        response = Response()
        response.headers['Access-Control-Allow-Origin'] = '*'
        response.headers['Access-Control-Allow-Methods'] = 'POST, OPTIONS'
        response.headers['Access-Control-Allow-Headers'] = 'Content-Type'
        return response

    data = request.json
    title = data.get('title', '')
    rss = data.get('rss', '')
    station = data.get('station', '')
    start_time = data.get('start_time', '')
    end_time = data.get('end_time', '')

    # ã‚¿ã‚¤ãƒˆãƒ«ã‚’ã‚µãƒ‹ã‚¿ã‚¤ã‚ºï¼ˆã‚¹ãƒšãƒ¼ã‚¹ã‚’ã‚¢ãƒ³ãƒ€ãƒ¼ãƒãƒ¼ã«ã€å…¨è§’è¨˜å·ã‚’åŠè§’ã«ï¼‰
    safe_title = sanitize_filename(title)

    # ãƒ‡ãƒãƒƒã‚°ç”¨ãƒ­ã‚°
    logger.info(f'Original title: {title}')
    logger.info(f'Sanitized title: {safe_title}')

    def generate_log():
        """ãƒ­ã‚°ã‚’ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã§è¿”ã™"""
        timestamp = datetime.now().strftime('%Y/%m/%d %H:%M:%S')

        # é–‹å§‹ãƒ­ã‚°
        yield f'data: {json.dumps({"type": "log", "message": f"[{timestamp}] ã‚³ãƒãƒ³ãƒ‰å®Ÿè¡Œé–‹å§‹..."})}\n\n'
        yield f'data: {json.dumps({"type": "log", "message": f"[{timestamp}] å…ƒã®ã‚¿ã‚¤ãƒˆãƒ«: {title}"})}\n\n'
        yield f'data: {json.dumps({"type": "log", "message": f"[{timestamp}] ã‚µãƒ‹ã‚¿ã‚¤ã‚ºå¾Œ: {safe_title}"})}\n\n'

        # myradikoã‚¹ã‚¯ãƒªãƒ—ãƒˆã®ãƒ‘ã‚¹
        script_path = SCRIPT_PATH

        # ã‚³ãƒãƒ³ãƒ‰æ§‹ç¯‰ï¼ˆã‚µãƒ‹ã‚¿ã‚¤ã‚ºã—ãŸã‚¿ã‚¤ãƒˆãƒ«ã‚’ä½¿ç”¨ï¼‰
        cmd = [
            script_path,
            safe_title,
            rss,
            station,
            start_time,
            end_time,
            '',  # SKIP
            '',  # DIR
            ''   # MAIL
        ]

        cmd_str = ' '.join([f'"{arg}"' if ' ' in arg else arg for arg in cmd])
        timestamp = datetime.now().strftime('%Y/%m/%d %H:%M:%S')
        yield f'data: {json.dumps({"type": "log", "message": f"[{timestamp}] {cmd_str}"})}\n\n'

        try:
            # ãƒ—ãƒ­ã‚»ã‚¹ã‚’èµ·å‹•ï¼ˆãƒãƒƒãƒ•ã‚¡ãªã—ã§å³åº§ã«å‡ºåŠ›ï¼‰
            process = subprocess.Popen(
                cmd,
                stdout=subprocess.PIPE,
                stderr=subprocess.STDOUT,
                encoding='utf-8',
                errors='replace',  # ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼ã‚’ç½®ãæ›ãˆæ–‡å­—ã§å‡¦ç†
                bufsize=0,  # ãƒãƒƒãƒ•ã‚¡ãªã—
                universal_newlines=True
            )

            # å‡ºåŠ›ã‚’é€æ¬¡é€ä¿¡
            last_output_time = time.time()

            while True:
                # ãƒ—ãƒ­ã‚»ã‚¹ãŒçµ‚äº†ã—ãŸã‹ãƒã‚§ãƒƒã‚¯
                if process.poll() is not None:
                    # æ®‹ã‚Šã®å‡ºåŠ›ã‚’èª­ã¿å–ã‚‹
                    remaining = process.stdout.read()
                    if remaining:
                        for line in remaining.splitlines():
                            line = line.rstrip()
                            if line:
                                timestamp = datetime.now().strftime('%Y/%m/%d %H:%M:%S')
                                yield f'data: {json.dumps({"type": "log", "message": f"[{timestamp}] {line}"})}\n\n'
                    break

                # å‡ºåŠ›ã‚’èª­ã¿å–ã‚‹ï¼ˆãƒãƒ³ãƒ–ãƒ­ãƒƒã‚­ãƒ³ã‚°ï¼‰
                line = process.stdout.readline()
                if line:
                    last_output_time = time.time()
                    line = line.rstrip()
                    if line:
                        timestamp = datetime.now().strftime('%Y/%m/%d %H:%M:%S')
                        yield f'data: {json.dumps({"type": "log", "message": f"[{timestamp}] {line}"})}\n\n'
                else:
                    # å‡ºåŠ›ãŒãªã„å ´åˆã¯å°‘ã—å¾…ã¤
                    time.sleep(0.1)

                    # 30ç§’é–“å‡ºåŠ›ãŒãªã„å ´åˆã€ãƒãƒ¼ãƒˆãƒ“ãƒ¼ãƒˆã‚’é€ä¿¡
                    if time.time() - last_output_time > 30:
                        timestamp = datetime.now().strftime('%Y/%m/%d %H:%M:%S')
                        yield f'data: {json.dumps({"type": "log", "message": f"[{timestamp}] å‡¦ç†ä¸­..."})}\n\n'
                        last_output_time = time.time()

            timestamp = datetime.now().strftime('%Y/%m/%d %H:%M:%S')
            if process.returncode == 0:
                # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’æ§‹ç¯‰ï¼ˆã‚µãƒ‹ã‚¿ã‚¤ã‚ºã—ãŸã‚¿ã‚¤ãƒˆãƒ«ã‚’ä½¿ç”¨ï¼‰
                output_dir = os.path.join(OUTPUT_DIR, rss)
                filename = f'{safe_title}({start_time[:4]}.{start_time[4:6]}.{start_time[6:8]}).mp3'
                file_path = os.path.join(output_dir, filename)

                # ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèª
                if os.path.exists(file_path):
                    # ç›¸å¯¾ãƒ‘ã‚¹ã‚’ç”Ÿæˆï¼ˆãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰URLç”¨ï¼‰
                    relative_path = f'{rss}/{filename}'
                    yield f'data: {json.dumps({"type": "success", "message": f"[{timestamp}] å®Ÿè¡Œå®Œäº†ï¼", "file": relative_path})}\n\n'
                else:
                    yield f'data: {json.dumps({"type": "success", "message": f"[{timestamp}] å®Ÿè¡Œå®Œäº†ï¼ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ï¼‰"})}\n\n'
            else:
                yield f'data: {json.dumps({"type": "error", "message": f"[{timestamp}] ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ (çµ‚äº†ã‚³ãƒ¼ãƒ‰: {process.returncode})"})}\n\n'

        except Exception as e:
            timestamp = datetime.now().strftime('%Y/%m/%d %H:%M:%S')
            yield f'data: {json.dumps({"type": "error", "message": f"[{timestamp}] ã‚¨ãƒ©ãƒ¼: {str(e)}"})}\n\n'

    return Response(
        stream_with_context(generate_log()),
        mimetype='text/event-stream',
        headers={
            'Cache-Control': 'no-cache',
            'X-Accel-Buffering': 'no'
        }
    )

@app.route('/download/<path:filepath>')
def download_file(filepath):
    """éŒ²éŸ³ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"""
    try:
        # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£: ãƒ‘ã‚¹ãƒˆãƒ©ãƒãƒ¼ã‚µãƒ«å¯¾ç­–
        base_dir = OUTPUT_DIR
        safe_path = os.path.normpath(os.path.join(base_dir, filepath))

        if not safe_path.startswith(base_dir):
            return Response('Invalid file path', status=400)

        if not os.path.exists(safe_path):
            return Response('File not found', status=404)

        return send_file(
            safe_path,
            as_attachment=True,
            download_name=os.path.basename(safe_path)
        )
    except Exception as e:
        logger.error(f'Download error: {str(e)}')
        return Response(f'Error: {str(e)}', status=500)

@app.route('/edit-audio', methods=['POST', 'OPTIONS'])
def edit_audio():
    """éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚«ãƒƒãƒˆç·¨é›†"""
    # OPTIONSãƒªã‚¯ã‚¨ã‚¹ãƒˆï¼ˆCORS preflightï¼‰ã¸ã®å¯¾å¿œ
    if request.method == 'OPTIONS':
        response = Response()
        response.headers['Access-Control-Allow-Origin'] = '*'
        response.headers['Access-Control-Allow-Methods'] = 'POST, OPTIONS'
        response.headers['Access-Control-Allow-Headers'] = 'Content-Type'
        return response

    try:
        data = request.json
        file_path = data.get('file_path', '')
        start_time = data.get('start_time', 0)
        end_time = data.get('end_time', 0)
        mode = data.get('mode', 'remove')  # 'remove' or 'extract'

        if not file_path:
            return jsonify({'error': 'File path is required'}), 400

        # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£: ãƒ‘ã‚¹ãƒˆãƒ©ãƒãƒ¼ã‚µãƒ«å¯¾ç­–
        base_dir = OUTPUT_DIR
        safe_path = os.path.normpath(os.path.join(base_dir, file_path))

        if not safe_path.startswith(base_dir):
            return jsonify({'error': 'Invalid file path'}), 400

        if not os.path.exists(safe_path):
            return jsonify({'error': 'File not found'}), 404

        # ãƒ•ã‚¡ã‚¤ãƒ«åã¨æ‹¡å¼µå­ã‚’åˆ†é›¢
        file_dir = os.path.dirname(safe_path)
        file_name = os.path.basename(safe_path)
        name_without_ext, ext = os.path.splitext(file_name)

        # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ç”Ÿæˆ
        if mode == 'remove':
            output_filename = f'{name_without_ext}_cut{ext}'
        else:  # extract
            output_filename = f'{name_without_ext}_extract{ext}'

        output_path = os.path.join(file_dir, output_filename)

        # ffmpegã‚³ãƒãƒ³ãƒ‰ã‚’æ§‹ç¯‰
        if mode == 'remove':
            # ç¯„å›²ã‚’å‰Šé™¤: é–‹å§‹å‰ã®éƒ¨åˆ†ã¨çµ‚äº†å¾Œã®éƒ¨åˆ†ã‚’çµåˆ
            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
            temp1 = os.path.join(file_dir, f'temp1_{name_without_ext}{ext}')
            temp2 = os.path.join(file_dir, f'temp2_{name_without_ext}{ext}')
            concat_file = os.path.join(file_dir, f'concat_{name_without_ext}.txt')

            try:
                # é–‹å§‹å‰ã®éƒ¨åˆ†ã‚’æŠ½å‡º
                cmd1 = [
                    'ffmpeg', '-y', '-i', safe_path,
                    '-t', str(start_time),
                    '-c', 'copy',
                    temp1
                ]

                # çµ‚äº†å¾Œã®éƒ¨åˆ†ã‚’æŠ½å‡º
                cmd2 = [
                    'ffmpeg', '-y', '-i', safe_path,
                    '-ss', str(end_time),
                    '-c', 'copy',
                    temp2
                ]

                # å®Ÿè¡Œ
                subprocess.run(cmd1, check=True, capture_output=True)
                subprocess.run(cmd2, check=True, capture_output=True)

                # concatãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
                with open(concat_file, 'w') as f:
                    f.write(f"file '{temp1}'\n")
                    f.write(f"file '{temp2}'\n")

                # çµåˆ
                cmd3 = [
                    'ffmpeg', '-y', '-f', 'concat', '-safe', '0',
                    '-i', concat_file,
                    '-c', 'copy',
                    output_path
                ]
                subprocess.run(cmd3, check=True, capture_output=True)

                # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
                os.remove(temp1)
                os.remove(temp2)
                os.remove(concat_file)

            except Exception as e:
                # ã‚¨ãƒ©ãƒ¼æ™‚ã¯ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
                for temp_file in [temp1, temp2, concat_file]:
                    if os.path.exists(temp_file):
                        os.remove(temp_file)
                raise e

        else:  # extract
            # ç¯„å›²ã‚’æŠ½å‡º
            cmd = [
                'ffmpeg', '-y', '-i', safe_path,
                '-ss', str(start_time),
                '-to', str(end_time),
                '-c', 'copy',
                output_path
            ]
            subprocess.run(cmd, check=True, capture_output=True)

        # ç›¸å¯¾ãƒ‘ã‚¹ã‚’è¿”ã™
        relative_path = os.path.relpath(output_path, base_dir)

        logger.info(f'Audio edit completed: {output_filename}')

        return jsonify({
            'success': True,
            'output_file': output_filename,
            'output_path': relative_path
        })

    except subprocess.CalledProcessError as e:
        logger.error(f'FFmpeg error: {e.stderr.decode() if e.stderr else str(e)}')
        return jsonify({'error': 'Audio editing failed'}), 500
    except Exception as e:
        logger.error(f'Edit audio error: {str(e)}')
        return jsonify({'error': str(e)}), 500

@app.route('/rename-file', methods=['POST', 'OPTIONS'])
def rename_file():
    """ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒªãƒãƒ¼ãƒ """
    # OPTIONSãƒªã‚¯ã‚¨ã‚¹ãƒˆï¼ˆCORS preflightï¼‰ã¸ã®å¯¾å¿œ
    if request.method == 'OPTIONS':
        response = Response()
        response.headers['Access-Control-Allow-Origin'] = '*'
        response.headers['Access-Control-Allow-Methods'] = 'POST, OPTIONS'
        response.headers['Access-Control-Allow-Headers'] = 'Content-Type'
        return response

    try:
        data = request.json
        file_path = data.get('file_path', '')
        new_name = data.get('new_name', '')

        if not file_path or not new_name:
            return jsonify({'error': 'File path and new name are required'}), 400

        # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£: ãƒ‘ã‚¹ãƒˆãƒ©ãƒãƒ¼ã‚µãƒ«å¯¾ç­–
        base_dir = OUTPUT_DIR
        safe_path = os.path.normpath(os.path.join(base_dir, file_path))

        if not safe_path.startswith(base_dir):
            return jsonify({'error': 'Invalid file path'}), 400

        if not os.path.exists(safe_path):
            return jsonify({'error': 'File not found'}), 404

        # æ–°ã—ã„ãƒ•ã‚¡ã‚¤ãƒ«åã®ãƒ‘ã‚¹ã‚’æ§‹ç¯‰
        file_dir = os.path.dirname(safe_path)
        new_path = os.path.join(file_dir, new_name)

        # æ—¢ã«åŒã˜åå‰ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
        if os.path.exists(new_path):
            return jsonify({'error': 'A file with that name already exists'}), 400

        # ãƒªãƒãƒ¼ãƒ å®Ÿè¡Œ
        os.rename(safe_path, new_path)

        # ç›¸å¯¾ãƒ‘ã‚¹ã‚’è¿”ã™
        relative_path = os.path.relpath(new_path, base_dir)

        logger.info(f'File renamed: {file_path} -> {new_name}')

        return jsonify({
            'success': True,
            'new_name': new_name,
            'new_path': relative_path
        })

    except Exception as e:
        logger.error(f'Rename file error: {str(e)}')
        return jsonify({'error': str(e)}), 500

@app.route('/files', methods=['GET'])
def list_files():
    """éŒ²éŸ³æ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã‚’å–å¾—"""
    try:
        base_dir = OUTPUT_DIR
        files = []

        if not os.path.exists(base_dir):
            return jsonify({'files': []})

        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å†å¸°çš„ã«æ¢ç´¢
        for root, dirs, filenames in os.walk(base_dir):
            for filename in filenames:
                if filename.endswith('.mp3'):
                    full_path = os.path.join(root, filename)
                    relative_path = os.path.relpath(full_path, base_dir)
                    file_stat = os.stat(full_path)

                    files.append({
                        'path': relative_path,
                        'name': filename,
                        'size': file_stat.st_size,
                        'modified': file_stat.st_mtime
                    })

        # æ›´æ–°æ—¥æ™‚ã§ã‚½ãƒ¼ãƒˆï¼ˆæ–°ã—ã„é †ï¼‰
        files.sort(key=lambda x: x['modified'], reverse=True)

        return jsonify({'files': files})
    except Exception as e:
        logger.error(f'List files error: {str(e)}')
        return jsonify({'error': str(e)}), 500

@app.route('/check-file', methods=['POST'])
def check_file_exists():
    """ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ãƒã‚§ãƒƒã‚¯"""
    try:
        data = request.json
        title = data.get('title', '')
        rss = data.get('rss', '')
        start_time = data.get('start_time', '')

        # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’æ§‹ç¯‰
        output_dir = os.path.join(OUTPUT_DIR, rss)
        filename = f'{title}({start_time[:4]}.{start_time[4:6]}.{start_time[6:8]}).mp3'
        file_path = os.path.join(output_dir, filename)

        exists = os.path.exists(file_path)
        relative_path = f'{rss}/{filename}' if exists else None

        return jsonify({
            'exists': exists,
            'path': relative_path,
            'filename': filename
        })
    except Exception as e:
        logger.error(f'Check file error: {str(e)}')
        return jsonify({'error': str(e)}), 500

@app.route('/cron/list', methods=['GET'])
def list_cron():
    """DBã‹ã‚‰cronäºˆç´„ã‚’å–å¾—"""
    try:
        jobs = db.get_all_cron_jobs()

        # ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ç”¨ã«ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
        cron_jobs = []
        for job in jobs:
            cron_jobs.append({
                'id': job['id'],
                'raw': f"{job['minute']} {job['hour']} {job['day_of_month']} {job['month']} {job['day_of_week']} {job['command']}",
                'minute': job['minute'],
                'hour': job['hour'],
                'dayOfWeek': job['day_of_week'],
                'command': job['command'],
                'title': job['title'],
                'station': job['station'],
                'startTime': job['start_time'],
                'endTime': job['end_time']
            })

        return jsonify({'cron_jobs': cron_jobs})

    except Exception as e:
        logger.error(f'List cron error: {str(e)}')
        return jsonify({'error': str(e)}), 500

def parse_cron_command(cron_line):
    """cronã‚³ãƒãƒ³ãƒ‰ã‚’ãƒ‘ãƒ¼ã‚¹ã—ã¦ç•ªçµ„æƒ…å ±ã‚’æŠ½å‡º"""
    import re

    parts = cron_line.split(None, 5)  # æœ€åˆã®5ã¤ã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ï¼ˆcronå¼ï¼‰ã¨ã‚³ãƒãƒ³ãƒ‰éƒ¨åˆ†ã‚’åˆ†é›¢

    if len(parts) < 6:
        return {
            'raw': cron_line,
            'minute': '',
            'hour': '',
            'dayOfWeek': '',
            'command': cron_line,
            'title': '',
            'station': '',
            'startTime': '',
            'endTime': ''
        }

    minute = parts[0]
    hour = parts[1]
    day_of_month = parts[2]
    month = parts[3]
    day_of_week = parts[4]
    command_part = parts[5]

    # myradikoã‚³ãƒãƒ³ãƒ‰ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°
    # æ–°å½¢å¼: /path/to/myradiko "ç•ªçµ„å" "RSS" "æ”¾é€å±€" "`date...`HHMM" "`date...`HHMM" "" "" ""
    # å¼•æ•°1=ã‚¿ã‚¤ãƒˆãƒ«, å¼•æ•°2=RSS, å¼•æ•°3=æ”¾é€å±€, å¼•æ•°4=é–‹å§‹æ™‚åˆ», å¼•æ•°5=çµ‚äº†æ™‚åˆ»
    pattern = r'([^\s]+)\s+"([^"]*)"\s+"([^"]*)"\s+"([^"]*)"\s+"[^"]*(\d{4})".*?"[^"]*(\d{4})"'
    match = re.search(pattern, command_part)

    title = ''
    station = ''
    start_time = ''
    end_time = ''

    if match:
        title = match.group(2)        # å¼•æ•°1: ã‚¿ã‚¤ãƒˆãƒ«
        # å¼•æ•°2ã¯RSSãªã®ã§ã€å¼•æ•°3ã®æ”¾é€å±€IDã‚’ä½¿ç”¨
        station = match.group(4)      # å¼•æ•°3: æ”¾é€å±€ID
        start_time = match.group(5)   # HHMMå½¢å¼
        end_time = match.group(6)     # HHMMå½¢å¼

    return {
        'raw': cron_line,
        'minute': minute,
        'hour': hour,
        'dayOfWeek': day_of_week,
        'command': command_part,
        'title': title,
        'station': station,
        'startTime': start_time,
        'endTime': end_time
    }

@app.route('/cron/add', methods=['POST'])
def add_cron():
    """DBã«æ–°ã—ã„cronäºˆç´„ã‚’è¿½åŠ ã—ã¦ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ã«ç™»éŒ²"""
    try:
        data = request.json
        cron_command = data.get('command', '')

        if not cron_command:
            return jsonify({'error': 'Command is required'}), 400

        # cronã‚³ãƒãƒ³ãƒ‰ã‚’ãƒ‘ãƒ¼ã‚¹
        parsed = parse_cron_command(cron_command)

        # DBã«ä¿å­˜
        job_id = db.save_cron_job(
            minute=parsed['minute'],
            hour=parsed['hour'],
            day_of_month='*',
            month='*',
            day_of_week=parsed['dayOfWeek'],
            command=parsed['command'],
            title=parsed['title'],
            station=parsed['station'],
            start_time=parsed['startTime'],
            end_time=parsed['endTime']
        )

        if not job_id:
            return jsonify({'error': 'Failed to save cron job'}), 500

        # ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ã«ç™»éŒ²
        try:
            # cronå½¢å¼ã®æ›œæ—¥ã‚’APSchedulerå½¢å¼ã«å¤‰æ›
            apscheduler_dow = convert_cron_dow_to_apscheduler(parsed['dayOfWeek'])

            logger.info(f"ğŸ“ Adding cron job to scheduler - ID: {job_id}")
            logger.info(f"ğŸ“ Schedule: minute={parsed['minute']}, hour={parsed['hour']}, dow={parsed['dayOfWeek']} -> {apscheduler_dow}")
            logger.info(f"ğŸ“ Command: {parsed['command'][:100]}")

            scheduler.add_job(
                func=execute_recording,
                trigger='cron',
                minute=parsed['minute'],
                hour=parsed['hour'],
                day='*',
                month='*',
                day_of_week=apscheduler_dow,
                args=[parsed['command'], job_id, 'cron'],
                id=f"cron_{job_id}",
                replace_existing=True
            )
            logger.info(f"âœ… Cron job added to scheduler successfully: cron_{job_id}")

            # ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ã®çŠ¶æ…‹ã‚’ãƒ­ã‚°
            all_jobs = scheduler.get_jobs()
            logger.info(f"ğŸ“Š Total scheduled jobs: {len(all_jobs)}")

        except Exception as e:
            logger.error(f"âŒ Failed to add job to scheduler: {str(e)}")
            logger.error(f"âŒ Job details - minute:{parsed['minute']}, hour:{parsed['hour']}, dow:{parsed['dayOfWeek']}, cmd:{parsed['command'][:50]}")
            # DBã‹ã‚‰ã‚‚å‰Šé™¤
            db.delete_cron_job(job_id)
            return jsonify({'error': f'Failed to schedule job: {str(e)}'}), 500

        return jsonify({'success': True, 'message': 'Cron job added successfully', 'job_id': job_id})

    except Exception as e:
        logger.error(f'Add cron error: {str(e)}')
        return jsonify({'error': str(e)}), 500

@app.route('/cron/remove', methods=['POST'])
def remove_cron():
    """DBã‹ã‚‰cronäºˆç´„ã‚’å‰Šé™¤ã—ã¦ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ã‹ã‚‰ã‚‚å‰Šé™¤"""
    try:
        data = request.json
        job_id = data.get('id')

        if not job_id:
            return jsonify({'error': 'Job ID is required'}), 400

        # DBã‹ã‚‰è©²å½“ã™ã‚‹ã‚¸ãƒ§ãƒ–ã‚’æ¤œç´¢
        jobs = db.get_all_cron_jobs()
        job_to_delete = None

        for job in jobs:
            if job['id'] == job_id:
                job_to_delete = job
                break

        if not job_to_delete:
            return jsonify({'error': 'Cron job not found'}), 404

        # ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ã‹ã‚‰å‰Šé™¤
        try:
            scheduler.remove_job(f"cron_{job_id}")
            logger.info(f"âœ… Cron job removed from scheduler: {job_id}")
        except Exception as e:
            logger.warning(f"âš ï¸ Job not found in scheduler (may be already removed): {str(e)}")

        # DBã‹ã‚‰å‰Šé™¤
        if db.delete_cron_job(job_id):
            return jsonify({'success': True, 'message': 'Cron job removed successfully'})
        else:
            return jsonify({'error': 'Failed to delete cron job from database'}), 500

    except Exception as e:
        logger.error(f'Remove cron error: {str(e)}')
        return jsonify({'error': str(e)}), 500

@app.route('/cron/logs', methods=['GET'])
def get_cron_logs():
    """cronã®ãƒ­ã‚°ã‚’å–å¾—ï¼ˆå®Ÿè¡Œã‚µãƒãƒªãƒ¼ã®ã¿ï¼‰"""
    try:
        summary_logs = []

        # myradikoå®Ÿè¡Œãƒ­ã‚°ã‚’ç¢ºèªã—ã¦ã‚µãƒãƒªãƒ¼ã‚’ä½œæˆ
        myradiko_log = '/tmp/myradiko_output.log'
        if os.path.exists(myradiko_log):
            try:
                with open(myradiko_log, 'r') as f:
                    content = f.read()

                # ãƒ­ã‚°ã‚’ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã”ã¨ã«åˆ†å‰²ï¼ˆlocaleã‚¨ãƒ©ãƒ¼ä»¥é™ãŒã²ã¨ã¤ã®å®Ÿè¡Œï¼‰
                sections = content.split('warning: setlocale:')

                # æœ€æ–°10ä»¶ã®å®Ÿè¡Œãƒ­ã‚°ã‚’è§£æ
                recent_sections = sections[-11:-1] if len(sections) > 11 else sections[1:]

                for section in reversed(recent_sections):
                    # æˆåŠŸ/å¤±æ•—ã‚’åˆ¤å®š
                    if 'size=' in section and 'time=' in section:
                        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã¨æ™‚é–“ãŒè¨˜éŒ²ã•ã‚Œã¦ã„ã‚Œã°æˆåŠŸ
                        # ãƒ•ã‚¡ã‚¤ãƒ«åã‚’æŠ½å‡º
                        lines = section.split('\n')
                        filename = 'ä¸æ˜'
                        for line in lines:
                            if '.mp3' in line or '.m4a' in line:
                                # Outputè¡Œã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«åã‚’æŠ½å‡º
                                if 'Output #0' in line or 'to ' in line:
                                    parts = line.split("'")
                                    if len(parts) >= 2:
                                        filename = parts[1].replace('.m4a', '.mp3')
                                        break

                        # ã‚µã‚¤ã‚ºã‚’æŠ½å‡º
                        size_match = section.split('size=')[-1].split()[0] if 'size=' in section else 'ä¸æ˜'

                        summary_logs.append(f'âœ… æˆåŠŸ: {filename} ({size_match})')
                    elif 'Error' in section or 'failed' in section.lower():
                        # ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’æŠ½å‡º
                        error_lines = [l for l in section.split('\n') if 'Error' in l or 'failed' in l.lower()]
                        error_msg = error_lines[0] if error_lines else 'ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ'
                        summary_logs.append(f'âŒ å¤±æ•—: {error_msg[:80]}')

            except Exception as e:
                logger.error(f'Error reading myradiko log: {str(e)}')

        # cronã‚¸ãƒ§ãƒ–ä¸€è¦§ã‚‚è¡¨ç¤º
        try:
            result = subprocess.run(['crontab', '-l'],
                                  capture_output=True,
                                  text=True)
            if result.returncode == 0 and result.stdout.strip():
                summary_logs.insert(0, '=== ç™»éŒ²ã•ã‚Œã¦ã„ã‚‹cronã‚¸ãƒ§ãƒ– ===')
                summary_logs.insert(1, result.stdout.strip())
                summary_logs.insert(2, '')
                summary_logs.insert(3, '=== æœ€è¿‘ã®å®Ÿè¡Œçµæœ ===')
        except Exception as e:
            pass

        if not summary_logs:
            summary_logs = ['ãƒ­ã‚°ãŒã‚ã‚Šã¾ã›ã‚“ã€‚cronãŒå®Ÿè¡Œã•ã‚Œã‚‹ã¨ã“ã“ã«å®Ÿè¡ŒçµæœãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚']

        return jsonify({'logs': summary_logs})

    except Exception as e:
        logger.error(f'Get cron logs error: {str(e)}')
        return jsonify({'error': str(e)}), 500

@app.route('/file/delete', methods=['POST'])
def delete_file():
    """éŒ²éŸ³ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤"""
    try:
        data = request.json
        filepath = data.get('path', '')

        if not filepath:
            return jsonify({'error': 'File path is required'}), 400

        # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£: ãƒ‘ã‚¹ãƒˆãƒ©ãƒãƒ¼ã‚µãƒ«å¯¾ç­–
        base_dir = OUTPUT_DIR
        safe_path = os.path.normpath(os.path.join(base_dir, filepath))

        if not safe_path.startswith(base_dir):
            return jsonify({'error': 'Invalid file path'}), 400

        if not os.path.exists(safe_path):
            return jsonify({'error': 'File not found'}), 404

        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
        os.remove(safe_path)
        logger.info(f'File deleted: {safe_path}')

        return jsonify({'success': True, 'message': 'File deleted successfully'})

    except Exception as e:
        logger.error(f'Delete file error: {str(e)}')
        return jsonify({'error': str(e)}), 500

@app.route('/files/delete-multiple', methods=['POST'])
def delete_multiple_files():
    """è¤‡æ•°ã®éŒ²éŸ³ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸€æ‹¬å‰Šé™¤"""
    try:
        data = request.json
        filepaths = data.get('paths', [])

        if not filepaths or not isinstance(filepaths, list):
            return jsonify({'error': 'File paths array is required'}), 400

        base_dir = OUTPUT_DIR
        deleted = []
        errors = []

        for filepath in filepaths:
            try:
                # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£: ãƒ‘ã‚¹ãƒˆãƒ©ãƒãƒ¼ã‚µãƒ«å¯¾ç­–
                safe_path = os.path.normpath(os.path.join(base_dir, filepath))

                if not safe_path.startswith(base_dir):
                    errors.append({'path': filepath, 'error': 'Invalid file path'})
                    continue

                if not os.path.exists(safe_path):
                    errors.append({'path': filepath, 'error': 'File not found'})
                    continue

                # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
                os.remove(safe_path)
                deleted.append(filepath)
                logger.info(f'File deleted: {safe_path}')

            except Exception as e:
                errors.append({'path': filepath, 'error': str(e)})
                logger.error(f'Failed to delete {filepath}: {str(e)}')

        return jsonify({
            'success': True,
            'deleted': deleted,
            'errors': errors,
            'message': f'{len(deleted)} files deleted successfully'
        })

    except Exception as e:
        logger.error(f'Delete multiple files error: {str(e)}')
        return jsonify({'error': str(e)}), 500

@app.route('/files/download-zip', methods=['POST'])
def download_zip():
    """è¤‡æ•°ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ZIPå½¢å¼ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"""
    try:
        data = request.json
        filepaths = data.get('paths', [])

        if not filepaths or not isinstance(filepaths, list):
            return jsonify({'error': 'File paths array is required'}), 400

        base_dir = OUTPUT_DIR

        # ä¸€æ™‚ZIPãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
        temp_zip = tempfile.NamedTemporaryFile(delete=False, suffix='.zip')
        temp_zip_path = temp_zip.name
        temp_zip.close()

        try:
            with zipfile.ZipFile(temp_zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
                added_files = 0
                for filepath in filepaths:
                    try:
                        # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£: ãƒ‘ã‚¹ãƒˆãƒ©ãƒãƒ¼ã‚µãƒ«å¯¾ç­–
                        safe_path = os.path.normpath(os.path.join(base_dir, filepath))

                        if not safe_path.startswith(base_dir):
                            logger.warning(f'Invalid file path: {filepath}')
                            continue

                        if not os.path.exists(safe_path):
                            logger.warning(f'File not found: {filepath}')
                            continue

                        # ZIPã«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¿½åŠ ï¼ˆå…ƒã®ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ä¿æŒï¼‰
                        arcname = os.path.basename(safe_path)
                        zipf.write(safe_path, arcname=arcname)
                        added_files += 1
                        logger.info(f'Added to ZIP: {arcname}')

                    except Exception as e:
                        logger.error(f'Failed to add {filepath} to ZIP: {str(e)}')

            if added_files == 0:
                os.unlink(temp_zip_path)
                return jsonify({'error': 'No valid files found'}), 404

            # ZIPãƒ•ã‚¡ã‚¤ãƒ«ã‚’é€ä¿¡
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            zip_filename = f'radiko_recordings_{timestamp}.zip'

            response = send_file(
                temp_zip_path,
                mimetype='application/zip',
                as_attachment=True,
                download_name=zip_filename
            )

            # é€ä¿¡å¾Œã«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ã™ã‚‹
            @response.call_on_close
            def cleanup():
                try:
                    if os.path.exists(temp_zip_path):
                        os.unlink(temp_zip_path)
                        logger.info(f'Temp ZIP file deleted: {temp_zip_path}')
                except Exception as e:
                    logger.error(f'Failed to delete temp ZIP: {str(e)}')

            return response

        except Exception as e:
            # ã‚¨ãƒ©ãƒ¼æ™‚ã‚‚ZIPãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
            if os.path.exists(temp_zip_path):
                os.unlink(temp_zip_path)
            raise e

    except Exception as e:
        logger.error(f'Download ZIP error: {str(e)}')
        return jsonify({'error': str(e)}), 500

@app.route('/stream/<path:filepath>')
def stream_file(filepath):
    """éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°é…ä¿¡"""
    try:
        # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£: ãƒ‘ã‚¹ãƒˆãƒ©ãƒãƒ¼ã‚µãƒ«å¯¾ç­–
        base_dir = OUTPUT_DIR
        safe_path = os.path.normpath(os.path.join(base_dir, filepath))

        if not safe_path.startswith(base_dir):
            return jsonify({'error': 'Invalid file path'}), 400

        if not os.path.exists(safe_path):
            return jsonify({'error': 'File not found'}), 404

        # ãƒ•ã‚¡ã‚¤ãƒ«ã®æ‹¡å¼µå­ã‚’ç¢ºèª
        ext = os.path.splitext(safe_path)[1].lower()

        # MIMEã‚¿ã‚¤ãƒ—ã‚’è¨­å®š
        mime_types = {
            '.mp3': 'audio/mpeg',
            '.m4a': 'audio/mp4',
            '.aac': 'audio/aac',
            '.wav': 'audio/wav'
        }

        mime_type = mime_types.get(ext, 'application/octet-stream')

        # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°é…ä¿¡ï¼ˆRange Requestå¯¾å¿œï¼‰
        return send_file(
            safe_path,
            mimetype=mime_type,
            as_attachment=False,
            conditional=True  # Range Requestå¯¾å¿œ
        )

    except Exception as e:
        logger.error(f'Stream file error: {str(e)}')
        return jsonify({'error': str(e)}), 500

@app.route('/schedule-at', methods=['POST'])
def schedule_at():
    """DBã«atäºˆç´„ã‚’ä¿å­˜ã—ã¦ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ã«ç™»éŒ²"""
    try:
        data = request.json
        script_path = data.get('script_path', SCRIPT_PATH)
        title = data.get('title', '')        # ç•ªçµ„å
        start_time = data.get('start_time')  # YYYYMMDDHHmmå½¢å¼
        end_time = data.get('end_time')      # YYYYMMDDHHmmå½¢å¼
        station_id = data.get('station_id')
        at_time = data.get('at_time')        # HH:MM YYYY-MM-DDå½¢å¼

        if not all([start_time, end_time, station_id, at_time]):
            return jsonify({'error': 'Missing required parameters'}), 400

        # ã‚¿ã‚¤ãƒˆãƒ«ã‚’ã‚µãƒ‹ã‚¿ã‚¤ã‚ºï¼ˆã‚¹ãƒšãƒ¼ã‚¹ã‚’ã‚¢ãƒ³ãƒ€ãƒ¼ãƒãƒ¼ã«ã€å…¨è§’è¨˜å·ã‚’åŠè§’ã«ï¼‰
        safe_title = sanitize_filename(title)

        # cronã¨åŒã˜å½¢å¼ã®ã‚³ãƒãƒ³ãƒ‰ã‚’ç”Ÿæˆï¼ˆã‚µãƒ‹ã‚¿ã‚¤ã‚ºã—ãŸã‚¿ã‚¤ãƒˆãƒ«ã‚’ä½¿ç”¨ï¼‰
        command = f'{script_path} "{safe_title}" "{station_id}" "{station_id}" "{start_time}" "{end_time}" "" "" "" >> /tmp/myradiko_output.log 2>&1'

        # at_timeã‚’datetimeã«å¤‰æ› (HH:MM YYYY-MM-DD -> datetime)
        schedule_time_str = f"{at_time.split()[1]} {at_time.split()[0]}"  # YYYY-MM-DD HH:MM
        schedule_time = datetime.strptime(schedule_time_str, '%Y-%m-%d %H:%M')

        # éå»ã®æ™‚åˆ»ãƒã‚§ãƒƒã‚¯
        now = datetime.now()
        if schedule_time < now:
            return jsonify({'error': 'Cannot schedule in the past'}), 400

        # DBã«ä¿å­˜ï¼ˆjob_idã¯è‡ªå‹•ç”Ÿæˆï¼‰
        job_id = db.save_at_job(
            job_id=None,  # Auto-generate
            schedule_time=schedule_time.strftime('%Y-%m-%d %H:%M:%S'),
            command=command,
            title=title,
            station=station_id,
            start_time=start_time,
            end_time=end_time
        )

        if not job_id:
            return jsonify({'error': 'Failed to save at job to database'}), 500

        # ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ã«ç™»éŒ²
        scheduler.add_job(
            func=execute_recording,
            trigger='date',
            run_date=schedule_time,
            args=[command, job_id],
            id=f"at_{job_id}",
            replace_existing=True
        )

        logger.info(f'âœ… At job scheduled: {job_id} at {schedule_time}')

        return jsonify({
            'success': True,
            'message': 'atäºˆç´„ã‚’ç™»éŒ²ã—ã¾ã—ãŸ',
            'job_id': job_id,
            'schedule_time': schedule_time.strftime('%Y-%m-%d %H:%M:%S')
        })

    except Exception as e:
        logger.error(f'Schedule at error: {str(e)}')
        return jsonify({'error': str(e)}), 500

@app.route('/at/list', methods=['GET'])
def list_at_jobs():
    """DBã‹ã‚‰atäºˆç´„ä¸€è¦§ã‚’å–å¾—"""
    try:
        jobs_data = db.get_all_at_jobs()

        jobs = []
        for job in jobs_data:
            # schedule_timeã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ (YYYY-MM-DD HH:MM:SS -> ã‚ˆã‚Šèª­ã¿ã‚„ã™ã„å½¢å¼)
            try:
                schedule_dt = datetime.strptime(job['schedule_time'], '%Y-%m-%d %H:%M:%S')
                formatted_datetime = schedule_dt.strftime('%Y/%m/%d %a %H:%M')
            except:
                formatted_datetime = job['schedule_time']

            jobs.append({
                'id': str(job['id']),
                'datetime': formatted_datetime,
                'title': job.get('title', ''),
                'station': job.get('station', ''),
                'schedule_time': job['schedule_time']
            })

        return jsonify({'jobs': jobs})

    except Exception as e:
        logger.error(f'List at jobs error: {str(e)}')
        return jsonify({'error': str(e)}), 500

@app.route('/at/cancel/<job_id>', methods=['DELETE'])
def cancel_at_job(job_id):
    """DBã‹ã‚‰atäºˆç´„ã‚’å‰Šé™¤ã—ã¦ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ã‹ã‚‰ã‚‚å‰Šé™¤"""
    try:
        # ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ã‹ã‚‰å‰Šé™¤
        try:
            scheduler.remove_job(f"at_{job_id}")
            logger.info(f"âœ… At job removed from scheduler: {job_id}")
        except Exception as e:
            logger.warning(f"âš ï¸ Job not found in scheduler (may be already executed or removed): {str(e)}")

        # DBã‹ã‚‰å‰Šé™¤
        if db.delete_at_job(int(job_id)):
            return jsonify({
                'success': True,
                'message': f'atäºˆç´„ #{job_id} ã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã—ã¾ã—ãŸ'
            })
        else:
            return jsonify({'error': 'Failed to delete at job from database'}), 500

    except Exception as e:
        logger.error(f'Cancel at job error: {str(e)}')
        return jsonify({'error': str(e)}), 500

@app.route('/at/detail/<job_id>', methods=['GET'])
def get_at_job_detail(job_id):
    """DBã‹ã‚‰atäºˆç´„ã®è©³ç´°ã‚’å–å¾—"""
    try:
        jobs = db.get_all_at_jobs()

        job_detail = None
        for job in jobs:
            if str(job['id']) == str(job_id):
                job_detail = job
                break

        if not job_detail:
            return jsonify({'error': 'Job not found'}), 404

        return jsonify({
            'command': job_detail['command'],
            'title': job_detail.get('title', ''),
            'station': job_detail.get('station', ''),
            'start_time': job_detail.get('start_time', ''),
            'end_time': job_detail.get('end_time', ''),
            'schedule_time': job_detail['schedule_time']
        })

    except Exception as e:
        logger.error(f'Get at job detail error: {str(e)}')
        return jsonify({'error': str(e)}), 500

# ========================================
# ç•ªçµ„è¡¨DBé–¢é€£API
# ========================================

@app.route('/programs/search', methods=['GET'])
def search_programs_api():
    """ç•ªçµ„ã‚’æ¤œç´¢"""
    try:
        keyword = request.args.get('keyword', '')
        area_id = request.args.get('area_id')
        date_from = request.args.get('date_from')
        date_to = request.args.get('date_to')

        logger.info(f'ğŸ” Search API called with keyword="{keyword}", area_id={area_id}, date_from={date_from}, date_to={date_to}')

        if not keyword:
            return jsonify({'error': 'keyword parameter is required'}), 400

        results = db.search_programs(keyword, area_id, date_from, date_to)
        logger.info(f'ğŸ” Search API returning {len(results)} results')

        return jsonify({
            'success': True,
            'count': len(results),
            'programs': results
        })

    except Exception as e:
        logger.error(f'Search API error: {str(e)}')
        return jsonify({'error': str(e)}), 500


@app.route('/programs/area/<area_id>/date/<date>', methods=['GET'])
def get_area_programs_api(area_id, date):
    """ç‰¹å®šã‚¨ãƒªã‚¢ãƒ»æ—¥ä»˜ã®ç•ªçµ„ã‚’å–å¾—ï¼ˆDBã«ãªã‘ã‚Œã°radiko APIã‹ã‚‰å–å¾—ï¼‰"""
    try:
        # å¼·åˆ¶æ›´æ–°ãƒ•ãƒ©ã‚°
        force_refresh = request.args.get('force', 'false').lower() == 'true'

        programs = db.get_programs_by_area_date(area_id, date)

        # å¼·åˆ¶æ›´æ–° ã¾ãŸã¯ DBã«ãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆã€radiko APIã‹ã‚‰å–å¾—ã—ã¦DBã«ä¿å­˜
        if force_refresh or len(programs) == 0:
            if force_refresh:
                logger.info(f'ğŸ”„ Force refresh for {area_id}/{date}, fetching from radiko API...')
            else:
                logger.info(f'ğŸ“¥ No data in DB for {area_id}/{date}, fetching from radiko API...')

            # radiko APIã‹ã‚‰å–å¾—
            fetched_programs = fetch_programs.fetch_area_programs(area_id, date)

            if fetched_programs:
                # DBã«ä¿å­˜ï¼ˆæ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã¯å‰Šé™¤ã•ã‚Œã‚‹ï¼‰
                db.save_programs(fetched_programs, area_id, date)
                logger.info(f'âœ… Fetched and saved {len(fetched_programs)} programs for {area_id}/{date}')

                # ä¿å­˜ã—ãŸãƒ‡ãƒ¼ã‚¿ã‚’å†å–å¾—ã—ã¦ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
                programs = db.get_programs_by_area_date(area_id, date)
            else:
                logger.warning(f'âš ï¸ No programs found from radiko API for {area_id}/{date}')

        return jsonify({
            'success': True,
            'area_id': area_id,
            'date': date,
            'count': len(programs),
            'programs': programs
        })

    except Exception as e:
        logger.error(f'Get area programs API error: {str(e)}')
        return jsonify({'error': str(e)}), 500


@app.route('/programs/update/status', methods=['GET'])
def get_update_status_api():
    """ç•ªçµ„è¡¨ã®æ›´æ–°ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’å–å¾—"""
    try:
        status = db.get_update_status()
        return jsonify(status)

    except Exception as e:
        logger.error(f'Get update status API error: {str(e)}')
        return jsonify({'error': str(e)}), 500


@app.route('/programs/update/trigger', methods=['POST'])
def trigger_update_api():
    """ç•ªçµ„è¡¨ã®å³æ™‚æ›´æ–°ã‚’ãƒˆãƒªã‚¬ãƒ¼"""
    try:
        logger.info('Manual update triggered via API')

        # ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§å®Ÿè¡Œï¼ˆãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’ãƒ–ãƒ­ãƒƒã‚¯ã—ãªã„ï¼‰
        scheduler.add_job(
            func=fetch_programs.update_all_areas,
            trigger='date',  # å³åº§ã«å®Ÿè¡Œ
            id='manual_update',
            name='Manual update',
            replace_existing=True
        )

        return jsonify({
            'success': True,
            'message': 'Update started in background'
        })

    except Exception as e:
        logger.error(f'Trigger update API error: {str(e)}')
        return jsonify({'error': str(e)}), 500


# ==================== ç®¡ç†ãƒ¡ãƒ‹ãƒ¥ãƒ¼API ====================

@app.route('/admin/update-programs-stream', methods=['GET'])
def admin_update_programs_stream():
    """ç®¡ç†ç”»é¢ã‹ã‚‰ã®ç•ªçµ„è¡¨ä¸€æ‹¬æ›´æ–°ï¼ˆSSEã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ï¼‰"""
    def generate():
        try:
            days = int(request.args.get('days', 3))
            logger.info(f'Admin: manual program update for {days} days (streaming)')

            # é€²æ—æƒ…å ±ã‚’ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°é€ä¿¡
            yield f"data: {json.dumps({'type': 'start', 'message': f'{days}æ—¥åˆ†ã®ç•ªçµ„è¡¨æ›´æ–°ã‚’é–‹å§‹ã—ã¾ã™...'})}\n\n"

            # fetch_programs.pyã®ALL_AREA_IDSã‚’å–å¾—
            from fetch_programs import ALL_AREA_IDS
            from datetime import datetime, timedelta
            import time

            # æ—¥ä»˜ãƒªã‚¹ãƒˆã‚’ç”Ÿæˆï¼ˆä»Šæ—¥ã‹ã‚‰æŒ‡å®šæ—¥æ•°åˆ†ï¼‰
            today = datetime.now()
            if today.hour < 5:
                today = today - timedelta(days=1)

            dates = []
            for i in range(days):
                date = today + timedelta(days=i)
                date_str = date.strftime('%Y%m%d')
                dates.append(date_str)

            total_tasks = len(ALL_AREA_IDS) * len(dates)
            completed = 0
            total_programs = 0
            success_count = 0
            error_count = 0
            warning_count = 0

            yield f"data: {json.dumps({'type': 'info', 'message': f'å…¨{len(ALL_AREA_IDS)}ã‚¨ãƒªã‚¢ Ã— {len(dates)}æ—¥ = {total_tasks}ä»¶ã®å‡¦ç†'})}\n\n"

            # å„ã‚¨ãƒªã‚¢ã‚’å‡¦ç†
            for idx, area_id in enumerate(ALL_AREA_IDS, 1):
                yield f"data: {json.dumps({'type': 'progress', 'area': area_id, 'current': idx, 'total': len(ALL_AREA_IDS)})}\n\n"

                for date in dates:
                    try:
                        programs = fetch_programs.fetch_area_programs(area_id, date)

                        if programs:
                            db.save_programs(programs, area_id, date)
                            total_programs += len(programs)
                            success_count += 1
                            yield f"data: {json.dumps({'type': 'success', 'area': area_id, 'date': date, 'programs': len(programs)})}\n\n"
                        else:
                            warning_count += 1
                            yield f"data: {json.dumps({'type': 'warning', 'area': area_id, 'date': date, 'message': 'No programs found'})}\n\n"

                        completed += 1
                        progress_percent = int((completed / total_tasks) * 100)
                        yield f"data: {json.dumps({'type': 'percent', 'percent': progress_percent, 'completed': completed, 'total': total_tasks, 'success': success_count, 'error': error_count, 'warning': warning_count})}\n\n"

                        time.sleep(0.2)  # ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­–

                    except Exception as e:
                        error_count += 1
                        error_msg = str(e)
                        # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚¨ãƒ©ãƒ¼ã‚’ã‚ã‹ã‚Šã‚„ã™ã
                        if 'timed out' in error_msg or 'timeout' in error_msg.lower():
                            error_msg = 'ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ (radikoã‚µãƒ¼ãƒãƒ¼å¿œç­”ãªã—)'
                        yield f"data: {json.dumps({'type': 'error', 'area': area_id, 'date': date, 'message': error_msg})}\n\n"
                        completed += 1
                        progress_percent = int((completed / total_tasks) * 100)
                        yield f"data: {json.dumps({'type': 'percent', 'percent': progress_percent, 'completed': completed, 'total': total_tasks, 'success': success_count, 'error': error_count, 'warning': warning_count})}\n\n"

            # å¤ã„ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤
            yield f"data: {json.dumps({'type': 'info', 'message': 'å¤ã„ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤ä¸­...'})}\n\n"
            db.cleanup_old_data(days_to_keep=15)

            # å®Œäº†
            yield f"data: {json.dumps({'type': 'complete', 'total_programs': total_programs, 'success': success_count, 'error': error_count, 'warning': warning_count, 'message': 'æ›´æ–°ãŒå®Œäº†ã—ã¾ã—ãŸ'})}\n\n"

        except Exception as e:
            logger.error(f'Admin update programs stream error: {str(e)}')
            yield f"data: {json.dumps({'type': 'error', 'message': str(e)})}\n\n"

    return Response(stream_with_context(generate()), mimetype='text/event-stream')


@app.route('/admin/logs/<log_type>')
def admin_view_logs(log_type):
    """ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¡¨ç¤º"""
    try:
        log_content = ''

        if log_type == 'myradiko':
            # myradikoå®Ÿè¡Œãƒ­ã‚°
            log_path = '/tmp/myradiko_output.log'
            if os.path.exists(log_path):
                with open(log_path, 'r', encoding='utf-8', errors='ignore') as f:
                    lines = f.readlines()
                    # æœ€æ–°500è¡Œã®ã¿
                    log_content = ''.join(lines[-500:])
            else:
                log_content = 'ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“'

        elif log_type == 'docker':
            # Flaskã‚¢ãƒ—ãƒªã®ãƒ­ã‚°ï¼ˆã“ã®ã‚³ãƒ³ãƒ†ãƒŠå†…ã§ã¯å–å¾—ä¸å¯ï¼‰
            log_content = 'Dockerãƒ­ã‚°ã¯ãƒ›ã‚¹ãƒˆå´ã§ `docker-compose logs proxy` ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã¦ç¢ºèªã—ã¦ãã ã•ã„ã€‚\n\n'
            log_content += 'ã‚³ãƒ³ãƒ†ãƒŠå†…ã‹ã‚‰ãƒ›ã‚¹ãƒˆã®Dockerã‚³ãƒãƒ³ãƒ‰ã¯å®Ÿè¡Œã§ãã¾ã›ã‚“ã€‚'

        elif log_type == 'nginx':
            # Nginxãƒ­ã‚°ï¼ˆã“ã®ã‚³ãƒ³ãƒ†ãƒŠå†…ã§ã¯å–å¾—ä¸å¯ï¼‰
            log_content = 'Nginxãƒ­ã‚°ã¯ãƒ›ã‚¹ãƒˆå´ã§ `docker-compose logs web` ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã¦ç¢ºèªã—ã¦ãã ã•ã„ã€‚\n\n'
            log_content += 'ã¾ãŸã¯ã€docker exec ã‚³ãƒãƒ³ãƒ‰ã§webã‚³ãƒ³ãƒ†ãƒŠã«å…¥ã‚Šã€/var/log/nginx/ä»¥ä¸‹ã®ãƒ­ã‚°ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚'

        else:
            return jsonify({'error': 'Invalid log type'}), 400

        return jsonify({
            'success': True,
            'log': log_content
        })

    except Exception as e:
        logger.error(f'Admin view logs error: {str(e)}')
        return jsonify({'error': str(e)}), 500


@app.route('/admin/execute-manual', methods=['POST'])
def admin_execute_manual():
    """æ‰‹å‹•ã§myradikoã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œ"""
    try:
        data = request.json
        script_path = data.get('script_path', SCRIPT_PATH)
        title = data.get('title', '')
        station_id = data.get('station_id')
        start_time = data.get('start_time')
        end_time = data.get('end_time')

        if not all([station_id, start_time, end_time]):
            return jsonify({'error': 'Missing required parameters'}), 400

        # ã‚¿ã‚¤ãƒˆãƒ«ã‚’ã‚µãƒ‹ã‚¿ã‚¤ã‚ºï¼ˆã‚¹ãƒšãƒ¼ã‚¹ã‚’ã‚¢ãƒ³ãƒ€ãƒ¼ãƒãƒ¼ã«ã€å…¨è§’è¨˜å·ã‚’åŠè§’ã«ï¼‰
        safe_title = sanitize_filename(title)

        # ã‚³ãƒãƒ³ãƒ‰ã‚’æ§‹ç¯‰ï¼ˆã‚µãƒ‹ã‚¿ã‚¤ã‚ºã—ãŸã‚¿ã‚¤ãƒˆãƒ«ã‚’ä½¿ç”¨ï¼‰
        command = f'{script_path} "{safe_title}" "{station_id}" "{station_id}" "{start_time}" "{end_time}" "" "" "" >> /tmp/myradiko_output.log 2>&1'

        logger.info(f'Admin: executing manual command: {command}')

        # ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œï¼ˆåŒæœŸå®Ÿè¡Œï¼‰
        result = subprocess.run(
            command,
            shell=True,
            capture_output=True,
            encoding='utf-8',
            errors='replace',  # ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼ã‚’ç½®ãæ›ãˆæ–‡å­—ã§å‡¦ç†
            timeout=600  # 10åˆ†ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
        )

        output = result.stdout + result.stderr

        if result.returncode != 0:
            logger.error(f'Command failed: {output}')
            return jsonify({
                'success': False,
                'error': 'ã‚³ãƒãƒ³ãƒ‰å®Ÿè¡Œã«å¤±æ•—ã—ã¾ã—ãŸ',
                'output': output
            }), 500

        logger.info(f'Command executed successfully: {output}')

        return jsonify({
            'success': True,
            'message': 'ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã¾ã—ãŸ',
            'output': output
        })

    except subprocess.TimeoutExpired:
        return jsonify({'error': 'ã‚³ãƒãƒ³ãƒ‰ãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸï¼ˆ10åˆ†ä»¥ä¸Šï¼‰'}), 500
    except Exception as e:
        logger.error(f'Admin execute manual error: {str(e)}')
        return jsonify({'error': str(e)}), 500


@app.route('/admin/cleanup', methods=['POST'])
def admin_cleanup():
    """å¤ã„DBãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤"""
    try:
        deleted = db.cleanup_old_data(days_to_keep=15)

        return jsonify({
            'success': True,
            'message': 'å¤ã„ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤ã—ã¾ã—ãŸ',
            'deleted': deleted
        })

    except Exception as e:
        logger.error(f'Admin cleanup error: {str(e)}')
        return jsonify({'error': str(e)}), 500


@app.route('/admin/disk-space')
def admin_disk_space():
    """ãƒ‡ã‚£ã‚¹ã‚¯å®¹é‡ã‚’ç¢ºèª"""
    try:
        # dfã‚³ãƒãƒ³ãƒ‰ã§ãƒ‡ã‚£ã‚¹ã‚¯å®¹é‡ã‚’å–å¾—
        result = subprocess.run(
            ['df', '-h', BASE_DIR],
            capture_output=True,
            text=True,
            timeout=5
        )

        return jsonify({
            'success': True,
            'info': result.stdout
        })

    except Exception as e:
        logger.error(f'Admin disk space error: {str(e)}')
        return jsonify({'error': str(e)}), 500


@app.route('/admin/db-status')
def admin_db_status():
    """DBçµ±è¨ˆæƒ…å ±ã‚’å–å¾—"""
    try:
        import sqlite3

        conn = sqlite3.connect(db.DB_PATH)
        cursor = conn.cursor()

        # ç·ç•ªçµ„æ•°
        cursor.execute('SELECT COUNT(*) FROM programs')
        total_programs = cursor.fetchone()[0]

        # æ›´æ–°å±¥æ­´æ•°
        cursor.execute('SELECT COUNT(*) FROM update_log')
        total_updates = cursor.fetchone()[0]

        # DBãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º
        db_size = os.path.getsize(db.DB_PATH)
        db_size_mb = round(db_size / 1024 / 1024, 2)

        conn.close()

        return jsonify({
            'success': True,
            'total_programs': total_programs,
            'total_updates': total_updates,
            'db_size': f'{db_size_mb} MB'
        })

    except Exception as e:
        logger.error(f'Admin DB status error: {str(e)}')
        return jsonify({'error': str(e)}), 500


# ========================================
# ã‚¢ãƒ¼ãƒˆãƒ¯ãƒ¼ã‚¯ç®¡ç†API
# ========================================

@app.route('/artwork/upload', methods=['POST'])
def upload_artwork():
    """ã‚¢ãƒ¼ãƒˆãƒ¯ãƒ¼ã‚¯ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰"""
    try:
        if 'file' not in request.files:
            return jsonify({'error': 'No file provided'}), 400

        if 'title' not in request.form:
            return jsonify({'error': 'No title provided'}), 400

        file = request.files['file']
        title = request.form['title']

        if file.filename == '':
            return jsonify({'error': 'No file selected'}), 400

        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚¿ã‚¤ãƒ—ãƒã‚§ãƒƒã‚¯
        allowed_types = ['image/jpeg', 'image/jpg', 'image/png', 'image/gif', 'image/webp']
        mime_type = file.content_type

        if mime_type not in allowed_types:
            return jsonify({'error': f'Invalid file type: {mime_type}'}), 400

        # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
        image_data = file.read()

        # DBã«ä¿å­˜
        success = db.save_artwork(title, image_data, mime_type)

        if success:
            return jsonify({'success': True, 'message': f'Artwork uploaded for: {title}'})
        else:
            return jsonify({'error': 'Failed to save artwork'}), 500

    except Exception as e:
        logger.error(f'Upload artwork error: {str(e)}')
        return jsonify({'error': str(e)}), 500


@app.route('/artwork/<path:title>', methods=['GET'])
def get_artwork(title):
    """ã‚¿ã‚¤ãƒˆãƒ«ã«å¯¾å¿œã™ã‚‹ã‚¢ãƒ¼ãƒˆãƒ¯ãƒ¼ã‚¯ã‚’å–å¾—"""
    try:
        artwork = db.get_artwork(title)

        if artwork:
            from io import BytesIO
            return send_file(
                BytesIO(artwork['image_data']),
                mimetype=artwork['mime_type'],
                as_attachment=False
            )
        else:
            # ã‚¢ãƒ¼ãƒˆãƒ¯ãƒ¼ã‚¯ãŒç™»éŒ²ã•ã‚Œã¦ã„ãªã„å ´åˆã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆç”»åƒã‚’è¿”ã™
            return send_file('img/jacket.png', mimetype='image/png')

    except Exception as e:
        logger.error(f'Get artwork error: {str(e)}')
        return jsonify({'error': str(e)}), 500


@app.route('/artwork/list', methods=['GET'])
def list_artworks():
    """ç™»éŒ²ã•ã‚Œã¦ã„ã‚‹ã‚¢ãƒ¼ãƒˆãƒ¯ãƒ¼ã‚¯ä¸€è¦§ã‚’å–å¾—"""
    try:
        artworks = db.list_artworks()
        return jsonify({'success': True, 'artworks': artworks})

    except Exception as e:
        logger.error(f'List artworks error: {str(e)}')
        return jsonify({'error': str(e)}), 500


@app.route('/artwork/delete', methods=['POST'])
def delete_artwork():
    """ã‚¢ãƒ¼ãƒˆãƒ¯ãƒ¼ã‚¯ã‚’å‰Šé™¤"""
    try:
        data = request.json
        title = data.get('title')

        if not title:
            return jsonify({'error': 'No title provided'}), 400

        success = db.delete_artwork(title)

        if success:
            return jsonify({'success': True, 'message': f'Artwork deleted for: {title}'})
        else:
            return jsonify({'error': 'Artwork not found'}), 404

    except Exception as e:
        logger.error(f'Delete artwork error: {str(e)}')
        return jsonify({'error': str(e)}), 500


if __name__ == '__main__':
    # é–‹ç™ºç’°å¢ƒç”¨ï¼ˆæœ¬ç•ªã§ã¯gunicornã‚’ä½¿ç”¨ï¼‰
    app.run(host='0.0.0.0', port=8080, debug=False, threaded=True)
